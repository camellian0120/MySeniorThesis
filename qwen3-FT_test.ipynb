{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5af0404-f640-4897-8604-903eae76739b",
   "metadata": {},
   "source": [
    "## Qwen3-14B's Fine-Tuning Test\n",
    "\n",
    "official\n",
    "> ref: https://docs.unsloth.ai/models/qwen3-how-to-run-and-fine-tune#fine-tuning-qwen3-with-unsloth\n",
    "> ref: https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb\n",
    "\n",
    "note\n",
    "> ref: https://note.com/sachi2222/n/na7b1d91ffb5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440150d6-20de-47a0-915a-687adc17a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "## LLM\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "\n",
    "## Dataset\n",
    "from datasets import load_dataset, Dataset\n",
    "from unsloth import to_sharegpt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed44576-0abd-4040-bfa4-6d342e0fc980",
   "metadata": {},
   "source": [
    "## Load & Setting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1406f9b1-7dae-432c-baf3-df7865171b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.11: Fast Qwen3 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.431 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:45: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98223553dae416092b7c459e1cff24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model loading\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Qwen3-14B\",\n",
    "    max_seq_length=40960, # context length\n",
    "    load_in_4bit=True, # less mem mode\n",
    "    load_in_8bit=False, # more mem mode\n",
    "    full_finetuning=False # if u need full-FT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b97fe96-ac06-4c0f-830f-78e8457e781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.11 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# select LoRA option\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32, # Choose any num like 8, 16, 32, 64, 128\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha=32, # alpha = r | r*2\n",
    "    lora_dropout=0, # 0 is optimized\n",
    "    bias=\"none\", # \"none\" is optimized\n",
    "    use_gradient_checkpointing=\"unsloth\", # True | \"unsloth\", for too-long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False, # under here, optical\n",
    "    loftq_config=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dac1d1-4db3-4dd0-afc8-91e4b9c4905a",
   "metadata": {},
   "source": [
    "## Convert Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ac05f82-d4e9-4354-9b7d-2208b3b4106d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e0c641ffcd424584c1f59ee9676c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging columns:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0861eaa396e4fac9859d0a37e37298c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting to ShareGPT:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e1485054d543d9a86dbcadd62f8f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c12e6df1cd4270b905687e39e0cf38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56960a933cf040799957d6c9964b4e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeee684b46bc49c78abd2934987353f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extending conversations:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make Datasets\n",
    "# load json\n",
    "raw_data = load_dataset(\"json\", data_files=\"./jvn_results_wordpress202304_conv_no-id.json\")\n",
    "\n",
    "# convert hugginface-style\n",
    "huggingface_data = Dataset.from_list(raw_data['train'])\n",
    "\n",
    "# convert share_gpt-style\n",
    "# Three dialogue sessions are preferred\n",
    "share_data = to_sharegpt(huggingface_data,\n",
    "                        merged_prompt=\"{instruction}\",\n",
    "                        merged_column_name=\"instruction\",\n",
    "                        output_column_name=\"output\",\n",
    "                        conversation_extension=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82a9b750-df66-4636-822c-baf2c10d48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minor format changes\n",
    "converted_share_data = [[{\n",
    "            \"role\": \"user\" if message[\"from\"] == \"human\" else \"assistant\",\n",
    "            \"content\": re.sub(r\"\\('(.+?)',\\)\", r\"\\1\", message[\"value\"])\n",
    "        }\n",
    "        for message in item[\"conversations\"]\n",
    "    ]\n",
    "    for item in share_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3da84a6f-d7a4-4e4c-bb32-d293310c8eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'JVNDB-2025-010225 について教えてください'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'JVNDB-2025-010225 とは eMagicOne の WordPress 用 eMagicOne Store Manager for WooCommerce におけるファイル名やパス名の外部制御に関する脆弱性 のことです。The eMagicOne Store Manager for WooCommerce plugin for WordPress is vulnerable to arbitrary file deletion due to insufficient file path validation in the delete_file() function in all versions up to, and including, 1.2.5. This makes it possible for unauthenticated attackers to delete arbitrary files on the server, which can easily lead to remote code execution when the right file is deleted (such as wp-config.php). This is only exploitable by unauthenticated attackers in default configurations where the the default password is left as 1:1, or where the attacker gains access to the credentials. この脆弱性を受けるバージョンは eMagicOne\\neMagicOne Store Manager for WooCommerce 1.2.5 およびそれ以前 です'},\n",
       " {'role': 'user', 'content': 'JVNDB-2023-017528 について教えてください'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'JVNDB-2023-017528 とは Flipper Code の WordPress 用 wp google map におけるクロスサイトリクエストフォージェリの脆弱性 のことです。Cross-Site Request Forgery (CSRF) vulnerability in flippercode WordPress Plugin for Google Maps – WP MAPS (formerly WP Google Map Plugin) plugin <=\\xa04.4.2 versions. この脆弱性を受けるバージョンは Flipper Code\\nwp google map 4.4.2 およびそれ以前 です'},\n",
       " {'role': 'user', 'content': 'JVNDB-2024-021678 について教えてください'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"JVNDB-2024-021678 とは katieseaborn の WordPress 用 zotpress における SQL インジェクションの脆弱性 のことです。Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection') vulnerability in Katie Seaborn Zotpress.This issue affects Zotpress: from n/a through 7.3.7. この脆弱性を受けるバージョンは katieseaborn\\nzotpress 7.3.8 未満 です\"}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_share_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a4e1d15-e6a5-42ca-8dad-6e4615adeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of <\\llm_start\\>, etc\n",
    "conversations = tokenizer.apply_chat_template(\n",
    "    converted_share_data,\n",
    "    tokenize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9ef8e76-1765-46d7-ab40-3f2b434345d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converted to Hugging Face format\n",
    "\n",
    "targetdataset = Dataset.from_dict({\"text\": conversations})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae6664-3b41-4edc-8a1a-5957c82dccf4",
   "metadata": {},
   "source": [
    "## Train settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f538b737-25dc-4ada-80e3-0b35ba24f7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b94add296a4c94a78f11c7fb3e4d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=24):   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=targetdataset,\n",
    "    eval_dataset=None, # test Datasets\n",
    "    args=SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        # num_train_epochs=1,\n",
    "        max_steps=30,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        report_to=\"none\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271e39e-17ac-4ab1-bfed-0eef07c43ae4",
   "metadata": {},
   "source": [
    "## Start FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e83a5062-0a43-4ebd-bd58-108b4e8d8b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 9,742 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 128,450,560 of 14,896,757,760 (0.86% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 03:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.880500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.297300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.903600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.932900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.807100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.854100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.818600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.796900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.772300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.784200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.754100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.622500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac46e77-c106-41f6-ad08-2b3aa1a49d04",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "89d9a395-e11f-4aac-9617-1316241f823d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vulnerability affects JVNDB-2025-010225. This issue affects WordPress Plugin wp-woocommerce-advanced-shipping: from n/a through 1.4.2. The WooCommerce Advanced Shipping plugin for WordPress is vulnerable to unauthorized modification of data due to a missing capability check on the woocommerce_advanced_shipping_save_custom_location_data function in all versions up to, and including, 1.4.2. This makes it possible for authenticated attackers, with subscriber-level access and above, to update the custom shipping locations. This issue affects WooCommerce Advanced Shipping: from n/a through 1.4.2.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "# Inference test\n",
    "prompt=\"\"\"\n",
    "hello! Please tell me about \"JVNDB-2025-010225\".\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\" : \"user\", \"content\" : prompt}]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = False, # Disable thinking\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 2048, # Increase for longer outputs!\n",
    "    temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c81bbb-d5a0-4ea8-a3a3-17de1d4f0437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# セキュリティ脆弱性の分析\n",
      "\n",
      "## 1. 脆弱性の特定\n",
      "このコードには「クロスサイトスクリプティング (XSS)」の脆弱性があります。`htmlspecialchars()`関数を使用して出力している箇所がなく、JavaScriptの注入を受ける可能性があります。\n",
      "\n",
      "## 2. 脆弱性のリスク\n",
      "この脆弱性を受けると、攻撃者がJavaScriptを注入し、ユーザーのブラウザを操作"
     ]
    }
   ],
   "source": [
    "# Inference test2\n",
    "prompt=\"\"\"\n",
    "You are a white hat hacker tasked with discovering vulnerabilities in the provided source code.\n",
    "Perform the following three actions on the source code below:\n",
    "1. Identify the vulnerability\n",
    "2. Present the risks of leaving it unaddressed\n",
    "3. Provide a solution to eliminate the vulnerability\n",
    "\n",
    "Ensure your output adheres to the following three points:\n",
    "1. Output in Japanese\n",
    "2. Be clear and concise\n",
    "3. Use Markdown format\n",
    "\n",
    "The source code is shown below:\n",
    "---\n",
    "---\n",
    "<?php\n",
    "// php_d100_roller.php\n",
    "// Simple 100-sided dice roller application (single file)\n",
    "// Usage: Place this file on your web server and open it in a browser.\n",
    "// For local testing: run `php -S localhost:8000` and visit http://localhost:8000/php_d100_roller.php\n",
    "\n",
    "session_start();\n",
    "\n",
    "// Keep roll history in session (max 100 entries)\n",
    "if (!isset($_SESSION['d100_history'])) {\n",
    "    $_SESSION['d100_history'] = [];\n",
    "}\n",
    "\n",
    "$errors = [];\n",
    "$results = [];\n",
    "$total = 0;\n",
    "$count = 1;\n",
    "\n",
    "if ($_SERVER['REQUEST_METHOD'] === 'POST') {\n",
    "    // Get roll count (clamped between 1–100)\n",
    "    $count = isset($_POST['count']) ? intval($_POST['count']) : 1;\n",
    "    if ($count < 1) $count = 1;\n",
    "    if ($count > 100) $count = 100;\n",
    "\n",
    "    // Optional label\n",
    "    $label = isset($_POST['label']) ? trim($_POST['label']) : '';\n",
    "\n",
    "    // Perform rolls\n",
    "    for ($i = 0; $i < $count; $i++) {\n",
    "        $roll = random_int(1, 100);\n",
    "        $results[] = $roll;\n",
    "        $total += $roll;\n",
    "    }\n",
    "\n",
    "    // Add to history (newest first)\n",
    "    $entry = [\n",
    "        'time' => date('Y-m-d H:i:s'),\n",
    "        'count' => $count,\n",
    "        'label' => $label,\n",
    "        'results' => $results,\n",
    "        'total' => $total,\n",
    "    ];\n",
    "\n",
    "    array_unshift($_SESSION['d100_history'], $entry);\n",
    "    if (count($_SESSION['d100_history']) > 100) {\n",
    "        $_SESSION['d100_history'] = array_slice($_SESSION['d100_history'], 0, 100);\n",
    "    }\n",
    "}\n",
    "\n",
    "$history = $_SESSION['d100_history'];\n",
    "?>\n",
    "<!doctype html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n",
    "<title>100-sided Dice Roller</title>\n",
    "<style>\n",
    "    body { font-family: system-ui, -apple-system, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial; padding: 20px; }\n",
    "    .box { max-width: 820px; margin: 0 auto; }\n",
    "    input[type=\"number\"] { width: 80px; }\n",
    "    .badge { display:inline-block; padding:6px 10px; margin:4px; border-radius:6px; background:#eee; }\n",
    "    .roll { font-weight:700; }\n",
    "    .history { margin-top:20px; }\n",
    "    .card { padding:12px; border:1px solid #ddd; border-radius:8px; margin-bottom:12px; }\n",
    "    .muted { color:#666; font-size:0.9rem; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"box\">\n",
    "    <h1>100-sided Dice Roller</h1>\n",
    "    <form method=\"post\" action=\"<?php echo htmlspecialchars($_SERVER['PHP_SELF']); ?>\">\n",
    "    <label>Number of rolls (1–100): <input type=\"number\" name=\"count\" value=\"<?php echo htmlspecialchars($count); ?>\" min=\"1\" max=\"100\"></label>\n",
    "    &nbsp;\n",
    "    <label>Label (optional): <input type=\"text\" name=\"label\" value=\"\"></label>\n",
    "    &nbsp;\n",
    "    <button type=\"submit\">Roll</button>\n",
    "    </form>\n",
    "\n",
    "    <?php if (!empty($results)): ?>\n",
    "    <div class=\"card\">\n",
    "        <div class=\"muted\">Timestamp: <?php echo htmlspecialchars($entry['time']); ?></div>\n",
    "        <h2>Results</h2>\n",
    "        <div>\n",
    "        <?php foreach ($results as $i => $r): ?>\n",
    "            <span class=\"badge roll\">#<?php echo $i+1; ?>: <?php echo $r; ?></span>\n",
    "        <?php endforeach; ?>\n",
    "        </div>\n",
    "        <p>Total: <strong><?php echo $total; ?></strong> / Average: <strong><?php echo count($results) ? round($total / count($results), 2) : 0; ?></strong></p>\n",
    "        <?php if ($entry['label'] !== ''): ?><p>Label: <?php echo htmlspecialchars($entry['label']); ?></p><?php endif; ?>\n",
    "    </div>\n",
    "    <?php endif; ?>\n",
    "\n",
    "    <div class=\"history\">\n",
    "    <h2>History (last <?php echo count($history); ?> rolls)</h2>\n",
    "    <?php if (empty($history)): ?>\n",
    "        <p class=\"muted\">No rolls yet.</p>\n",
    "    <?php else: ?>\n",
    "        <?php foreach ($history as $idx => $h): ?>\n",
    "        <div class=\"card\">\n",
    "            <div class=\"muted\"><?php echo htmlspecialchars($h['time']); ?> — Rolls: <?php echo $h['count']; ?><?php if ($h['label'] !== ''): ?> — Label: <?php echo htmlspecialchars($h['label']); ?><?php endif; ?></div>\n",
    "            <div style=\"margin-top:8px;\">\n",
    "            <?php foreach ($h['results'] as $i => $r): ?>\n",
    "                <span class=\"badge\"><?php echo $r; ?></span>\n",
    "            <?php endforeach; ?>\n",
    "            </div>\n",
    "            <p style=\"margin-top:8px;\">Total: <?php echo $h['total']; ?> / Average: <?php echo count($h['results']) ? round($h['total'] / count($h['results']), 2) : 0; ?></p>\n",
    "        </div>\n",
    "        <?php endforeach; ?>\n",
    "    <?php endif; ?>\n",
    "    </div>\n",
    "\n",
    "    <div style=\"margin-top:20px;\" class=\"muted\">\n",
    "    <p>Note: Uses <code>random_int(1, 100)</code> for cryptographically secure random number generation. The session keeps up to 100 history entries.</p>\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\" : \"user\", \"content\" : prompt}]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = False, # Disable thinking\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 4096, # Increase for longer outputs!\n",
    "    temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5c69f-ccc6-4258-ab50-288ed1f49980",
   "metadata": {},
   "source": [
    "## Save LoRA/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893ba66-336d-4866-9ae6-22b9aef76386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save LoRA\n",
    "model.save_pretrained(\"Vulnerability_Detection_Wordpress\")\n",
    "tokenizer.save_pretrained(\"Vulnerability_Detection_Wordpress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834b556-f524-4a85-9446-744ac41cf5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ALL-MODEL\n",
    "model.save_pretrained_merged(\"Vulnerability_Detection_Wordpress\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1d856-5928-4451-8851-bb0cec1a762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ALL-MODEL as .gguf\n",
    "model.save_pretrained_merged(\"Vulnerability_Detection_Wordpress\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18d9a2-018d-4a95-a557-f2bea42005f2",
   "metadata": {},
   "source": [
    "## Upload LoRA/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac3fa2-f6dc-43a5-bcf0-553f73aa5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
