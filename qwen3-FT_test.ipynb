{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5af0404-f640-4897-8604-903eae76739b",
   "metadata": {},
   "source": [
    "## Qwen3-14B's Fine-Tuning Test\n",
    "\n",
    "official\n",
    "> ref: https://docs.unsloth.ai/models/qwen3-how-to-run-and-fine-tune#fine-tuning-qwen3-with-unsloth\n",
    "> ref: https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb\n",
    "\n",
    "note\n",
    "> ref: https://note.com/sachi2222/n/na7b1d91ffb5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440150d6-20de-47a0-915a-687adc17a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "## LLM\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "\n",
    "## Dataset\n",
    "from datasets import load_dataset, Dataset\n",
    "from unsloth import to_sharegpt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed44576-0abd-4040-bfa4-6d342e0fc980",
   "metadata": {},
   "source": [
    "## Load & Setting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1406f9b1-7dae-432c-baf3-df7865171b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.11: Fast Qwen3 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.431 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:45: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98223553dae416092b7c459e1cff24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model loading\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Qwen3-14B\",\n",
    "    max_seq_length=40960, # context length\n",
    "    load_in_4bit=True, # less mem mode\n",
    "    load_in_8bit=False, # more mem mode\n",
    "    full_finetuning=False # if u need full-FT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b97fe96-ac06-4c0f-830f-78e8457e781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.11 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# select LoRA option\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32, # Choose any num like 8, 16, 32, 64, 128\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha=32, # alpha = r | r*2\n",
    "    lora_dropout=0, # 0 is optimized\n",
    "    bias=\"none\", # \"none\" is optimized\n",
    "    use_gradient_checkpointing=\"unsloth\", # True | \"unsloth\", for too-long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False, # under here, optical\n",
    "    loftq_config=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dac1d1-4db3-4dd0-afc8-91e4b9c4905a",
   "metadata": {},
   "source": [
    "## Convert Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ac05f82-d4e9-4354-9b7d-2208b3b4106d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e0c641ffcd424584c1f59ee9676c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging columns:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0861eaa396e4fac9859d0a37e37298c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting to ShareGPT:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e1485054d543d9a86dbcadd62f8f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c12e6df1cd4270b905687e39e0cf38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56960a933cf040799957d6c9964b4e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeee684b46bc49c78abd2934987353f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extending conversations:   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make Datasets\n",
    "# load json\n",
    "raw_data = load_dataset(\"json\", data_files=\"./jvn_results_wordpress202304_conv_no-id.json\")\n",
    "\n",
    "# convert hugginface-style\n",
    "huggingface_data = Dataset.from_list(raw_data['train'])\n",
    "\n",
    "# convert share_gpt-style\n",
    "# Three dialogue sessions are preferred\n",
    "share_data = to_sharegpt(huggingface_data,\n",
    "                        merged_prompt=\"{instruction}\",\n",
    "                        merged_column_name=\"instruction\",\n",
    "                        output_column_name=\"output\",\n",
    "                        conversation_extension=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82a9b750-df66-4636-822c-baf2c10d48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minor format changes\n",
    "converted_share_data = [[{\n",
    "            \"role\": \"user\" if message[\"from\"] == \"human\" else \"assistant\",\n",
    "            \"content\": re.sub(r\"\\('(.+?)',\\)\", r\"\\1\", message[\"value\"])\n",
    "        }\n",
    "        for message in item[\"conversations\"]\n",
    "    ]\n",
    "    for item in share_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3da84a6f-d7a4-4e4c-bb32-d293310c8eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'JVNDB-2025-010225 について教えてください'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'JVNDB-2025-010225 とは eMagicOne の WordPress 用 eMagicOne Store Manager for WooCommerce におけるファイル名やパス名の外部制御に関する脆弱性 のことです。The eMagicOne Store Manager for WooCommerce plugin for WordPress is vulnerable to arbitrary file deletion due to insufficient file path validation in the delete_file() function in all versions up to, and including, 1.2.5. This makes it possible for unauthenticated attackers to delete arbitrary files on the server, which can easily lead to remote code execution when the right file is deleted (such as wp-config.php). This is only exploitable by unauthenticated attackers in default configurations where the the default password is left as 1:1, or where the attacker gains access to the credentials. この脆弱性を受けるバージョンは eMagicOne\\neMagicOne Store Manager for WooCommerce 1.2.5 およびそれ以前 です'},\n",
       " {'role': 'user', 'content': 'JVNDB-2023-017528 について教えてください'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'JVNDB-2023-017528 とは Flipper Code の WordPress 用 wp google map におけるクロスサイトリクエストフォージェリの脆弱性 のことです。Cross-Site Request Forgery (CSRF) vulnerability in flippercode WordPress Plugin for Google Maps – WP MAPS (formerly WP Google Map Plugin) plugin <=\\xa04.4.2 versions. この脆弱性を受けるバージョンは Flipper Code\\nwp google map 4.4.2 およびそれ以前 です'},\n",
       " {'role': 'user', 'content': 'JVNDB-2024-021678 について教えてください'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"JVNDB-2024-021678 とは katieseaborn の WordPress 用 zotpress における SQL インジェクションの脆弱性 のことです。Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection') vulnerability in Katie Seaborn Zotpress.This issue affects Zotpress: from n/a through 7.3.7. この脆弱性を受けるバージョンは katieseaborn\\nzotpress 7.3.8 未満 です\"}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_share_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a4e1d15-e6a5-42ca-8dad-6e4615adeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of <\\llm_start\\>, etc\n",
    "conversations = tokenizer.apply_chat_template(\n",
    "    converted_share_data,\n",
    "    tokenize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9ef8e76-1765-46d7-ab40-3f2b434345d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converted to Hugging Face format\n",
    "\n",
    "targetdataset = Dataset.from_dict({\"text\": conversations})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae6664-3b41-4edc-8a1a-5957c82dccf4",
   "metadata": {},
   "source": [
    "## Train settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f538b737-25dc-4ada-80e3-0b35ba24f7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16032702899e4861a033563703fdbeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=24):   0%|          | 0/9742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=targetdataset,\n",
    "    eval_dataset=None, # test Datasets\n",
    "    args=SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        # num_train_epochs=1,\n",
    "        max_steps=30,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        report_to=\"none\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271e39e-17ac-4ab1-bfed-0eef07c43ae4",
   "metadata": {},
   "source": [
    "## Start FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a5062-0a43-4ebd-bd58-108b4e8d8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac46e77-c106-41f6-ad08-2b3aa1a49d04",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89d9a395-e11f-4aac-9617-1316241f823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference test\n",
    "prompt=\"\"\"\n",
    "hello! What is your special skill?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\" : \"user\", \"content\" : prompt}]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = True, # Disable thinking\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 4096, # Increase for longer outputs!\n",
    "    temperature = 0.6,\n",
    "    top_p = 0.95,\n",
    "    top_k = 20,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23c81bbb-d5a0-4ea8-a3a3-17de1d4f0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference test2\n",
    "prompt=\"\"\"\n",
    "You are a white hat hacker tasked with discovering vulnerabilities in the provided source code.\n",
    "Perform the following three actions on the source code below:\n",
    "1. Identify the vulnerability\n",
    "2. Present the risks of leaving it unaddressed\n",
    "3. Provide a solution to eliminate the vulnerability\n",
    "\n",
    "Ensure your output adheres to the following three points:\n",
    "1. Output in Japanese\n",
    "2. Be clear and concise\n",
    "3. Use Markdown format\n",
    "\n",
    "The source code is shown below:\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\" : \"user\", \"content\" : prompt}]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = True, # Disable thinking\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 4096, # Increase for longer outputs!\n",
    "    temperature = 0.6,\n",
    "    top_p = 0.95,\n",
    "    top_k = 20,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5c69f-ccc6-4258-ab50-288ed1f49980",
   "metadata": {},
   "source": [
    "## Save LoRA/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893ba66-336d-4866-9ae6-22b9aef76386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save LoRA\n",
    "model.save_pretrained(\"Vulnerability_Detection_Wordpress\")\n",
    "tokenizer.save_pretrained(\"Vulnerability_Detection_Wordpress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834b556-f524-4a85-9446-744ac41cf5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ALL-MODEL\n",
    "model.save_pretrained_merged(\"Vulnerability_Detection_Wordpress\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1d856-5928-4451-8851-bb0cec1a762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ALL-MODEL as .gguf\n",
    "model.save_pretrained_merged(\"Vulnerability_Detection_Wordpress\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18d9a2-018d-4a95-a557-f2bea42005f2",
   "metadata": {},
   "source": [
    "## Upload LoRA/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac3fa2-f6dc-43a5-bcf0-553f73aa5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
