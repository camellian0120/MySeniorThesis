{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf9ac82-7b15-4e63-aec1-a79270c7a3d9",
   "metadata": {},
   "source": [
    "# JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰RAGç”¨ã®ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œã‚‹\n",
    "\n",
    "LangChain ã‚’ä½¿ã£ã¦ RAG ã‚’è©¦ã—ã¦ã¿ãŸ #AI - Qiita\n",
    "> https://qiita.com/tinymouse/items/4d359674f6b2494bb22d\n",
    "\n",
    "LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã®ãŸã‚ã®LangChain å¾Œç·¨â‘¤ å¤–éƒ¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰ã€åˆ†å‰²åŠã³ä¿å­˜ - qiita\n",
    "> https://qiita.com/utanesuke/items/6efc03eca94f7de3b9cd#json-%E3%83%AD%E3%83%BC%E3%83%80%E3%83%BC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff141d-66e4-470d-bd23-2e567dab3a55",
   "metadata": {},
   "source": [
    "## install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57589987-87be-4085-a843-5e7bb4b2c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth langchain langchain_community langchain-huggingface sentence-transformers transformers accelerate lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee8d2f-09c0-4383-ad4e-b9e08c3bfba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3af62-719f-4913-a8b6-2b8d6435600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70968dca-77f8-49aa-8679-1487b170da79",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e67b13e-2d1d-4cdd-bbfe-813cd80308e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from unsloth import FastLanguageModel\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import math\n",
    "\n",
    "import pyarrow as pa\n",
    "import lancedb\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c17663-3a65-4d82-b93a-bff03dbe6897",
   "metadata": {},
   "source": [
    "## prepare tokenizer & model, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9c6202-7803-4da9-befd-13e701fd1e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.11: Fast Qwen3 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.422 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbabfe5c3df74705b90d11e8e20e5eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "EMBED_MODEL = \"./infloat_multilingual-e5-large/\"\n",
    "DB_PATH = \"./LanceDB/rules.lancedb\"\n",
    "TABLE_NAME = \"rules\"\n",
    "JSON_PATH = Path(\"./rspec_rules.json\")\n",
    "BATCH_SIZE = 256\n",
    "USE_DEVICE = \"cuda\"\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n",
    "    max_seq_length = 40960,\n",
    "    load_in_4bit = True,\n",
    "    load_in_8bit = False,\n",
    ")\n",
    "\n",
    "pipe = transformers.pipeline(\n",
    "    'text-generation',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,\n",
    "    dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ce6b6-adb9-401d-8e2e-2a02da0edd4a",
   "metadata": {},
   "source": [
    "## prepare embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7128a0a7-5614-4a5d-a6cc-394feca24b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1) Embedding ãƒ¢ãƒ‡ãƒ«\n",
    "# ----------------------------\n",
    "emb_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    model_kwargs={\"device\": USE_DEVICE},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "def embed(text: str) -> List[float]:\n",
    "    \"\"\"E5 åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—\"\"\"\n",
    "    formatted = f\"passage: {text}\"\n",
    "    emb = emb_model.embed_query(formatted)\n",
    "    arr = np.asarray(emb, dtype=np.float32)\n",
    "    return arr.tolist()\n",
    "\n",
    "# LangChainã®HuggingFacePipelineã¯éæ¨å¥¨ã®è­¦å‘ŠãŒå‡ºã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€\n",
    "# ç›´æ¥å‘¼ã³å‡ºã™ã‹ã€å¿…è¦ãªå ´åˆã®ã¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚\n",
    "# ã“ã“ã§ã¯RAGéƒ¨åˆ†ã§ç›´æ¥ generate ã‚’å‘¼ã‚“ã§ã„ã‚‹ãŸã‚ llm å¤‰æ•°ã¯å¿…é ˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€\n",
    "# å¿µã®ãŸã‚æ®‹ã™å ´åˆã¯ transformers ã® pipeline ã‚’ãƒ©ãƒƒãƒ—ã—ã¾ã™ã€‚\n",
    "# from langchain_huggingface import HuggingFacePipeline\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654055e-2fd4-460a-bb56-8cf718dcdf99",
   "metadata": {},
   "source": [
    "## make TextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e29e87d-3d7c-4612-bc53-15e9c69e178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2) Splitter\n",
    "# ----------------------------\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ca914-19dc-4999-9ba0-3f4a7caddf10",
   "metadata": {},
   "source": [
    "## setup LanceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bcb5ee-e3f6-476f-ab10-85b206fc6b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(metadata={'instruction': 3, 'output': 4}, page_content='passage: Q. SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®è„†å¼±æ€§ã®ä¾‹ã‚’æ•™ãˆã¦  A. carmelogarcia ã® Simple Leave Manager In PHP With Source Code ã«ãŠã‘ã‚‹ SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®è„†å¼±æ€§ãŒè¦‹ã¤ã‹ã£ã¦ã„ã¾ã™ã€‚A flaw has been found in code-projects Simple Leave Manager 1.0. This vulnerability affects unknown code of the file /user.php. This manipulation of the argument table causes sql injection. Remote exploitation of the attack is possible. The exploit has been published and may be used. è©²å½“ã™ã‚‹è£½å“ã¯carmelogarcia\\nSimple Leave Manager In PHP With Source Code 1.0ã«ãªã‚Šã¾ã™ã€‚\\n')\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 3) LanceDB æ¥ç¶š & schema ä½œæˆ\n",
    "# ----------------------------\n",
    "db = lancedb.connect(DB_PATH)\n",
    "\n",
    "# ã™ã§ã«ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª\n",
    "if TABLE_NAME in db.table_names():\n",
    "    print(f\"ãƒ†ãƒ¼ãƒ–ãƒ« {TABLE_NAME} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...\")\n",
    "    table = db.open_table(TABLE_NAME)\n",
    "else:\n",
    "    print(f\"ãƒ†ãƒ¼ãƒ–ãƒ« {TABLE_NAME} ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€æ–°è¦ä½œæˆã—ã¾ã™...\")\n",
    "\n",
    "    print(\"ç¢ºèª: åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã‚’å–å¾—ã—ã¦ã„ã¾ã™...\")\n",
    "    sample_dim = len(embed(\"this is a sample\"))\n",
    "    print(\"Embedding dim detected:\", sample_dim)\n",
    "    EMB_DIM = sample_dim\n",
    "\n",
    "    schema = pa.schema([\n",
    "        (\"id\", pa.string()),\n",
    "        (\"title\", pa.string()),\n",
    "        (\"chunk\", pa.string()),\n",
    "        (\"embedding\", pa.list_(pa.float32(), list_size=EMB_DIM)), \n",
    "        (\"url\", pa.string()),\n",
    "    ])\n",
    "\n",
    "    table = db.create_table(TABLE_NAME, schema=schema, mode=\"overwrite\")\n",
    "    print(f\"ãƒ†ãƒ¼ãƒ–ãƒ« {TABLE_NAME} ã‚’ä½œæˆã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb6afd-81b0-4d09-b247-a2636104d76d",
   "metadata": {},
   "source": [
    "## load Json & make DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748b5bc2-f7a9-4e30-9b86-98a358fa8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29406/2349016760.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4) JSON èª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒ¼ã‚¿æŠ•å…¥\n",
    "# ----------------------------\n",
    "if JSON_PATH.exists():\n",
    "    with JSON_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows_to_insert = []\n",
    "    \n",
    "    print(\"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "    for item in data:\n",
    "        title = item[\"title\"]\n",
    "        description = item[\"description\"]\n",
    "        url = item.get(\"url\", \"\")\n",
    "\n",
    "        base_text = f\"{title}\\n\\n{description}\"\n",
    "        chunks = splitter.split_text(base_text)\n",
    "\n",
    "        for idx, ch in enumerate(chunks):\n",
    "            if ch.strip() == title:\n",
    "                continue\n",
    "            \n",
    "            emb = embed(ch)\n",
    "\n",
    "            rows_to_insert.append({\n",
    "                \"id\": f\"{url}#{idx}\",\n",
    "                \"title\": title,\n",
    "                \"chunk\": ch,\n",
    "                \"embedding\": emb,\n",
    "                \"url\": url\n",
    "            })\n",
    "            \n",
    "            # ã€ä¿®æ­£ç‚¹2ã€‘ ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚ä¸€å®šæ•°ãŸã¾ã£ãŸã‚‰insertã—ã¦ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã™ã‚‹\n",
    "            if len(rows_to_insert) >= BATCH_SIZE:\n",
    "                table.add(rows_to_insert)\n",
    "                print(f\"âœ“ {len(rows_to_insert)} ä»¶è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "                rows_to_insert = [] # ãƒªã‚»ãƒƒãƒˆ\n",
    "\n",
    "    # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã«æ®‹ã£ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ \n",
    "    if rows_to_insert:\n",
    "        table.add(rows_to_insert)\n",
    "        print(f\"âœ“ æ®‹ã‚Šã® {len(rows_to_insert)} ä»¶ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "\n",
    "else:\n",
    "    print(f\"è­¦å‘Š: {JSON_PATH} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ãªã—ã§æ¤œç´¢ã«é€²ã¿ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279b305-fa95-42ca-9b49-ec05e0115943",
   "metadata": {},
   "source": [
    "## define similer-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb7e913-ab7e-4ad0-bf31-3a86b9379201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5) æ¤œç´¢é–¢æ•°\n",
    "# ----------------------------\n",
    "def search(query: str, k: int = 5):\n",
    "    formatted = f\"query: {query}\"\n",
    "    query_emb = emb_model.embed_query(formatted)\n",
    "\n",
    "    results = (\n",
    "        table.search(query_emb)\n",
    "        .metric(\"cosine\")\n",
    "        .limit(k)\n",
    "        .to_list()\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def build_context(docs: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    æ¤œç´¢çµæœ(docs)ã®ãƒªã‚¹ãƒˆã‚’ã€LLMã«æ¸¡ã™ãŸã‚ã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«æ•´å½¢ã™ã‚‹é–¢æ•°\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for i, d in enumerate(docs):\n",
    "        # è¾æ›¸ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’å–å¾—\n",
    "        title = d.get(\"title\", \"No Title\")\n",
    "        chunk = d.get(\"chunk\", \"\")\n",
    "        \n",
    "        # ã‚¹ã‚³ã‚¢ã®å–å¾— (LanceDBã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã£ã¦ã‚­ãƒ¼åãŒç•°ãªã‚‹å ´åˆã¸ã®å¯¾å¿œ)\n",
    "        # _distance ã¯è·é›¢ãªã®ã§ä½ã„ã»ã†ãŒé¡ä¼¼åº¦ãŒé«˜ã„ã§ã™ãŒã€ã“ã“ã§ã¯å‚è€ƒå€¤ã¨ã—ã¦è¡¨ç¤ºã—ã¾ã™\n",
    "        score = d.get(\"_score\", d.get(\"_distance\", 0.0))\n",
    "        \n",
    "        # æ•´å½¢ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: [ç•ªå·] (ã‚¹ã‚³ã‚¢) ã‚¿ã‚¤ãƒˆãƒ« -> æœ¬æ–‡\n",
    "        part_text = f\"Reference [{i+1}] (Metric: {score:.4f})\\nTitle: {title}\\nContent:\\n{chunk}\"\n",
    "        parts.append(part_text)\n",
    "    \n",
    "    # å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åŒºåˆ‡ã‚Šç·šã§çµåˆã—ã¦è¿”ã™\n",
    "    return \"\\n\\n\" + (\"-\" * 20) + \"\\n\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb674d23-d7fb-492f-b705-ef2a6e2dc5a5",
   "metadata": {},
   "source": [
    "## load DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7526c0-f350-4829-b1da-bc1ce0ae42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 6) LLMæ¨è«–ãƒ˜ãƒ«ãƒ‘ãƒ¼ & æ–°ãƒ•ãƒ­ãƒ¼ã®å®Ÿè£…\n",
    "# ----------------------------\n",
    "def run_llm_inference(messages: List[Dict[str, str]], max_tokens: int = 256) -> str:\n",
    "    \"\"\"\n",
    "    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã›ãšã«LLMã®å‡ºåŠ›ã‚’æ–‡å­—åˆ—ã¨ã—ã¦å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "    (Step 1: è„†å¼±æ€§ç‰¹å®šç”¨)\n",
    "    \"\"\"\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False,\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(USE_DEVICE)\n",
    "    \n",
    "    # generateæ™‚ã¯å‹¾é…è¨ˆç®—ä¸è¦\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=0.3, # ç‰¹å®šã‚¿ã‚¹ã‚¯ãªã®ã§ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’ä¸‹ã’ã‚‹\n",
    "            top_p=0.95,\n",
    "            use_cache=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†ã‚’é™¤å»ã—ã¦å¿œç­”ã®ã¿æŠ½å‡º\n",
    "    generated_ids = outputs[0][len(inputs.input_ids[0]):]\n",
    "    decoded_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return decoded_text.strip()\n",
    "\n",
    "def rag_answer_v2(code: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    3æ®µéšãƒ•ãƒ­ãƒ¼ã®å®Ÿè£…:\n",
    "    1. LLMã§è„†å¼±æ€§åã‚’ç‰¹å®š\n",
    "    2. ãã®åå‰ã§RAGæ¤œç´¢\n",
    "    3. RAGæƒ…å ±ã‚’å…ƒã«å¯¾ç­–ã‚’å‡ºåŠ›\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n=== Step 1: LLMã«ã‚ˆã‚‹è„†å¼±æ€§è¨ºæ–­ã‚’å®Ÿè¡Œä¸­... ===\")\n",
    "    \n",
    "    # --- Step 1: è„†å¼±æ€§ã®ç‰¹å®š (RAGãªã—) ---\n",
    "    detect_system_prompt = \"\"\"You are a specialized security code auditor.\n",
    "Analyze the provided source code and identify the single most critical security vulnerability present.\n",
    "Output ONLY the standard name of the vulnerability (e.g., \"Cross-Site Scripting (XSS)\", \"SQL Injection\", \"OS Command Injection\").\n",
    "Do not provide explanations or code fixes yet. If no vulnerability is found, output \"None\".\n",
    "\"\"\"\n",
    "    \n",
    "    detect_messages = [\n",
    "        {\"role\": \"system\", \"content\": detect_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze this code:\\n\\n{code}\"}\n",
    "    ]\n",
    "    \n",
    "    # æ¨è«–å®Ÿè¡Œï¼ˆçŸ­ãå›ç­”ã•ã›ã‚‹ï¼‰\n",
    "    detected_vulnerability = run_llm_inference(detect_messages, max_tokens=50)\n",
    "    print(f\"â–¶ ç‰¹å®šã•ã‚ŒãŸè„†å¼±æ€§: {detected_vulnerability}\")\n",
    "\n",
    "    if \"None\" in detected_vulnerability:\n",
    "        print(\"è„†å¼±æ€§ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "        return\n",
    "\n",
    "    # --- Step 2: RAGã§é–¢é€£æƒ…å ±ã®å–å¾— ---\n",
    "    print(f\"\\n=== Step 2: ã€Œ{detected_vulnerability}ã€ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢ä¸­... ===\")\n",
    "    \n",
    "    # å…ƒã®è³ªå•æ–‡ã§ã¯ãªãã€ç‰¹å®šã•ã‚ŒãŸã€Œè„†å¼±æ€§åã€ã§æ¤œç´¢ã‚’ã‹ã‘ã‚‹\n",
    "    docs = search(detected_vulnerability, k=k)\n",
    "    \n",
    "    if not docs:\n",
    "        print(\"â€» é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ä¸€èˆ¬çš„ãªçŸ¥è­˜ã§å›ç­”ã—ã¾ã™ã€‚\")\n",
    "        context = \"No external documentation found.\"\n",
    "    else:\n",
    "        context = build_context(docs)\n",
    "        # æ¤œç´¢çµæœã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤ºï¼ˆç¢ºèªç”¨ï¼‰\n",
    "        for i, d in enumerate(docs):\n",
    "            print(f\"  Found [{i+1}]: {d['title']}\")\n",
    "\n",
    "    # --- Step 3: æœ€çµ‚å›ç­”ã®ç”Ÿæˆ (RAGã‚ã‚Š) ---\n",
    "    print(\"\\n=== Step 3: å¯¾ç­–ã¨è§£èª¬ã®ç”Ÿæˆä¸­... ===\\n\")\n",
    "\n",
    "    final_system_prompt = f\"\"\"You are a white hat hacker.\n",
    "The user wants to fix a vulnerability identified as \"{detected_vulnerability}\".\n",
    "Based on the provided \"Reference Information\" (RAG Context) and the source code, provide:\n",
    "1. An explanation of why this code is vulnerable to {detected_vulnerability}.\n",
    "2. Risks associated with it.\n",
    "3. A corrected version of the code or specific mitigation steps.\n",
    "\n",
    "# Guidelines\n",
    "- Answer in JAPANESE (æ—¥æœ¬èª).\n",
    "- Use Markdown format.\n",
    "- Prioritize the methods suggested in the Reference Information.\n",
    "\"\"\"\n",
    "\n",
    "    final_user_message = f\"\"\"\n",
    "# Reference Information (Guidelines)\n",
    "{context}\n",
    "\n",
    "# Source Code\n",
    "{code}\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": final_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": final_user_message}\n",
    "    ]\n",
    "    \n",
    "    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™\n",
    "    text_input = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False,\n",
    "    )\n",
    "\n",
    "    from transformers import TextStreamer\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "    \n",
    "    # æœ€çµ‚ç”Ÿæˆ\n",
    "    model.generate(\n",
    "        **tokenizer(text_input, return_tensors=\"pt\").to(USE_DEVICE),\n",
    "        max_new_tokens=2048,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298eb72e-a17a-42dd-b152-c50055d2b4fc",
   "metadata": {},
   "source": [
    "## infer qwen3 & embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a7459f-d292-4907-a913-c2fe76a24500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a9ddf76-178b-490c-b74a-bd000b6fac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e180aa1-0ed8-4064-b08d-61eaec269dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "<?php\n",
    "// php_d100_roller.php\n",
    "// Simple 100-sided dice roller application (single file)\n",
    "// Usage: Place this file on your web server and open it in a browser.\n",
    "// For local testing: run `php -S localhost:8000` and visit http://localhost:8000/php_d100_roller.php\n",
    "\n",
    "session_start();\n",
    "\n",
    "// Keep roll history in session (max 100 entries)\n",
    "if (!isset($_SESSION['d100_history'])) {\n",
    "    $_SESSION['d100_history'] = [];\n",
    "}\n",
    "\n",
    "$errors = [];\n",
    "$results = [];\n",
    "$total = 0;\n",
    "$count = 1;\n",
    "\n",
    "if ($_SERVER['REQUEST_METHOD'] === 'POST') {\n",
    "    // Get roll count (clamped between 1â€“100)\n",
    "    $count = isset($_POST['count']) ? intval($_POST['count']) : 1;\n",
    "    if ($count < 1) $count = 1;\n",
    "    if ($count > 100) $count = 100;\n",
    "\n",
    "    // Optional label\n",
    "    $label = isset($_POST['label']) ? trim($_POST['label']) : '';\n",
    "\n",
    "    // Perform rolls\n",
    "    for ($i = 0; $i < $count; $i++) {\n",
    "        $roll = random_int(1, 100);\n",
    "        $results[] = $roll;\n",
    "        $total += $roll;\n",
    "    }\n",
    "\n",
    "    // Add to history (newest first)\n",
    "    $entry = [\n",
    "        'time' => date('Y-m-d H:i:s'),\n",
    "        'count' => $count,\n",
    "        'label' => $label,\n",
    "        'results' => $results,\n",
    "        'total' => $total,\n",
    "    ];\n",
    "\n",
    "    array_unshift($_SESSION['d100_history'], $entry);\n",
    "    if (count($_SESSION['d100_history']) > 100) {\n",
    "        $_SESSION['d100_history'] = array_slice($_SESSION['d100_history'], 0, 100);\n",
    "    }\n",
    "}\n",
    "\n",
    "$history = $_SESSION['d100_history'];\n",
    "?>\n",
    "<!doctype html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n",
    "<title>100-sided Dice Roller</title>\n",
    "<style>\n",
    "    body { font-family: system-ui, -apple-system, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial; padding: 20px; }\n",
    "    .box { max-width: 820px; margin: 0 auto; }\n",
    "    input[type=\"number\"] { width: 80px; }\n",
    "    .badge { display:inline-block; padding:6px 10px; margin:4px; border-radius:6px; background:#eee; }\n",
    "    .roll { font-weight:700; }\n",
    "    .history { margin-top:20px; }\n",
    "    .card { padding:12px; border:1px solid #ddd; border-radius:8px; margin-bottom:12px; }\n",
    "    .muted { color:#666; font-size:0.9rem; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"box\">\n",
    "    <h1>100-sided Dice Roller</h1>\n",
    "    <form method=\"post\" action=\"<?php echo htmlspecialchars($_SERVER['PHP_SELF']); ?>\">\n",
    "    <label>Number of rolls (1â€“100): <input type=\"number\" name=\"count\" value=\"<?php echo htmlspecialchars($count); ?>\" min=\"1\" max=\"100\"></label>\n",
    "    &nbsp;\n",
    "    <label>Label (optional): <input type=\"text\" name=\"label\" value=\"\"></label>\n",
    "    &nbsp;\n",
    "    <button type=\"submit\">Roll</button>\n",
    "    </form>\n",
    "\n",
    "    <?php if (!empty($results)): ?>\n",
    "    <div class=\"card\">\n",
    "        <div class=\"muted\">Timestamp: <?php echo htmlspecialchars($entry['time']); ?></div>\n",
    "        <h2>Results</h2>\n",
    "        <div>\n",
    "        <?php foreach ($results as $i => $r): ?>\n",
    "            <span class=\"badge roll\">#<?php echo $i+1; ?>: <?php echo $r; ?></span>\n",
    "        <?php endforeach; ?>\n",
    "        </div>\n",
    "        <p>Total: <strong><?php echo $total; ?></strong> / Average: <strong><?php echo count($results) ? round($total / count($results), 2) : 0; ?></strong></p>\n",
    "        <?php if ($entry['label'] !== ''): ?><p>Label: <?php echo htmlspecialchars($entry['label']); ?></p><?php endif; ?>\n",
    "    </div>\n",
    "    <?php endif; ?>\n",
    "\n",
    "    <div class=\"history\">\n",
    "    <h2>History (last <?php echo count($history); ?> rolls)</h2>\n",
    "    <?php if (empty($history)): ?>\n",
    "        <p class=\"muted\">No rolls yet.</p>\n",
    "    <?php else: ?>\n",
    "        <?php foreach ($history as $idx => $h): ?>\n",
    "        <div class=\"card\">\n",
    "            <div class=\"muted\"><?php echo htmlspecialchars($h['time']); ?> â€” Rolls: <?php echo $h['count']; ?><?php if ($h['label'] !== ''): ?> â€” Label: <?php echo htmlspecialchars($h['label']); ?><?php endif; ?></div>\n",
    "            <div style=\"margin-top:8px;\">\n",
    "            <?php foreach ($h['results'] as $i => $r): ?>\n",
    "                <span class=\"badge\"><?php echo $r; ?></span>\n",
    "            <?php endforeach; ?>\n",
    "            </div>\n",
    "            <p style=\"margin-top:8px;\">Total: <?php echo $h['total']; ?> / Average: <?php echo count($h['results']) ? round($h['total'] / count($h['results']), 2) : 0; ?></p>\n",
    "        </div>\n",
    "        <?php endforeach; ?>\n",
    "    <?php endif; ?>\n",
    "    </div>\n",
    "\n",
    "    <div style=\"margin-top:20px;\" class=\"muted\">\n",
    "    <p>Note: Uses <code>random_int(1, 100)</code> for cryptographically secure random number generation. The session keeps up to 100 history entries.</p>\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3df0383-063f-47e4-9916-bb4ec953a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd483a9-3531-4fac-b254-9361dd1e6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946f4f9d-0889-4a7f-9b81-aadce147fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2ac72c-56bc-468b-b105-e3964d261509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9bfeae2-e909-4dae-b420-9e21790fb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c16a313-afcb-46fb-aca8-180da1896ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eac6656-36c3-49f9-8627-8a09574e16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7) å®Ÿè¡Œ\n",
    "# ----------------------------\n",
    "# è„†å¼±æ€§ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰\n",
    "c = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ä»¥å‰ã®ã‚ˆã†ã«è³ªå•æ–‡(q)ã‚’æ¸¡ã™å¿…è¦ã¯ãªãã€ã‚³ãƒ¼ãƒ‰(c)ã‚’æ¸¡ã—ã¦è¨ºæ–­ã•ã›ã‚‹\n",
    "rag_answer_v2(c, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
