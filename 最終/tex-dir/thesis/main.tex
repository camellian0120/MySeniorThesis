%------------------------------------
%   basic settings
%------------------------------------
\documentclass[12pt,a4paper,oneside]{jsbook}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[dvipdfmx]{graphicx}
\usepackage{url}
\usepackage{here}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[ipaex]{pxchfon}
\usepackage{otf}
\usepackage{listings}
\usepackage[square, numbers]{natbib}
\usepackage{booktabs}
\usepackage{float} 
\usepackage{placeins}
% \usepackage{graphics}
\usepackage[dvipdfmx]{graphicx} % includegraphicsを使うためのパッケージを読み込む
% \usepackage{natbib}

% \bibpunct[:]{(}{)}{,}{a}{}{,}
%------------------------------------
%   listings settings (minted -> listings)
%------------------------------------
\lstset{
  basicstyle=\ttfamily\small,  % Font style
  numbers=left,                % Add line numbers
  numberstyle=\tiny,           % Line number style
  stepnumber=1,                % Line number increment
  frame=single,                % Add a frame around the code
  tabsize=4,                   % Tab size
  breaklines=true,             % Allow line breaking
  keywordstyle=\bfseries,      % Keywords in bold
  commentstyle=\itshape,       % Comments in italics
  stringstyle=\color{red},     % Strings in red
  showspaces=false,            % Do not mark spaces
  showstringspaces=false,      % Do not mark string spaces
  language=Python              % Default language
}

%------------------------------------
%   margin settings
%------------------------------------
\setlength{\topmargin}{-5mm}
\setlength{\fullwidth}{125mm}
\setlength{\textwidth}{\fullwidth}
\setlength{\oddsidemargin}{5mm}
\setlength{\evensidemargin}{\oddsidemargin}
%------------------------------------
%   newtheorems
%------------------------------------
\theoremstyle{plain}
\newtheorem{theorem}{定理}[chapter]
\newtheorem{corollary}[theorem]{系}
\newtheorem{lemma}[theorem]{補題}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{conjecture}[theorem]{予想}
\newtheorem{proposition}[theorem]{命題}
\newtheorem{problem}[theorem]{問題}
\newtheorem{definition}[theorem]{定義}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{claim}{Claim}
\newtheorem{subclaim}{Subclaim}[claim]
\newcommand{\resetclaim}{\setcounter{claim}{0}}
\newtheorem{case}{Case}
\newtheorem{subcase}{Subcase}[case]
\newcommand{\resetcase}{\setcounter{case}{0}}
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}
%------------------------------------
%   display figures
%   #1=width, #2=filename,
%   #3=caption, #4=label
%   \fig{0.8\linewidth}{aaa.pdf}{bbb}{ccc}
%------------------------------------
\renewcommand{\figurename}{図.}
\newcommand{\fig}[4]{
\begin{figure}[H]
\centering
\includegraphics[width=#1]{#2}
\caption{#3}
\label{#4}
\end{figure}
}
\newcommand{\figg}[4]{
\begin{figure*}[h!t]
\centering
\includegraphics[width=#1]{#2}
\caption{#3}
\label{#4}
\end{figure*}
}
%------------------------------------
%   setting of algorithms
%------------------------------------
\renewcommand{\algorithmicrequire}{\textbf{条件:}}
\renewcommand{\algorithmicensure}{\textbf{実行結果:}}
\algrenewcommand\algorithmicdo{}
\algrenewcommand\algorithmicthen{}
%------------------------------------
%   other renewcommands and newcommands
%------------------------------------
\renewcommand{\proofname}{\bf 証明.}
%------------------------------------
%   Title & Authors
%------------------------------------
\title{
卒業論文\\[1.5cm]
LLMによるソフトウェア脆弱性の検出\\[6cm]
}
\author{高知大学 理工学部 情報科学科\\[0.5cm]
B223R030P 横川武典}
\date{2025年度}

%------------------------------------
\begin{document}
%------------------------------------
%タイトルページの出力
\maketitle
%目次の作成・出力
\tableofcontents

%----------------------------------------------------------------------------
%   Chapter 1
\chapter{はじめに}
\label{chapter_1}
%----------------------------------------------------------------------------
\section{背景}
%------------------------------------
近年，Webアプリケーションの開発現場では，
短期間での実装や頻繁な機能追加が求められる一方で，
セキュリティ対策が十分に検討されないまま
運用される事例も少なくない．
特に，学習用途や小規模なWebアプリケーションにおいては，
入力値検証やセッション管理といった
基本的なセキュリティ対策が不十分な状態で
公開されるケースが散見される．
このような状況を背景として，
Webアプリケーションに内在する脆弱性を
早期に検出し，
開発者が理解・修正しやすい形で提示する技術の重要性が
高まっている．

これらの脆弱性を効率的に検出する手法の一つとして，
近年，大規模言語モデル（Large Language Model: LLM）の活用が
注目されている．
LLMはプログラムコードを自然言語的な文脈として扱うことが可能であり，
従来のルールベースやシグネチャベースの解析では対応が困難であった
多様な実装スタイルや記述パターンに対しても，
一定の柔軟性を持って対応できる可能性がある．
そのため，静的解析ツールを補完する手段として，
LLMを用いた脆弱性検出やセキュリティ支援への応用が期待されている．

一方で，LLMによる脆弱性検出は，
必ずしも常に高い精度を保証するものではなく，
誤検知や検出漏れが発生する可能性も指摘されている．
特に，Webアプリケーションで用いられる各種言語を対象とした
LLMの脆弱性検出性能については，
モデルの学習状態や知識付与の方法，
さらには外部情報の利用有無によって
挙動が大きく異なることが想定される．
しかし，これらの要因が
検出性能や誤検知傾向にどのような影響を与えるのかについて，
体系的に比較・評価した研究は十分とは言えない．

Webアプリケーションで広く利用されているPHPは，
記述の自由度が高く，
同一の機能であっても実装方法に大きなばらつきが生じやすい．
このため，
XSS，CSRF，セッション管理の不備といった
言語・フレームワーク特有の脆弱性が発生しやすく，
自動解析による正確な検出は容易ではない．
このことは，
LLMを用いた手法においても，
単純な知識の追加や学習のみでは
検出精度の向上が保証されない可能性を示唆している．

以上の背景を踏まえ，
本研究では，
Webアプリケーションに対する脆弱性検出手法の高度化を目的として，
大規模言語モデルを用いたセキュリティ応用に着目する．
具体的には，
PHPプログラムを対象として，
素のLLM，Fine-Tuningを施したLLM，
および外部知識を参照するRAG構成LLMを比較し，
それぞれの構成が
脆弱性検出性能や誤検知の発生傾向，
ならびに提示される修正案の内容に
どのような差異をもたらすのかを明らかにする．
これにより，
LLMを用いた脆弱性検出手法の有効性と限界を整理し，
今後のセキュリティ支援への活用に向けた
知見を得ることを目的とする．

%----------------------------------------------------------------------------
\chapter{関連研究}
\label{chapter_2}
%----------------------------------------------------------------------------
本章では，本研究で提案する手法の妥当性を示すため，
既存のソフトウェア脆弱性検出手法および
大規模言語モデル（LLM）を用いた関連研究を整理し，
それらの課題を明確化する．
まず，従来のソフトウェア脆弱性検出手法について概観し，
その限界を明らかにする．
次に，大規模言語モデル（LLM）の概要と，
セキュリティ分野への応用例について述べる．
その後，LLMを用いた脆弱性検出に関する先行研究を整理し，
Retrieval-Augmented Generation（RAG）や
ファインチューニングといった代表的手法について説明する．
最後に，評価指標および既存研究の課題をまとめ，
本研究の位置づけを明確にする．


%------------------------------------
\section{従来のソフトウェア脆弱性検出}
%------------------------------------
ソフトウェアの脆弱性検出手法は，
大きく静的解析と動的解析に分類される \cite{chess_mcgraw}.
静的解析は，プログラムを実行せずにソースコードやバイナリを解析する手法であり，
代表的なものとしてデータフロー解析やルールベース解析が挙げられる．
静的解析の代表例としては，Lint系ツールや商用のSAST
（Static Application Security Testing）ツールなどが広く利用されている．
Lint系ツールは，
主にコーディング規約や単純な構文規則に基づいて
潜在的な不具合を検出する静的解析ツールであり，
SASTツールは，
より高度なデータフロー解析や制御フロー解析を用いて
脆弱性の検出を行う．
静的解析は網羅的な検査が可能である一方，実行時の文脈を考慮できないため
誤検知（False Positive）が多いという課題がある．

一方，動的解析はプログラムを実際に実行し，
その挙動を監視することで脆弱性を検出する手法である．
ファジングや実行時モニタリングなどが代表例であり，
AFL（American Fuzzy Lop）に代表されるファジング手法は，実際に悪用可能な脆弱性を検出できる利点を有する．
しかし，実行パスに依存するため，すべての脆弱性を網羅的に検出することは困難である．

近年では，静的解析と動的解析を組み合わせた
ハイブリッド解析手法も提案されており，
両者の欠点を補完するアプローチとして注目されている．
しかし，解析コストの増大や運用の複雑化といった課題も残されている．

これらの従来手法は，既知の脆弱性パターンに基づく検出には有効である一方で，
コードの文脈理解や実装意図の推定といった点に限界がある．
このような課題を背景として，
自然言語およびソースコードの文脈を同時に扱える
LLMを活用した手法が注目されている．

%------------------------------------
\section{Large Language Model（LLM）}
%------------------------------------
% 典型的なTransformersの図式をいれる
% 入力などに関してもう少し丁寧に書いてもいい？
% feed-forward層でReLU関数を使用することで、始めて行列でなくなる/線形でなくなる？ことも示す
%------------------------------------
大規模言語モデル（Large Language Model: LLM）は，大量のテキストデータを用いて事前学習された
深層学習モデルであり，自然言語処理分野において高い性能を示している．
近年では，Transformer構造を基盤としたモデルが主流となっており，
自己注意機構によって文脈情報を効果的に捉えることが可能である．\cite{transformers}

このようなTransformerベースのLLMにおいて中心的な役割を果たすのが，
自己注意機構である．自己注意機構は，
入力系列 $\mathbf{x} = (x_1, x_2, \dots, x_n)$ に基づいて，
各出力 $\mathbf{y} = (y_1, y_2, \dots, y_n)$ を生成する際に，
入力系列中の重要な要素に重みを付けて参照する仕組みである．

Transformer は，入力系列を固定長のベクトル列として表現し，
それらを複数層にわたって変換するエンコーダ・デコーダ構造
（あるいはデコーダ単体構造）を持つ．
入力系列を $n$ 個のトークンからなる行列
$\mathbf{x} \in \mathbb{R}^{n \times d_{\mathrm{model}}}$
として表すと，各層において線形変換を用いて
クエリ（query），キー（key），バリュー（value）を以下のように生成する．
\begin{equation}
\mathbf{q} = \mathbf{x}\mathbf{W}_q,\quad
\mathbf{k} = \mathbf{x}\mathbf{W}_k,\quad
\mathbf{v} = \mathbf{x}\mathbf{W}_v
\end{equation}
ここで，
$\mathbf{W}_q,\mathbf{W}_k,\mathbf{W}_v \in \mathbb{R}^{d_{\mathrm{model}} \times d_k}$
は学習可能な重み行列であり，
$\mathbf{q},\mathbf{k},\mathbf{v}$ は
それぞれクエリ，キー，バリューの行列表現である．

自己注意機構では，$\mathbf{q}$ と $\mathbf{k}$ の内積に基づいて
トークン間の関連度を算出し，
以下の式によって注意重み付き和を計算する．\cite{transformers}
\begin{equation}
\mathrm{Attention}(\mathbf{q}, \mathbf{k}, \mathbf{v})
= \mathrm{softmax}\left(\frac{\mathbf{q}\mathbf{k}^{\top}}{\sqrt{d_k}}\right)\mathbf{v}
\end{equation}
ここで，$d_k$ はキーの次元数であり，
内積値の分散を抑制するためのスケーリング項として導入される．
この計算により，系列中の任意のトークンが
他のすべてのトークンを参照した表現を同時に得ることができ，
距離に依存しない長距離依存関係の学習が可能となる．

さらに，Transformer ではこの注意機構を複数並列に配置した
マルチヘッドアテンション（Multi-Head Attention）を用いる．\cite{transformers}
$h$ 個のヘッドを用いる場合，
各ヘッド $i$ に対して独立した重み行列を用いて注意計算を行い，
その出力を連結して線形変換することで，
以下のように表される．
\begin{equation}
\mathrm{head}_i
= \mathrm{Attention}
(\mathbf{q}\mathbf{W}_i^q,\,
 \mathbf{k}\mathbf{W}_i^k,\,
 \mathbf{v}\mathbf{W}_i^v)
\end{equation}
\begin{equation}
\mathrm{MultiHead}(\mathbf{q}, \mathbf{k}, \mathbf{v})
= \mathrm{Concat}
(\mathrm{head}_1,\dots,\mathrm{head}_h)\mathbf{W}^O
\end{equation}
この構造により，異なる表現部分空間における依存関係を
同時に捉えることが可能となり，
モデルの表現能力が大きく向上する．
また，自己注意機構は系列全体を一括で処理できるため，
RNN 系モデルと比較して並列計算に適しており，
大規模データを用いた学習を効率的に行えるという利点を持つ．

LLM における出力生成は，
Transformer 層を通じて得られた最終層の隠れ状態
$\mathbf{H} \in \mathbb{R}^{n \times d_{\mathrm{model}}}$
に対し，
語彙サイズ $|V|$ への線形変換と softmax 関数を適用することで行われる．
具体的には，次トークン $y_t$ の確率分布は以下のように定義される．
\begin{equation}
P(y_t \mid y_{<t})
= \mathrm{softmax}(\mathbf{H}_t \mathbf{W}_{\mathrm{out}} + \mathbf{b})
\end{equation}
ここで，
$\mathbf{W}_{\mathrm{out}} \in \mathbb{R}^{d_{\mathrm{model}} \times |V|}$
は出力重み行列，
$\mathbf{b}$ はバイアス項である．
LLM はこの確率分布に基づき，
最大確率のトークンを選択する，
あるいはサンプリングを行うことで，
逐次的に出力文を生成する．

近年のLLMは自然言語だけでなくソースコードを含むデータで学習されており，
プログラムの構文構造や意味的関係を一定程度理解できることが報告されている．
CodeBERT\cite{codebert}やGraphCodeBERT\cite{graphcodebert}などのLLMは，
コードと自然言語の対応関係を学習することで，
プログラム理解タスクにおいて高い性能を示している\cite{llminsoftwaresecurity}．

このような特性から，LLMは単なる自然言語処理モデルにとどまらず，
ソフトウェア解析やセキュリティ分野への応用が期待されている．
次節では，セキュリティ分野におけるLLMの具体的な活用事例について述べる．

%------------------------------------
\section{セキュリティ分野とLLMの関連性および応用}
%------------------------------------
近年，LLMは自然言語処理分野にとどまらず，
サイバーセキュリティ分野においても幅広い応用が進んでいる．
LLMが脆弱性検出，マルウェア解析，ネットワーク侵入検知，フィッシング検出など，
多様なサイバーセキュリティタスクに適用されていることが報告されている\cite{llmcyber}．
このことから，LLMは特定用途に限定された技術ではなく，
セキュリティ分野全体に横断的に利用可能な基盤技術として位置づけられている．

一方で，LLMが生成した成果物そのものが新たなセキュリティリスクとなり得る点も指摘されている．
一部の研究では，LLMが生成したWeb言語向けJavaScriptコードを分析した結果，
24.5\%のコードにおいてセッションタイムアウトの欠如やHTTPセキュリティヘッダーの不足といった
不適切な実装が確認されたと報告されている\cite{hiddenriskllmgeneratedweb}．
この知見は，LLMの出力結果を無条件に信頼することの危険性を示している．

このように，セキュリティ分野におけるLLMの活用は，
防御・検出を支援する側面と，
新たな脆弱性を生み出す可能性という
両義的な性質を有している．
そのため，LLMとセキュリティの関係を論じる上では，
応用可能性だけでなく，
生成結果の検証やリスク評価を含めた
包括的な視点が不可欠である．

%------------------------------------
\section{LLMを用いた脆弱性検出の先行研究}
%------------------------------------
LLMを用いた脆弱性検出に関する先行研究では，
主にCやC++といった低レベル言語を対象としたものが多い．
これらの研究では，ソースコードを入力とし，
脆弱性の有無や種類を分類問題として扱う手法が主に提案されている．
特に，バッファオーバーフローやメモリ破壊といった脆弱性を対象とし，
LLMがコードの文脈情報を活用することで
従来手法よりも高い検出性能を示す可能性が報告されている．

近年では，脆弱性情報が頻繁に更新される
セキュリティ分野の特性を踏まえ，
外部知識ベースを活用する手法を組み合わせた研究も提案されている．
これらの研究では，CWE（Common Weakness Enumeration）や
CVE（Common Vulnerabilities and Exposures）といった
既存の脆弱性知識ベースを参照することで，
脆弱性検出やその説明の精度向上を図っている．
例えば，CVE-LLMでは，
既存のCVEデータとセキュリティオントロジーを統合し，
LLMが脆弱性の背景や影響範囲を考慮しながら
自動的に脆弱性評価を行う枠組みが提案されている \cite{cve-llm}．
このような外部知識の導入は，
コード単体の解析にとどまらず，
既知の脆弱性知識を踏まえた
より包括的な脆弱性理解を可能にする点で有効であると考えられる．

%------------------------------------
\section{埋め込みモデルと類似度検索}
%------------------------------------
本節では，
後述するRetrieval-Augmented Generation（RAG）構成における
検索機構の理解を目的として，
埋め込みモデルと類似度検索の基礎について説明する．
特に，
LLM への入力 $x$ に基づいて
関連する文書 $z$ を取得する過程を明確にする．

近年，情報検索や質問応答，および
Retrieval-Augmented Generation（RAG）といった手法において，
テキストを数値ベクトルとして表現する
埋め込み（Embedding）モデルが広く利用されている．
埋め込みモデルは，
入力されたテキスト $x$ を高次元の実数ベクトル空間へ写像することで，
意味的な近さを数値的に比較可能にする．
このような分散表現に基づく意味検索は，
Sentence-BERT（SBERT）\cite{reimers2019sentencebert}
以降，多くの応用分野で用いられている．

一般に，埋め込みモデルは，
文や段落，あるいはソースコードといった
可変長の入力 $x$ を，
$d$ 次元のベクトル
$\mathbf{v} \in \mathbb{R}^d$
へ変換する写像
$f(\cdot)$ として定式化できる．
すなわち，
\begin{equation}
\mathbf{v} = f(x)
\end{equation}
である．
このとき，
意味的に類似したテキスト同士は，
ベクトル空間上でも近接するように学習される．

埋め込みベクトル間の類似度を測る指標としては，
コサイン類似度（Cosine Similarity）が一般的に用いられる．
二つのベクトル
$\mathbf{v}_1, \mathbf{v}_2 \in \mathbb{R}^d$
に対するコサイン類似度は，
次式で定義される．
\begin{equation}
\mathrm{sim}(\mathbf{v}_1, \mathbf{v}_2)
=
\frac{\mathbf{v}_1 \cdot \mathbf{v}_2}
{\lVert \mathbf{v}_1 \rVert \, \lVert \mathbf{v}_2 \rVert}
\end{equation}
この値は $-1$ から $1$ の範囲を取り，
値が大きいほど
二つのテキストが意味的に類似していることを示す．

類似度検索では，
あらかじめ知識ベース内の文書集合
$\{z_1, z_2, \dots, z_N\}$
を埋め込みモデルによってベクトル化しておく．
その上で，
入力 $x$ に対応するクエリ埋め込み
$\mathbf{v}_x = f(x)$
と，各文書 $z_i$ の埋め込み
$\mathbf{v}_{z_i} = f(z_i)$
との類似度を計算し，
類似度の高い上位 $k$ 件の文書を
関連文書集合 $z$ として取得する．
このような密ベクトル検索の枠組みは，
Dense Passage Retrieval（DPR）\cite{karpukhin2020dense}
などにより体系化され，
RAGにおける検索機構の基盤技術となっている．

この類似度検索の過程は，
RAG において定義される
入力 $x$ に対する文書 $z$ の条件付き確率
$p(z \mid x)$
に対応する処理と解釈できる．
すなわち，
埋め込みモデル $f(\cdot)$ により
$x$ および各文書 $z_i$ をベクトル空間に写像し，
類似度指標 $\mathrm{sim}(\mathbf{v}_x, \mathbf{v}_{z_i})$
に基づいて文書を順位付けする操作は，
確率的には
「入力 $x$ が与えられたときに，
どの文書 $z$ が関連文書として選択されやすいか」
を表す分布 $p(z \mid x)$ を近似的に与えるものとみなせる．

実際の実装においては，
$p(z \mid x)$ を明示的な確率分布として正規化する代わりに，
類似度スコアに基づく上位 $k$ 件の文書を
決定論的に選択する手法が一般的に用いられる．
このような top-$k$ 類似度検索は，
RAG の確率モデルを実用的に近似する方法として，
多くのシステムで採用されている．

また，近年では多言語対応かつ汎用的な意味表現を獲得可能な
埋め込みモデルが多数提案されている．
その一例として，
e5-multilingual\cite{e5} は，
検索タスク向けに弱教師あり対照学習を用いて事前学習されたモデルであり，
入力 $x$ と文書 $z$ の意味的対応関係を
高精度に捉えることが可能である．
自然言語を主対象としつつも，
技術文書やプログラムコードといった
専門的テキストに対しても
一定の有効性が報告されている．

本研究においては，
RAG構成における検索段階において
埋め込みモデルを用いた類似度検索を採用する．
具体的には，
解析対象のPHPコードまたはその一部を入力 $x$ とし，
脆弱性に関する知識ベース内の文書群から
$x$ に意味的に類似した文書 $z$ を検索することで，
LLM が参照すべき関連情報を取得する．
このように，
埋め込みモデルと類似度検索は，
RAGにおける情報検索機構の基盤技術として
重要な役割を果たしている．

%------------------------------------
\section{Retrieval-Augmented Generation（RAG）}
%------------------------------------
Retrieval-Augmented Generation（RAG）は，
LLM による生成時に，
入力 $x$ に基づいて外部の知識ベースから
関連文書 $z$ を検索し，
それらを追加の入力として用いることで，
生成結果 $y$ の品質向上を図る手法である．
この枠組みにより，
モデル内部のパラメータに含まれない知識を
動的に参照することが可能となり，
事実性の向上やハルシネーションの抑制が期待されている\cite{rag}．

RAGは，
生成結果 $y$ を，
入力 $x$ および検索された文書集合 $z$ に条件づけた確率として
以下のように定式化できる．
\begin{equation}
p(y \mid x) = \sum_{z \in \mathcal{Z}} p(y \mid x, z)\, p(z \mid x)
\end{equation}
ここで，
$p(z \mid x)$ は，
入力 $x$ に基づいて
関連文書 $z$ を検索する確率分布を表し，
埋め込みモデルと類似度検索によって実現される．
また，
$p(y \mid x, z)$ は，
検索結果 $z$ を条件として
出力 $y$ を生成する
言語モデルの確率分布を表す．

このようにRAGでは，
入力 $x$ に対して
まず関連情報 $z$ を取得し，
それを条件として出力 $y$ を生成するという
二段階の処理が行われる．
この確率的枠組みは，
Retrieval-Augmented Generation の原論文において
提案・定式化されたモデルに基づいている\cite{rag}．

セキュリティ分野においては，
CWEやCVEといった脆弱性知識ベースを
文書集合 $z$ としてRAGに組み込むことで，
入力されたコード $x$ に対する
脆弱性の検出や説明生成の精度を
向上させる試みが報告されている．
特に，
コード片と既知の脆弱性パターンとの対応関係を
明示的に参照できる点は，
モデルの解釈性向上という観点からも有用である．

一方で，
RAGの性能は検索される文書 $z$ の品質に大きく依存しており，
入力 $x$ と無関係な文書が取得された場合には，
生成結果 $y$ の誤りやノイズの増加につながる可能性がある．
そのため，
検索手法および知識ベースの設計は，
RAG全体の性能を左右する重要な要素となる．

%------------------------------------
\section{ファインチューニング（Fine-Tuning）}
%------------------------------------
ファインチューニング（Fine-Tuning）とは，
大規模コーパスを用いて事前学習されたモデルに対し，
特定タスクのデータを用いて追加学習を行うことで，
タスク固有の特徴に適応させる手法である．
この考え方は，深層ニューラルネットワークにおける
表現学習の枠組みに基づいており，
事前学習によって獲得された汎用的な中間表現を，
下流タスクに最適化する過程として位置づけられる．

Hintonらは，自己符号化器を用いた研究において，
高次元データから有用な低次元表現を事前に学習し，
その後のタスク適応によって性能が向上することを示している
\cite{hinton2006reducing}．
このような段階的学習の考え方は，
現在のLLMにおける事前学習とファインチューニングの関係と
本質的に共通している．

ファインチューニングの考え方は，
特に畳み込みニューラルネットワーク（CNN）において広く用いられてきた．
画像認識の分野では，ImageNet Large Scale Visual Recognition Challenge（ILSVRC）をはじめとする
大規模データセットで事前学習された CNN モデルが，
多くの下流タスクに対する転移学習の基盤モデルとして活用されている．
例えば，医用画像解析を対象とした研究においては，
ImageNet で事前学習された深層 CNN をファインチューニングすることで，
同一タスクにスクラッチから学習した CNN と比較して高い性能を示した．
このように，事前学習された CNN モデルの重みを初期値として用い，
タスク固有の学習データでパラメータを再調整する手法が
ファインチューニングとして有効であることが示されている\cite{uesaka2017multi_view}．

この考え方は，ソフトウェア脆弱性検出といった実応用分野においても取り入れられている．
例えば，脆弱なコードと安全なコードを用いた教師あり学習により，
特定の脆弱性パターンに対する識別性能が向上することが報告されている
\cite{devigneffectivesearchvulnerability}．
一方で，ファインチューニングには
大量のラベル付きデータを必要とする点や，
学習データに強く依存したバイアスが生じやすい点などの課題も存在し，
汎化性能の低下を招く可能性が指摘されている．

さらに，脆弱性検出を目的としたファインチューニングにおいては，
学習時点での知識が固定される点も課題となる．
CVEに代表される脆弱性情報は日々更新されており，
新たな攻撃手法や脆弱性種別が継続的に追加される．
ファインチューニング済みモデルは，
学習データに含まれない新規脆弱性に対しては対応が困難であり，
時間の経過とともに知識の陳腐化が生じる可能性がある．
このことは，
セキュリティ分野において
ファインチューニング単体を長期間運用することの
難しさを示している．

以上の課題から，
ファインチューニングは有効な手法である一方，
知識更新の柔軟性や運用性の観点では
制約が存在することが分かる．

%------------------------------------
\section{評価指標およびベンチマーク}
%------------------------------------
脆弱性検出手法の評価には，
Precision，Recall，F1-scoreといった指標が一般的に用いられる．
これらの指標は，検出結果を
真陽性（True Positive: TP），
偽陽性（False Positive: FP），
偽陰性（False Negative: FN）
に基づいて定義される．

Precisionは，検出された脆弱性のうち，
実際に正しいものの割合を表す指標であり，
次式で定義される．
\begin{equation}
\mathrm{Precision} = \frac{TP}{TP + FP}
\end{equation}
Precisionが低い場合，誤検知が多く発生していることを意味し，
実運用においては解析コストの増大や運用負荷の増加につながる．
そのため，脆弱性検出タスクではPrecisionの高さが重要視される．

一方，Recallは，実際に存在する脆弱性のうち，
正しく検出できた割合を表す指標であり，
次式で定義される．
\begin{equation}
\mathrm{Recall} = \frac{TP}{TP + FN}
\end{equation}
Recallが低い場合，脆弱性の見逃しが多いことを意味し，
セキュリティ上の重大なリスクにつながる可能性がある．
そのため，PrecisionだけでなくRecallとのバランスが重要である．

F1-scoreは，PrecisionとRecallの調和平均として定義され，
両者のバランスを総合的に評価する指標である．
\begin{equation}
\mathrm{F1\text{-}score} = 
\frac{2 \cdot \mathrm{Precision} \cdot \mathrm{Recall}}
{\mathrm{Precision} + \mathrm{Recall}}
\end{equation}
F1-scoreは，PrecisionとRecallのいずれか一方が
極端に低い場合に値が低下するため，
両指標を同時に考慮した評価が可能となる．

さらに，本研究では，
分類器のしきい値に依存しない評価指標として，
ROC曲線およびAUC（Area Under the ROC Curve）も用いる．
ROC曲線は，
偽陽性率（False Positive Rate: FPR）を横軸，
真陽性率（True Positive Rate: TPR）を縦軸として，
分類しきい値を変化させた際の性能を可視化したものである．
ここで，
\begin{equation}
\mathrm{TPR} = \frac{TP}{TP + FN}, \quad
\mathrm{FPR} = \frac{FP}{FP + TN}
\end{equation}
で定義される．

AUCは，
ROC曲線の下側の面積として定義され，
分類器が正例と負例をどの程度正しく識別できているかを
一つの値で表す指標である．
AUCの値は $0.5$ から $1.0$ の範囲を取り，
$1.0$ に近いほど識別性能が高いことを示す．
AUCは，
クラスの分布や分類しきい値の設定に依存しにくいため，
脆弱性検出のように
クラス不均衡が大きいタスクにおいても
比較的安定した評価が可能である．

なお，単一の評価指標のみで手法の有効性を判断することは難しく，
複数の指標を組み合わせて総合的に評価する必要がある．
特に，脆弱性検出タスクでは，
Accuracyのみでは性能を適切に評価できない場合が多く，
Precision，Recall，F1-scoreに加えて，
AUCを併用することが有効である．

本研究においても，
PHPプログラムを対象とした脆弱性検出性能を評価するため，
これらの指標を用いて定量的な比較を行う．
特に，
素のLLM，Fine-Tuningを施したLLM，
およびRAG構成LLMという
異なるモデル構成間の性能差を明確にすることを目的とし，
単一の指標に依存せず，
Precision，Recall，F1-score，AUCを併用した
多面的な評価を行う．

これにより，
各手法が
誤検知を抑制する能力，
脆弱性を見逃さずに検出する能力，
ならびに
分類全体としての識別性能において
どのような特徴を持つのかを
体系的に比較可能とする．

%------------------------------------
\section{既存研究の課題と本研究の位置づけ}
%------------------------------------
以上のように，LLMを用いた脆弱性検出に関する研究は一定の成果を上げているが，
その多くはC/C++を対象とし，
バッファオーバーフローなどのメモリ管理に起因する脆弱性の検出に焦点を当てている．
この背景には，既存のベンチマークデータセットや先行研究の多くが，
低レベル言語を対象として構築されてきたという事情がある．

一方で，Web言語として広く利用されているPHPなどにおいては，
クロスサイトスクリプティング（XSS）やSQLインジェクションといった，
言語仕様や実行環境に依存した脆弱性が多数存在するにもかかわらず，
LLMを用いた包括的に扱った研究は依然として限定的である．
また，既存研究では特定の脆弱性クラスに偏った評価が多く，
検出可能な脆弱性の多様性という観点での分析も限定的である．

そこで本研究では，
Web言語であるPHPを対象としたLLMによる脆弱性検出の可能性を検討する．
さらに，メモリ関連脆弱性に限定せず，
XSSやCSRF，セッション管理の不備といった
Webアプリケーション特有の複数の脆弱性種別を対象とすることで，
LLMが多様な脆弱性パターンを
どの程度識別可能であるかを明らかにすることを目的とする．

加えて，
LLMの構成手法の違いに着目し，
素のLLM，
ファインチューニングを施したLLM，
および外部知識を参照するRAG構成LLMを
同一条件下で比較・評価する．
これにより，
モデルの学習状態や知識付与方法の違いが，
脆弱性検出性能や誤検知傾向，
提示される修正案の内容に
どのような影響を及ぼすのかを体系的に分析する．

Web言語特有の脆弱性を対象とし，
複数のLLM構成を統一的な評価指標の下で比較する点において，
本研究は既存研究とは異なる位置づけを持つ．

%----------------------------------------------------------------------------
\chapter{提案手法}
\label{chapter_3}
%----------------------------------------------------------------------------
本章では，本研究において提案する
LLMを用いたPHPプログラムの脆弱性検出手法について述べる．
ここでの提案とは，
特定の新規アルゴリズムを導入するものではなく，
LLMの構成方法の違いが
脆弱性検出性能に与える影響を明らかにするための
統一的な評価枠組みを設計・構築する点にある．

PHPは，
Webアプリケーション開発において長年広く利用されてきた
サーバサイドスクリプト言語であり，
現在も多くの既存システムや中小規模Webサービスにおいて
重要な役割を担っている．
一方で，
動的型付けや簡潔な記述を特徴とする言語仕様，
および多様な実装慣習に起因して，
XSSやSQLインジェクションといった
Web特有の脆弱性が発生しやすいという課題を抱えている．
これらの脆弱性は，
入力値の流れや実行時の文脈に依存して発生する場合が多く，
単純なパターンマッチングや
静的なルールに基づく検出手法では，
十分に対応できないことが指摘されている．

第2章で整理した関連研究より，
既存の脆弱性検出手法には
対象言語や脆弱性種別の偏りが存在することが明らかとなった．
特に，言語仕様や実装慣習の違いを考慮した分析が十分に行われていない点は，
PHPのような柔軟な記述が可能な言語において，
脆弱性検出を困難にする要因の一つである．

このような背景を踏まえ，
本研究では
Webアプリケーションで広く利用されているPHPを対象とし，
LLMのコード理解能力を活用した
脆弱性検出手法を提案する．
LLMは，
プログラムコードを文脈情報を含む構造として扱うことが可能であり，
従来手法では見落とされやすい
言語仕様や実装文脈に依存した脆弱性に対しても，
有効に機能する可能性がある．
特に，
言語仕様や実行文脈に依存する脆弱性に対して，
LLMがどの程度有効に機能するかを明らかにすることを目的とする．

本章ではまず，
本研究の概要および設計方針を示し，
続いて対象とする脆弱性および分析対象について説明する．
その後，
提案手法の全体構成，
LLMによるコード解析手法，
知識ベースの活用方法，
ならびに出力形式と判定方法について詳述し，
最後に実装上の留意点について述べる．

%------------------------------------
\section{本研究の概要}
%------------------------------------
本研究の目的は，
Webアプリケーション開発で広く利用されているPHPを対象として，
LLMを用いた脆弱性検出手法を構築し，
その有効性を検証することである．
特に，
LLMの構成方法の違いに着目し，
素のLLM，Fine-Tuning済みLLM，
およびRAG構成LLMを
統一的な条件下で比較・評価することで，
各構成の特性を明らかにすることを目的とする．

本研究では，
LLMの活用形態として以下の三つの構成を採用する．
\begin{itemize}
  \item 事前学習済み言語モデルをそのまま用いる構成（以下，素のLLM）
  \item 脆弱性データセットを用いてFine-Tuningを行った構成
  \item 素のLLMに対して知識ベースを接続したRAG構成
\end{itemize}
これら三構成を同一条件下で比較することで，
学習による知識獲得と，
外部知識の参照という
異なるアプローチの特性を明らかにする．

また，本研究では検出結果を
「脆弱性の種類」「想定されるリスク」「修正案」
といった形式で出力することで，
開発者が結果を理解しやすく，
実際の修正作業に活用しやすいことを重視している．
これにより，LLMを単なる分類器として用いるのではなく，
脆弱性分析を支援するツールとして位置付ける点に
本研究の特徴がある．

%------------------------------------
\section{設計方針}
%------------------------------------
第2章で述べた関連研究の整理より，
従来の脆弱性検出手法には
対象言語の偏りや，
検出対象の限定性といった課題が存在することが明らかとなった．
本研究では，これらの課題に対応するため，
以下の設計方針に基づいて提案手法を構築する．

まず，対象言語としてPHPを採用し，
Webアプリケーションにおいて頻発する
入力処理や外部データの取り扱いに起因する脆弱性を
重点的に扱うこととした．
これにより，
Web言語特有の脆弱性に対する
検出性能を評価可能な枠組みを構築する．

次に，解析手法としてLLMを中核に据え，
静的解析やルールベース手法では対応が困難であった
多様なコーディングスタイルや
文脈依存の脆弱性に対応することを目指す．

さらに，本研究では
LLMの活用形態の違いに着目し，
素のLLM，Fine-Tuning済みLLM，RAG構成の
三つの構成を比較対象とする．
この際，入力コード，プロンプト形式，
および出力形式を統一することで，
モデル構成以外の要因が
検出結果に影響を与えないよう設計した．
このように，
評価条件を厳密に統一した比較枠組みを構築することで，
LLMの構成方法そのものが
脆弱性検出性能に与える影響を
客観的に評価可能としている．

%------------------------------------
\section{対象脆弱性および分析対象}
%------------------------------------
本節では，本研究で対象とする脆弱性の種類および
分析対象とするプログラムの範囲について説明する．

%------------------------------------
\subsection{対象脆弱性}
%------------------------------------
本研究では，Webアプリケーションにおいて
発生頻度が高く，
かつ実害につながりやすい脆弱性を主な対象とする．
具体的には，以下の脆弱性を扱う．
\begin{itemize}
  \item クロスサイトスクリプティング（XSS）
  \item クロスサイトリクエストフォージェリ（CSRF）
  \item セッション管理の不備（セッション固定化，ハイジャック等）
\end{itemize}

これらの脆弱性は，
実運用されているWebアプリケーションにおいて
比較的高い頻度で報告されており，
情報漏洩や不正操作，なりすましといった
深刻な被害につながる可能性が高い点で共通している．
そのため，
脆弱性検出手法の有効性を評価する対象として
実用的な重要性が高いと考えられる．

また，これらの脆弱性は，
ユーザ入力の取得から出力に至る処理の流れや，
セッション状態といった実行時の文脈に強く依存して発生する場合が多い．
このため，
単純なパターンマッチングや
静的なルールに基づく従来手法では，
検出が困難となるケースが少なくない．

さらに，PHPは，
HTML生成とアプリケーションロジックが混在しやすい言語仕様や，
セッション管理の実装が開発者に委ねられる点を特徴としており，
XSSやCSRF，セッション管理に関する脆弱性が
実装文脈に依存して生じやすい．
このような言語特性を考慮すると，
コードの構造や処理意図を文脈情報として捉える能力を有する
LLMを用いた解析手法は，
これらの脆弱性に対して有効に機能する可能性がある．

以上の理由から，本研究では，
PHPの言語特性および脆弱性の発生要因との関係が明確であり，
かつLLMのコード理解能力を評価する上で適切な対象として，
XSS，CSRF，およびセッション管理の不備を
分析対象の脆弱性として選定した．

%------------------------------------
\subsection{分析対象プログラム}
%------------------------------------
分析対象としては，
PHPで記述されたサーバサイドプログラムを対象とする．
関数定義，条件分岐，
データベースアクセス，
外部入力処理などを解析対象とし，
フレームワーク固有の機構や
実行環境依存の設定については考慮しない．

%------------------------------------
\section{提案手法の全体構成}
%------------------------------------
提案手法の全体構成を図\ref{fig:system_overview}に示す．
本手法は，
入力となるPHPソースコード，
LLMによる解析処理，
および検出結果の出力から構成される．

解析対象のPHPコードは，
ファイル単位で前処理を施した後，
LLMへの入力として与えられる．
LLMはコードの構造や処理内容を解析し，
脆弱性の有無および種類を判定する．

RAG構成では，
解析対象コードに関連する脆弱性知識を
知識ベースから検索し，
その内容をプロンプトに付加した上で
LLMによる解析を行う．
これにより，
LLMはコード単体の情報だけでなく，
外部知識を参照した判断を行うことが可能となる．

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.2\linewidth]{./fig_system_overview.jpg}
  \caption{提案手法の全体構成}
  \label{fig:system_overview}
\end{figure}

%------------------------------------
\section{LLMによるコード解析手法}
%------------------------------------
本研究では，
LLMによるコード解析手法として，
以下の三種類の構成を用いる．

素のLLM構成では，
事前学習済みの言語モデルに対して
PHPコードと解析指示を直接入力し，
脆弱性の有無および種類を出力させる．
この構成は追加学習を必要としないため，
導入が容易である一方，
専門知識の不足による誤検出が生じる可能性がある．

Fine-Tuning構成では，
脆弱性データセットを用いて
事前学習済みモデルを微調整し，
Webアプリケーション脆弱性に関する知識を
モデル内部に獲得させる．
これにより，
特定の脆弱性パターンに対する
検出精度の向上が期待される．

RAG構成では，
LLM自体は素のLLMと同一のモデルを用い，
解析時に外部知識ベースを検索・参照する．
これにより，
モデルを再学習することなく，
最新かつ体系化された知識を
解析に反映可能とする．


%------------------------------------
\section{知識ベースの活用方法}
%------------------------------------
本研究では，
LLMによる脆弱性検出の精度および一貫性を向上させるため，
脆弱性に関する知識を体系的に整理した
知識ベースを構築し，これを解析に活用する．
知識ベースには，
各脆弱性の発生条件，
代表的な脆弱コード例，
安全な実装例，
および修正方針に関する情報を含める．

RAG構成においては，
解析対象となるPHPコード，
もしくはその一部をクエリとして用い，
知識ベース内の文書から
関連性の高い情報を検索する．
この検索処理には，
第2章で述べた埋め込みモデルと類似度検索を用い，
入力コードと意味的に近い知識文書を抽出する．

検索によって得られた知識は，
そのまま出力として用いるのではなく，
LLMへの入力プロンプトに付加情報として与えられる．
これにより，
LLMはコード単体の解析結果に加えて，
脆弱性に関する明示的な知識を参照しながら
判断を行うことが可能となる．

このような構成により，
Fine-Tuningを行わない場合であっても，
外部知識の更新や拡張が容易となり，
新たな脆弱性情報への追従性を確保できる．
また，
モデル内部に知識を固定的に保持させる
Fine-Tuning構成との比較を通じて，
知識付与手法の違いが
脆弱性検出性能に与える影響を
評価可能な設計となっている．

%------------------------------------
\section{出力形式および判定方法}
%------------------------------------
LLMの出力は，
脆弱性の種類，
リスクの説明，
修正案の三要素から構成される．

また，本研究では，
LLMの出力結果に対して
以下の基準に基づき判定を行う．

まず，脆弱性の有無については，
対象コードに対して
正解データとして付与された
脆弱性ラベルと比較し，
一致した場合を正検出とする．

次に，脆弱性の種類については，
出力された脆弱性分類が
正解ラベルと一致しているかどうかを判定する．
複数の脆弱性が存在する場合には，
いずれか一つでも正しく指摘されていれば
検出成功とみなす．

本研究では，
脆弱性の有無および種類の判定を
定量評価の対象とし，
リスク説明および修正案については
補助的な定性評価として扱う．

一方で，
存在しない脆弱性を指摘した場合は
過検出（False Positive）として扱う．
これらの判定結果に基づき，
第4章において
各構成の検出性能を定量的に評価する．


%------------------------------------
\section{実装上の留意点}
%------------------------------------
実装にあたっては，
LLM構成間の比較を公平に行うため，
プロンプトの指示内容および
出力形式をすべての構成で統一した．

また，
長大なPHPコードを解析する場合に備え，
入力長制限を考慮し，
ファイル単位で解析を行う設計とした．

これらの工夫により，
モデル構成以外の要因が
検出結果に影響を与えないよう配慮した．

%----------------------------------------------------------------------------
\chapter{実験設定と評価方法}
\label{chapter_4}
%----------------------------------------------------------------------------
本章では，第3章で提案したLLMを用いた脆弱性解析手法の有効性を検証するため，
実験設定および評価方法について述べる．
提案手法の妥当性を定量的に評価するため，
複数のLLM構成を同一条件下で比較する実験を実施する．

本章では，第3章で提案したLLMを用いた脆弱性解析手法の有効性を検証するため，
実験設定および評価方法について述べる．
提案手法の妥当性を定量的に評価するため，
複数のLLM構成を同一条件下で比較する実験を実施する．
また，クラス不均衡の影響を考慮し，
しきい値に依存しない評価を行うため，
AUCを含む複数の評価指標を用いる．

%------------------------------------
\section{実験の目的}
%------------------------------------
本研究における実験の目的は，
第3章で提案した
LLMを用いたPHPプログラムの脆弱性検出手法について，
その有効性および特性を定量的に評価することである．

特に，
事前学習済みLLM単体による解析能力の限界を明らかにするとともに，
Fine-TuningおよびRAG構成が
脆弱性検出結果にどのような影響を与えるかを比較・分析する．

本実験では，
厳密な汎化性能の最適化を目的とするのではなく，
LLMの活用形態の違いが
脆弱性検出挙動および出力傾向に与える影響を
相対的に評価することを主眼とする．


%------------------------------------
\section{使用データセット}
%------------------------------------
本研究では，
Fine-Tuning用データセットと
RAG構成で使用する知識ベースを，
異なる情報源から構築し，
それぞれ異なる目的で使用する．

Fine-Tuning用データセットには，
JVNおよびCVEに公開されている
PHPに関連する脆弱性情報を基に収集した事例を用いた．
各データには，
脆弱性の概要および脆弱性種別ラベルを付与し，
モデルに対して
Webアプリケーション脆弱性に関する知識を付与することを目的とした．

本研究では，
データ規模の制約および
比較実験を主目的とする設計方針から，
Fine-Tuning用データの分割
（学習用・検証用・評価用）を行っていない．
そのため，
本構成は一般的な機械学習における
汎化性能評価を目的としたものではなく，
脆弱性知識をモデル内部に付与した場合の
検出挙動の変化を観察するための
実験的設定として位置付ける．

RAG構成で使用する知識ベースには，
rules.sonarsource.comにおいて公開されている
脆弱なコード記法，
検出ルール，
および修正指針に関する情報を収集した．
なお，
評価対象とするPHPプログラムは，
Fine-Tuning用データおよび
RAG用知識ベースのいずれにも含めないことで，
情報漏洩を防止し，
比較実験の公平性を確保している．


%------------------------------------
\section{実験対象モデル}
%------------------------------------
本研究では，
素のLLM（Base LLM），
Fine-Tuning済みLLM（Fine-Tuned LLM），
およびRAG構成LLM（RAG-augmented LLM）を対象とし，
同一のPHPプログラム群に対して脆弱性検出を行う．
また，基礎モデルとして
\texttt{unsloth/Qwen3-14B-Base-unsloth-bnb-4bit} を使用する．
以下に，各構成について説明する．

%------------------------------------
\subsection{素のLLM}
%------------------------------------
本研究では，
追加学習や外部知識の参照を行わない構成を
\textbf{Base LLM} と呼ぶ．

素のLLMでは，
事前学習済みモデルをそのまま用い，
追加学習や外部知識の参照を行わない．
この構成は，
LLM本来の汎化能力を評価するための
ベースラインとして位置付ける．

%------------------------------------
\subsection{Fine-Tuning済みLLM}
%------------------------------------
本研究では，
事前学習済みモデルに対して
脆弱性データセットを用いた追加学習を行った構成を
\textbf{Fine-Tuned LLM} と呼ぶ．

Fine-Tuning構成では，
JVNおよびCVEから収集した
PHP脆弱性データセットを用いて，
基礎モデルに対する追加学習を行う．
これにより，
モデル内部に
Webアプリケーション脆弱性に関する知識を直接獲得させ，
脆弱性種別の識別性能向上を図る．

Fine-Tuningは，
事前学習済みの大規模言語モデルに対して
80エポックの学習を行い，
実験の再現性を確保するため，
乱数シードを3407に固定した．
なお，本研究では，
収集したデータセット全体を用いて
Fine-Tuningを実施しており，
学習用データと検証用データの分割は行っていない．
これは，本研究の目的が
Fine-Tuning単体の汎化性能評価ではなく，
RAG構成との比較を通じて，
知識付加手法の違いが
脆弱性検出結果に与える影響を分析することにあるためである．

そのため，本構成は，
Fine-Tuningによる性能向上の絶対値を示すものではなく，
RAG構成との相対的な比較を目的としたものである．

%------------------------------------
\subsection{RAG構成LLM}
%------------------------------------
本研究では，
LLM自体のパラメータは変更せず，
推論時に外部知識ベースを検索・参照する構成を
\textbf{RAG-augmented LLM} と呼ぶ．

RAG構成では，
LLM自体は素のLLMと同一のモデルを用い，
解析時に外部知識ベースを検索・参照する．
入力されたPHPコードを埋め込み空間に写像し，
知識ベース内の文書との類似度に基づいて
関連情報を検索し，
その結果をプロンプトに付加する．

この類似度検索には，
埋め込みモデルとして
\texttt{e5-multilingual}\cite{e5}
を使用する．
\texttt{e5-multilingual}は，
検索タスク向けに事前学習された
多言語対応の埋め込みモデルであり，
クエリと文書の意味的対応関係を
高精度に捉えることが可能である．

なお，知識ベース検索においては，
入力コードをクエリとして埋め込みベクトルに変換し，
コサイン類似度に基づく類似度検索を行った．
本研究では，検索件数を top-k = 5 に固定し，
類似度に対する明示的な閾値は設定していない．

そのため，検索結果には，
入力コードとの関連性が必ずしも高くない文書が
含まれる可能性があり，
この点が後述する検出結果および誤検知傾向に
影響を与える可能性がある．

%------------------------------------
\section{実験手順}
%------------------------------------
実験は以下の手順で実施する．

\begin{enumerate}
  \item 対象プログラムをLLMに入力する
  \item 定義したプロンプトに基づき，脆弱性の有無および種類を出力させる
  \item 出力結果を保存し，正解ラベルと比較する
\end{enumerate}

なお，LLMの非決定性による影響を低減するため，
同一条件で複数回実行し，その結果を集計する．
また，AUC算出のため，
各試行における脆弱性検出結果を集計し，
検出頻度をスコアとして用いる．

%------------------------------------
\section{評価指標}
%------------------------------------
本研究では，
第2章で述べた評価指標に基づき，
脆弱性検出性能を定量的に評価する．
具体的には，
Precision，Recall，F1-scoreに加え，AUCを用い，
各LLM構成の検出性能を比較する．
これらの指標を用いることで，
脆弱性の検出精度および検出漏れの傾向を
総合的に把握することが可能となる．

また，
数値指標に加えて，
出力されたリスク説明および修正案の妥当性についても，
定性的な評価を行う．
この評価では，
脆弱性の指摘理由がコードの文脈に即して説明されているか，
および修正案が実用的な内容となっているかに着目する．

さらに，本研究における評価では，
LLMの出力結果が一回の実行において
複数の脆弱性を含む場合がある点を考慮し，
評価単位を
「脆弱性種別 × 試行回数」
と定義する．
この定義に基づき，
各LLM構成について
同一条件下で複数回の試行を行い，
その出力結果を集計する．

LLMが出力した脆弱性指摘のうち，
正解ラベルに含まれる脆弱性を検出した場合を
True Positive（TP）とする．
この際，修正案の成否や説明の完全性にかかわらず，
脆弱性そのものを正しく指摘していれば
検出成功として扱う．

一方，正解ラベルに含まれない脆弱性を指摘した場合は，
誤検知として
False Positive（FP）と定義する．
また，正解ラベルに含まれる脆弱性を
検出できなかった試行については，
False Negative（FN）として扱う．

これらの定義に基づき，
Precision，Recall，F1-score を
micro-average により算出する．
また，AUCについては，
脆弱性検出を正例，
検出されなかった場合を負例として扱い，
検出頻度をスコアとすることでROC曲線を描画し，
その下面積を算出する．
次章において，
各LLM構成間の性能差および誤検知傾向を比較・分析する．

%------------------------------------
\section{実験条件の統一と公平性}
%------------------------------------
本研究では，
異なるLLM構成間で脆弱性検出性能を比較するため，
可能な限り実験条件を統一した．

入力として与えるPHPコード，
評価対象とする脆弱性ラベル，
および最終的な出力形式
（脆弱性の種類，リスク説明，修正案）は，
すべての構成において共通とした．

一方で，
RAG構成においては，
脆弱性診断の過程において
以下の中間処理が追加される点で，
他の構成と処理フローが異なる．

\begin{enumerate}
  \item LLMによる脆弱性の有無および種類の判定
  \item 判定結果および入力コードに基づく
        関連知識文書の検索
  \item 検索結果を付加した上での
        リスク説明および修正案の生成
\end{enumerate}

評価においては，
最初の脆弱性判定結果のみを
正解ラベルと比較することで，
処理段階数の違いが
検出性能評価に影響を与えないよう配慮した．

また，RAG構成における知識検索では，
検索件数を top-k = 5 に固定し，
類似度閾値を設けない設定とした．
この設定は，全ての実験において共通とし，
RAG構成内での条件差が生じないよう統一した．

%----------------------------------------------------------------------------
\chapter{実験結果と考察}
\label{chapter_5}
%----------------------------------------------------------------------------
本章では，第4章で述べた実験設定および評価方法に基づき実施した
脆弱性検出実験の結果を示し，提案手法の有効性について考察を行う．
まず，各手法における検出性能を定量的に比較し，
次に評価指標の設定が結果解釈に与える影響について分析する．
さらに，脆弱性種別ごとの検出傾向および誤検知の分析を行い，
Fine-TuningおよびRAGを用いた手法の特性を比較した上で，
最後に本手法の有効性と限界について議論する．

%------------------------------------
\section{検出性能の比較結果}
%------------------------------------
本節では，素のLLM，Fine-Tuning済みLLM，およびRAG構成LLMの
脆弱性検出性能を比較する．
評価指標としては，第4章で述べたPrecision，Recall，F1-score，
およびROC-AUCを用いる．

表\ref{tab:overall_performance}に示す数値は，
正解ラベルとして定義された脆弱性に対する
検出成否を基準として算出したものであり，
誤検知された脆弱性は
False Positive として Precision を低下させる要因となる．
したがって，本研究におけるPrecisionは，
LLMが不要な脆弱性指摘を抑制しつつ，
適切な脆弱性のみを検出できているかを示す指標として解釈できる．
一方，Recallは，
正解ラベルに含まれる脆弱性を
どの程度網羅的に検出できているかを示す．

実験結果より，
全体としてはいずれの手法においても
比較的高いRecallおよびPrecisionが得られており，
LLMがWebアプリケーションの脆弱性検出において
一定の識別能力を有していることが確認された．
特にFine-Tuning済みLLMは，
Recall 0.882，Precision 0.938，F1-score 0.909，
AUC 0.92と，
全ての指標において最も高い値を示しており，
学習データに含まれる脆弱性パターンに対しては
検出性能が向上する傾向が見られた．

一方で，RAG構成LLMは，
RecallおよびPrecisionがともに0.824と
素のLLMと同程度の値に留まっており，
全体的な検出性能の向上という観点では，
Fine-Tuningほどの効果は確認されなかった．
また，RAG構成はAUCにおいてはBaseを上回るものの，
Precisionの改善には必ずしも結びついておらず，
外部知識の付与が
一様に検出精度を向上させるわけではないことが示唆される．

これらの結果から，
Fine-Tuningは既知の脆弱性パターンに対する検出性能を
全体的に底上げする効果を持つ一方で，
RAG構成は必ずしも
包括的な検出精度の向上を保証するものではないことが分かる．
この傾向は，
脆弱性の種別や実装文脈に依存して
顕著に現れる可能性があり，
詳細については次節において
脆弱性種別ごとに分析する．

\begin{table}[t]
\centering
\caption{各手法の脆弱性検出に関するPrecision, Recall, AUC}
\label{tab:overall_performance}
\begin{tabular}{lccccc}
\hline
手法 & $\theta^*$ & Recall & Precision & F1 & AUC \\
\hline
Base & 0.7 & 0.824 & 0.875 & 0.848 & 0.84 \\
FT   & 0.7 & 0.882 & 0.938 & 0.909 & 0.92 \\
RAG  & 0.6 & 0.824 & 0.824 & 0.824 & 0.86 \\
\hline
\end{tabular}
\end{table}

%------------------------------------
\section{脆弱性種別ごとの検出傾向}
%------------------------------------
本節では，脆弱性種別ごとの検出傾向について，
確率スコアに基づく定量評価を用いて分析する．
対象とした脆弱性は，
XSS，CSRF，およびセッション関連の脆弱性とし，
Webアプリケーションにおいて
頻繁に問題となる代表的な脆弱性を対象とした．

本研究では，各モデルが出力する脆弱性スコアを
二値分類問題として解釈し，
Precision--Recall のバランスを考慮した指標として
F1値が最大となる閾値 $\theta^*$ を
脆弱性種別ごとに決定した．
その上で，
$\theta^*$ における Precision，Recall，
および閾値に依存しない性能指標として
ROC-AUC を算出した．

表\ref{tab:xss_performance}，
表\ref{tab:csrf_performance}，
表\ref{tab:session_performance}は，
それぞれ XSS，CSRF，およびセッション関連の脆弱性に対する
各手法の評価結果を示している．

XSS に関しては，
Base LLM および Fine-Tuning 済み LLM の AUC は
それぞれ 0.68，0.67 と同程度であり，
事前学習済みモデルのみでも
一定の識別能力を有していることが確認された．
しかしながら，
いずれの手法においても Precision が 0.43 に留まっており，
誤検知が多い傾向が見られる．
一方で，
RAG 構成 LLM は Precision を 0.75 まで改善し，
AUC も 0.80 と最も高い値を示した．
これは，
XSS の検出においては
ルールベース知識や具体的な実装指針といった
外部知識の参照が，
スコア分布の分離に寄与した可能性を示唆している．

CSRF に関しては，
Base LLM および Fine-Tuning 済み LLM が
高い Precision を維持しており，
特に Fine-Tuning 済み LLM は
Recall 0.88，AUC 0.93 と最も高い性能を示した．
この結果は，
CSRF がリクエスト構造やトークンの有無といった
比較的明確な特徴を持つ脆弱性であり，
タスク固有データによる Fine-Tuning が
判別境界の明確化に有効であることを示している．
一方，RAG 構成 LLM も安定した性能を示すものの，
Fine-Tuning 済み LLM を上回る結果には至らなかった．

セッション関連の脆弱性については，
Base LLM の AUC が 0.65 と低く，
単純な事前学習モデルでは
識別が困難であることが確認された．
これに対し，
Fine-Tuning 済み LLM は
Precision 1.00，AUC 0.90 を達成しており，
最も高い判別性能を示した．
RAG 構成 LLM も AUC 0.85 と比較的高い値を示しているが，
Fine-Tuning 済み LLM には及ばなかった．
セッション管理に関する脆弱性は，
実装依存性が高く，
データ駆動による学習が
有効に機能した可能性があると考えられる．

以上より，
脆弱性種別によって
有効なアプローチが異なることが確認された．
XSS に対しては RAG による外部知識の付与が有効である一方，
CSRF およびセッション関連の脆弱性に対しては
Fine-Tuning による性能向上が顕著であった．
このことから，
単一の評価指標や手法に依存するのではなく，
Precision，Recall，AUC を併せて評価することで，
各手法の特性を
より多面的に把握できることが示された．

\begin{table}[t]
\centering
\caption{各手法のXSSに対するPrecision, Recall, AUC}
\label{tab:xss_performance}
\begin{tabular}{lccccc}
\hline
手法 & $\theta^*$ & Recall & Precision & F1 & AUC \\
\hline
Base & 0.7 & 0.75 & 0.43 & 0.55 & 0.68 \\
FT   & 0.8 & 0.75 & 0.43 & 0.55 & 0.67 \\
RAG  & 0.8 & 0.75 & 0.75 & 0.75 & 0.80 \\
\hline
\end{tabular}
\end{table}

\begin{table}[t]
\centering
\caption{各手法のCSRFに対するPrecision, Recall, AUC}
\label{tab:csrf_performance}
\begin{tabular}{lccccc}
\hline
手法 & $\theta^*$ & Recall & Precision & F1 & AUC \\
\hline
Base & 0.7 & 0.75 & 1.00 & 0.86 & 0.88 \\
FT   & 0.8 & 0.88 & 1.00 & 0.93 & 0.93 \\
RAG  & 0.7 & 0.88 & 0.88 & 0.88 & 0.90 \\
\hline
\end{tabular}
\end{table}

\begin{table}[t]
\centering
\caption{各手法のセッション関連の脆弱性に対するPrecision, Recall, AUC}
\label{tab:session_performance}
\begin{tabular}{lccccc}
\hline
手法 & $\theta^*$ & Recall & Precision & F1 & AUC \\
\hline
Base & 0.5 & 0.60 & 0.60 & 0.60 & 0.65 \\
FT   & 0.7 & 0.80 & 1.00 & 0.89 & 0.90 \\
RAG  & 0.6 & 0.80 & 0.80 & 0.80 & 0.85 \\
\hline
\end{tabular}
\end{table}

%------------------------------------
\section{誤検知の分析}
%------------------------------------
本節では，各手法における
誤検知（False Positive）の傾向について分析する．

素のLLMでは，
入力コードの文脈を過度に一般化し，
実際には成立しない脆弱性を
指摘するケースが多く見られた．
特に，
PHPでの発生可能性が低い
バッファオーバフローや領域外アクセスといった
脆弱性を指摘する例や，
脆弱性が存在しないとラベル付けされたコードに対しても
問題があると判断する例が確認され，
これらが Precision 低下の一因となっていると考えられる．

Fine-Tuning 済みLLMでは，
学習データに基づく脆弱性知識の獲得により，
指摘される脆弱性の種類は
素のLLMと比較して整理される傾向が確認された．
特に CSRF やセッション関連の脆弱性に関しては，
不要な指摘が抑制され，
高い Precision が得られている．
一方で，
XSS のように実装依存性の高い脆弱性に対しては，
誤検知が完全には解消されず，
検出精度の改善には限界が見られた．

具体的には，
セッション管理や入力検証に関しては，
脆弱性の存在自体は正しく捉えているものの，
修正内容や影響範囲の説明が不十分な例も一部で確認された．
しかしながら，
脆弱性が存在しないと正解ラベルで定義されている
プログラムに対しては，
「脆弱性無し」と判断する出力が多く得られており，
不要な脆弱性指摘を一定程度抑制できている点も確認された．

このことから，
Fine-Tuning は
特定の脆弱性種別における誤検知を低減し，
検出精度を向上させる効果を持つ一方で，
すべての脆弱性に対して一様に有効であるわけではなく，
脆弱性種別ごとの特性に依存することが示唆される．

RAG 構成LLMでは，
外部知識の参照に基づき，
特定の脆弱性種別を一貫して指摘する傾向が強く，
同一プログラムに対して
類似した指摘が繰り返されるなど，
出力の再現性が高いことが確認された．
特に，
XSS のような代表的な Web アプリケーション脆弱性については，
外部知識の参照により，
Precision が改善する傾向が見られた．

一方で，
実装の詳細や攻撃成立条件を十分に考慮せず，
一般的な脆弱性パターンを
機械的に適用してしまう例も確認された．
例えば，
入力の扱いが安全であるにもかかわらず
XSS を指摘する例が見られた．

この要因の一つとして，
RAG 構成における類似度検索の特性が考えられる．
本研究で用いた RAG 構成では，
類似度検索に明示的な閾値を設けていないため，
入力コードとの関連性が十分でない文書が
プロンプトに含まれる場合がある．
これが，
入力コードと直接対応しない脆弱性の指摘を誘発し，
False Positive の増加につながった可能性がある．

以上より，
RAG 構成LLMは
脆弱性知識の想起や XSS 検出精度の向上には有効である一方で，
誤検知の抑制には
検索精度や文書選択の制御が重要であることが示唆される．

%------------------------------------
\section{Fine-TuningとRAGの比較考察}
%------------------------------------
本節では，
Fine-Tuning と RAG という
二つのアプローチの特性を比較し，
それぞれの利点と課題について考察する．

Fine-Tuning 済み LLM は，
CSRF やセッション関連の脆弱性において，
高い Precision および AUC を示しており，
タスク固有データによる学習が
判別境界の明確化に有効であることが確認された．
一方で，
XSS のように実装依存性が高く，
多様な記述パターンを持つ脆弱性に対しては，
Fine-Tuning による性能向上が限定的である場合も見られた．

RAG 構成LLMは，
外部の知識ベースを参照しながら推論を行うため，
知識の追加や更新が容易であり，
脆弱性の背景説明や修正方針の提示といった
説明生成の補助として有効である．
特に XSS に関しては，
RAG による外部知識の参照が
誤検知の低減および Precision の改善に寄与する結果が得られた．

しかしながら，
類似度検索において明示的な閾値を設けていない場合，
入力コードとの関連性が十分でない文書が
プロンプトに含まれることがあり，
これが CSRF やセッション関連の脆弱性において
False Positive を増加させる要因となる可能性がある．
このことから，
RAG による脆弱性検出精度の向上は，
知識検索の精度や文書選択の制御，
およびプロンプト設計に大きく依存することが明らかとなった．

以上の結果から，
Fine-Tuning と RAG は
それぞれ異なる脆弱性種別に対して有効であり，
一方が他方を完全に代替するものではないことが示された．

%------------------------------------
\section{脆弱性修正案の妥当性に関する考察}
%------------------------------------
本章では，前節までで得られた脆弱性検出結果を踏まえ，
各脆弱性に対して提示された修正案の妥当性について考察する．
前節までの分析より，
脆弱性種別によって検出精度や誤検知の傾向が異なることが確認されており，
本節では，
それらの検出結果が修正案の品質にどのように影響しているかを検討する．

%------------------------------------
\subsection{修正案評価の観点}
%------------------------------------
本研究では，修正案の妥当性を以下の観点から定性的に評価する．

\begin{itemize}
\item 脆弱性の根本原因に対処しているか
\item 一般的なセキュリティベストプラクティスと整合しているか
\item 実装コストや可読性の観点から現実的であるか
\item 他の脆弱性やユーザビリティ低下を誘発しないか
\end{itemize}

これらの観点に基づき，単に表面的な対策に留まっていないか，
あるいは過剰な対策となっていないかを評価する．

%------------------------------------
\subsection{妥当な修正案の特徴}
%------------------------------------
XSS 脆弱性に対して出力時に \texttt{htmlspecialchars()} や \texttt{json\_encode()} を適用する修正や，
CSRF 脆弱性に対してトークン検証を導入する修正は，脆弱性の発生原因に直接対応しており，
妥当な修正案であると評価できる．また，セッション固定化攻撃に対する 
\texttt{session\_regenerate\_id(true)} や \texttt{session.use\_strict\_mode = 1} などの利用は，一般的に推奨されている対策であり，
既存の機能やユーザビリティへの影響も比較的小さい．

これらの修正案は，既存のWebアプリケーション開発において広く採用されている手法であり，
実装の容易さと効果のバランスが取れている点で有効であると考えられる．

%------------------------------------
\subsection{不十分または過剰な修正案の考察}
%------------------------------------
一方で，本研究において提示された修正案の中には，
脆弱性の本質的な原因に十分対応していない，
あるいは過剰な対策となっている例も確認された．

まず，XSS 脆弱性に関連して，
出力箇所に対して一律にエスケープ処理を施す修正案が見られた．
しかし，中には既に安全な API（例： exttt{textContent}）を
用いている箇所に対して追加でエスケープを行う，
あるいは多重にエスケープ処理を適用する修正案も存在した．
このような過剰なエスケープは，
表示の不整合や可読性の低下を招く可能性があり，
必ずしも望ましい対策とは言えない．

また，パストラバーサル脆弱性に対する修正案として，
入力値の一部を置換・加工するのみで，
依然としてパスに任意の文字列を含めることが可能な記法が提示される例も確認された．
これらの修正案は，一見すると対策を施しているように見えるものの，
攻撃者による不正なパス指定を根本的に防止できておらず，十分な対策とは言い難い．

さらに，検出された脆弱性とは直接関係のない修正や，
条件分岐の追加によって処理を複雑化させる修正など，
結果として保守性を低下させたり，新たな脆弱性を誘発する可能性のある修正案も一部に見られた．

これらの例から，修正案が提示されている場合であっても，
その内容が脆弱性の発生要因と適切に対応付けられていない場合には，
実用的なセキュリティ向上にはつながらないことが分かる．
したがって，修正案の評価においては，単に対策の有無を見るのではなく，
その妥当性や影響範囲を慎重に検討する必要がある．

%------------------------------------
\subsection{検出性能と修正案品質の関係}
%------------------------------------
本研究の結果から，
脆弱性を正しく検出できている場合であっても，
提示される修正案の品質にはばらつきがあることが明らかとなった．
特に，アプリケーションの文脈に強く依存する認可や設計上の問題に関しては，
抽象的または不十分な修正案が提示される傾向が見られた．

このことから，脆弱性検出性能の向上だけでなく，
修正案の妥当性を評価・改善する仕組みが今後の課題であると言える．

%------------------------------------
\subsection{まとめ}
%------------------------------------
本節では，脆弱性修正案の妥当性について定性的な考察を行った．
その結果，一般的な脆弱性に対しては妥当な修正案が提示される一方で，
設計や認可に関わる問題については不十分または過剰な修正案が含まれる場合があることが分かった．
この知見は，次章における本研究の限界と今後の展望に関する議論につながるものである．

%------------------------------------
\section{本手法の有効性と限界}
%------------------------------------
以上の実験結果から，
Fine-Tuning および RAG を用いた手法は，
脆弱性のリスク説明や修正案の生成といった
補助的なタスクにおいては一定の有効性を示した．
一方で，
脆弱性検出精度の向上という観点では，
素の LLM に対して
一貫した優位性を示すには至らなかった．

特に，
脆弱性種別ごとの検出比較に基づく定量評価の結果，
手法ごとの有効性は
脆弱性の種類によって異なる傾向が確認された．
XSS に関しては，
Fine-Tuning および RAG を適用した場合でも
Recall に大きな差は見られず，
既存の言語モデルが持つ
一般的なセキュリティ知識に依存して
検出が行われている可能性が示唆された．

一方，
CSRF やセッション管理に関する脆弱性では，
一部の構成において
Recall の改善が確認されたものの，
同時に False Positive の増加も観測された．
これは，
Fine-Tuning や RAG により
関連知識が強調されることで，
実際には脆弱性が存在しない箇所に対しても
過剰に脆弱性を指摘する傾向が
強まったためであると考えられる．

このように，
いずれの手法においても
脆弱性の見落とし（False Negative）は
一定程度抑制できているものの，
False Positive を十分に低減できていない点が
共通の課題として浮き彫りとなった．
特に，
脆弱性の構造的理解や
実行時文脈を要するケースにおいては，
表層的なコードパターンに基づく判断が
誤検出につながりやすいことが示唆される．

また，本手法にはいくつかの限界も存在する．
まず，
評価対象が PHP コードに限定されており，
他言語や異なる実装パラダイムへの一般化については
今後の検討が必要である．
さらに，
脆弱性の正解ラベルの定義や粒度，
特に脆弱性が存在しないコードの扱いが
評価結果に大きく影響するという制約がある．
加えて，
RAG における知識ベースの品質や
類似度検索の閾値設定，
文書選択戦略が
検出結果に与える影響については，
より詳細な分析が求められる．

これらの課題を踏まえ，
次章では本研究のまとめと
今後の展望について述べる．

%------------------------------------
%   Chapter 6
\chapter{まとめと今後の展望}
\label{chapter_6}
%------------------------------------
本章では，本研究全体を通じて得られた知見をまとめるとともに，
提案手法の限界および今後の課題について述べる．

%------------------------------------
\section{本研究のまとめ}
%------------------------------------
本研究では，Webアプリケーションにおいて広く利用されている
PHPプログラムを対象として，
大規模言語モデル（LLM）を用いた脆弱性検出手法の有効性を検証した．
特に，XSS，CSRF，セッション管理の不備といった
Webアプリケーション特有の脆弱性に着目し，
複数のプログラムを用いた実験を通じて，
LLMによる自動解析の実用可能性を検討した．

本研究では，
素のLLM，Fine-Tuningを施したLLM，およびRAG構成の三手法を比較し，
同一条件下における検出結果および誤検知傾向を分析した．
これにより，
LLMの利用形態の違いが脆弱性検出性能や出力内容に与える影響を
体系的に明らかにした．

%------------------------------------
\section{研究成果の整理}
%------------------------------------
実験結果から，LLMはPHPコードの構造や処理の流れを一定程度理解し，
代表的な脆弱性については自動的に検出できることが確認された．
一方で，脆弱性の種類や実装文脈によっては，
誤検知や検出漏れが発生する場合もあり，
全てのケースにおいて安定した性能を示すわけではないことが明らかとなった．

Fine-Tuning構成では，
学習データに含まれる脆弱性パターンに対して
検出性能の向上が確認された．
しかし，学習時に想定されていない実装や，
文脈依存性の高い脆弱性に対しては，
性能が十分に発揮されない場合も見られた．

これに対してRAG構成では，
外部知識を参照することで，
脆弱性の説明や修正案の一貫性が向上する傾向が確認された．
特に，CWEなどの一般的な知識体系を参照可能である点は，
誤った推論やハルシネーションの抑制に寄与しており，
実運用を想定した利用において有効であると評価できる．

%------------------------------------
\section{本研究の貢献}
%------------------------------------
本研究の主な貢献は，以下の三点に整理できる．

第一に，
PHPを対象としたWebアプリケーション脆弱性検出において，
LLMの有効性を実験的に示した点である．
従来研究では低レベル言語を対象とした解析が中心であったのに対し，
Web言語特有の脆弱性を扱った点に本研究の新規性がある．

第二に，
Fine-TuningおよびRAGという異なるLLM活用手法を
同一条件下で比較し，
それぞれの特性と適用上の利点・欠点を明確にした点である．
これにより，
利用目的に応じたLLM構成の選択指針を示した．

%------------------------------------
%   Chapter 6
\chapter{まとめと今後の展望}
\label{chapter_6}
%------------------------------------
本章では，本研究全体を通じて得られた知見を総括するとともに，
提案手法の有効性と限界を整理し，
今後の課題および展望について述べる．

%------------------------------------
\section{本研究のまとめ}
%------------------------------------
本研究では，Webアプリケーションにおいて広く利用されている
PHPプログラムを対象として，
大規模言語モデル（LLM）を用いた脆弱性検出手法の有効性を検証した．
特に，XSS，CSRF，およびセッション管理の不備といった
Webアプリケーション特有の脆弱性に着目し，
複数のプログラムを用いた実験を通じて，
LLMによる自動解析の実用可能性を検討した．

本研究では，
素のLLM，Fine-Tuningを施したLLM，
およびRAG構成の三手法を比較対象とし，
同一条件下における脆弱性検出結果と
誤検知の傾向について分析を行った．
これにより，
LLMの利用形態の違いが
脆弱性検出性能および出力内容に与える影響を
体系的に整理した．

%------------------------------------
\section{研究成果の整理}
%------------------------------------
実験結果から，
LLMはPHPコードの構造や処理の流れを一定程度把握し，
代表的なWebアプリケーション脆弱性については，
自動的に検出できることが確認された．
一方で，
脆弱性の種類や実装文脈によっては，
検出漏れや誤検知が発生する場合もあり，
全てのケースにおいて
安定した検出性能を示すわけではないことが明らかとなった．

Fine-Tuning構成では，
学習データに含まれる脆弱性パターンに対して，
一定の検出性能向上が確認された．
しかし，
学習時に想定されていない実装や，
文脈依存性の高い脆弱性に対しては，
必ずしも十分な性能を発揮できない場合も見られた．

これに対してRAG構成では，
外部知識を参照することで，
脆弱性の説明や修正案の一貫性が向上する傾向が確認された．
特に，
CWEなどの一般的な知識体系を参照可能である点は，
誤った推論やハルシネーションの抑制に寄与しており，
脆弱性の理解支援という観点において
有効であると評価できる．

一方で，
いずれの構成においても，
False Positiveを十分に抑制することは困難であり，
脆弱性種別によっては
過剰な指摘が生じる傾向が確認された．
このことから，
LLMは脆弱性検出を完全に自動化する手法というよりも，
人手による確認を前提とした
補助的な支援手法として位置づけることが
現実的であると考えられる．

%------------------------------------
\section{本研究の貢献}
%------------------------------------
本研究の主な貢献は，以下の三点に整理できる．

第一に，
PHPを対象としたWebアプリケーション脆弱性検出において，
LLMの有効性と限界を
実験的に明らかにした点である．
従来研究では低レベル言語を対象とした解析が中心であったのに対し，
Webアプリケーション特有の脆弱性を扱った点に
本研究の新規性がある．

第二に，
素のLLM，Fine-Tuning，RAGという
異なるLLM活用手法を同一条件下で比較し，
それぞれの特性と
適用上の利点・欠点を整理した点である．
これにより，
利用目的に応じたLLM構成の選択に関する
基礎的な指針を示した．

第三に，
脆弱性検出結果だけでなく，
提示される修正案の内容にも着目し，
過剰な対策や不十分な修正が
生じ得ることを示した点である．
これは，
LLMをセキュリティ支援に用いる際の
実用上の留意点を示す重要な知見である．

%------------------------------------
\section{限界と課題}
%------------------------------------
本研究にはいくつかの限界が存在する．
第一に，
評価対象を比較的小規模なPHPプログラムに限定しており，
大規模かつ実運用環境に近いコードに対する有効性については，
十分に検証できていない．

第二に，
LLMの出力は入力プロンプトや参照知識に依存するため，
結果の再現性や安定性に課題がある．
この点は，
実運用を想定した導入において
慎重な検討が必要である．

%------------------------------------
\section{今後の課題}
%------------------------------------
今後の展望として，
対象言語および脆弱性種別の拡張が挙げられる．
JavaScriptやPythonなど，
他のWeb関連言語を対象とすることで，
本研究で得られた知見の汎用性を検証できると考えられる．

また，
大規模コードベースやCI/CD環境への適用を通じて，
LLMを用いた脆弱性検出手法の
実運用における有効性を評価することも重要である．

さらに，
検出結果と修正案を統合的に評価する枠組みを導入することで，
LLMを単なる解析支援にとどめず，
セキュアコーディングを支援する
実践的な開発支援ツールへと発展させることが期待される．

%------------------------------------
%   Acknowledgements
\chapter*{謝辞}
\label{chapter_7}
%------------------------------------
\addcontentsline{toc}{chapter}{謝辞}
本研究を進めるにあたりご指導頂きました木脇太一先生に感謝いたします．
日頃の議論を通じて多くの知識や示唆を頂きました木脇研究室の皆様に感謝いたします．

%------------------------------------
%   References
%------------------------------------
\bibliography{main} %hoge.bibから拡張子を外した名前
\bibliographystyle{plainnat} %参考文献出力スタイル
%------------------------------------
% \appendix
%------------------------------------

%------------------------------------
\end{document}
%------------------------------------
