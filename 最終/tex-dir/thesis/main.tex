%------------------------------------
%   basic settings
%------------------------------------
\documentclass[12pt,a4paper,oneside]{jsbook}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[dvipdfmx]{graphicx}
\usepackage{url}
\usepackage{here}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[ipaex]{pxchfon}
\usepackage{otf}
\usepackage{listings}
\usepackage[square, numbers]{natbib}
\usepackage{booktabs}
\usepackage{float} 
\usepackage{placeins}
% \usepackage{graphics}
\usepackage[dvipdfmx]{graphicx} % includegraphicsを使うためのパッケージを読み込む
% \usepackage{natbib}

% \bibpunct[:]{(}{)}{,}{a}{}{,}
%------------------------------------
%   listings settings (minted -> listings)
%------------------------------------
\lstset{
  basicstyle=\ttfamily\small,  % Font style
  numbers=left,                % Add line numbers
  numberstyle=\tiny,           % Line number style
  stepnumber=1,                % Line number increment
  frame=single,                % Add a frame around the code
  tabsize=4,                   % Tab size
  breaklines=true,             % Allow line breaking
  keywordstyle=\bfseries,      % Keywords in bold
  commentstyle=\itshape,       % Comments in italics
  stringstyle=\color{red},     % Strings in red
  showspaces=false,            % Do not mark spaces
  showstringspaces=false,      % Do not mark string spaces
  language=Python              % Default language
}

%------------------------------------
%   margin settings
%------------------------------------
\setlength{\topmargin}{-5mm}
\setlength{\fullwidth}{125mm}
\setlength{\textwidth}{\fullwidth}
\setlength{\oddsidemargin}{5mm}
\setlength{\evensidemargin}{\oddsidemargin}
%------------------------------------
%   newtheorems
%------------------------------------
\theoremstyle{plain}
\newtheorem{theorem}{定理}[chapter]
\newtheorem{corollary}[theorem]{系}
\newtheorem{lemma}[theorem]{補題}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{conjecture}[theorem]{予想}
\newtheorem{proposition}[theorem]{命題}
\newtheorem{problem}[theorem]{問題}
\newtheorem{definition}[theorem]{定義}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{claim}{Claim}
\newtheorem{subclaim}{Subclaim}[claim]
\newcommand{\resetclaim}{\setcounter{claim}{0}}
\newtheorem{case}{Case}
\newtheorem{subcase}{Subcase}[case]
\newcommand{\resetcase}{\setcounter{case}{0}}
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}
%------------------------------------
%   display figures
%   #1=width, #2=filename,
%   #3=caption, #4=label
%   \fig{0.8\linewidth}{aaa.pdf}{bbb}{ccc}
%------------------------------------
\renewcommand{\figurename}{図.}
\newcommand{\fig}[4]{
\begin{figure}[H]
\centering
\includegraphics[width=#1]{#2}
\caption{#3}
\label{#4}
\end{figure}
}
\newcommand{\figg}[4]{
\begin{figure*}[h!t]
\centering
\includegraphics[width=#1]{#2}
\caption{#3}
\label{#4}
\end{figure*}
}
%------------------------------------
%   setting of algorithms
%------------------------------------
\renewcommand{\algorithmicrequire}{\textbf{条件:}}
\renewcommand{\algorithmicensure}{\textbf{実行結果:}}
\algrenewcommand\algorithmicdo{}
\algrenewcommand\algorithmicthen{}
%------------------------------------
%   other renewcommands and newcommands
%------------------------------------
\renewcommand{\proofname}{\bf 証明.}
%------------------------------------
%   Title & Authors
%------------------------------------
\title{
卒業論文\\[1.5cm]
LLMによるソフトウェア脆弱性の検出\\[6cm]
}
\author{高知大学 理工学部 情報科学科\\[0.5cm]
B223R030P 横川武典}
\date{2025年度}

%------------------------------------
\begin{document}
%------------------------------------
%タイトルページの出力
\maketitle
%目次の作成・出力
\tableofcontents

%----------------------------------------------------------------------------
%   Chapter 1
\chapter{はじめに}
\label{chapter_1}
%----------------------------------------------------------------------------
\section{背景}
%------------------------------------
近年，Webアプリケーションの開発現場では，短期間での実装や頻繁な機能追加が求められる一方で，
セキュリティ対策が十分に考慮されないまま運用される事例も少なくない。
特に学習用途や小規模なWebアプリケーションにおいては，
入力値検証やセッション管理といった基本的な対策が不十分なまま公開されることがある．
このような状況を背景として，
Webアプリケーションに内在する脆弱性を早期に検出し，
開発者が修正を行いやすい形で提示する技術の重要性が高まっている．

これらの脆弱性を効率的に検出する手法の一つとして，
大規模言語モデル（LLM）の活用が注目されている。
LLMはプログラムコードを自然言語的な文脈として扱うことが可能であり，
従来のルールベースやシグネチャベースの手法では対応が困難であった
柔軟な実装や新たな記述パターンに対しても，
一定の有効性が期待されている。
しかしながら，Webアプリケーションで用いられる各種言語を対象とした
LLMによる脆弱性検出については，
その有効性や特性を体系的に評価した研究は十分とは言えない．

特に，Webアプリケーションで広く利用されているPHPは，
記述の自由度が高く，実装スタイルのばらつきも大きいことから，
言語特有の脆弱性や誤用が生じやすいという特徴を持つ。
このことは，特定のプログラミング言語に依存した
脆弱性検出の難しさを示しており，
LLMを用いた手法においても，
その適用可能性や限界を慎重に検討する必要がある．

以上の背景を踏まえ，
Webアプリケーションに対する脆弱性検出手法の高度化を目的として，
本研究では大規模言語モデルを用いたセキュリティ応用に着目し，
PHPプログラムを対象とした脆弱性検出手法の検証を行う．


%----------------------------------------------------------------------------
\chapter{関連研究}
\label{chapter_2}
%----------------------------------------------------------------------------
本章では，本研究で提案する手法の妥当性を示すため，
既存のソフトウェア脆弱性検出手法および
大規模言語モデル（LLM）を用いた関連研究を整理し，
それらの課題を明確化する．
まず，従来のソフトウェア脆弱性検出手法について概観し，
その限界を明らかにする．
次に，大規模言語モデル（LLM）の概要と，
セキュリティ分野への応用例について述べる．
その後，LLMを用いた脆弱性検出に関する先行研究を整理し，
Retrieval-Augmented Generation（RAG）や
ファインチューニングといった代表的手法について説明する．
最後に，評価指標および既存研究の課題をまとめ，
本研究の位置づけを明確にする．


%------------------------------------
\section{従来のソフトウェア脆弱性検出}
%------------------------------------
ソフトウェアの脆弱性検出手法は，
大きく静的解析と動的解析に分類される \cite{chess_mcgraw}.
静的解析は，プログラムを実行せずにソースコードやバイナリを解析する手法であり，
代表的なものとしてデータフロー解析やルールベース解析が挙げられる．
静的解析の代表例としては，Lint系ツールや商用のSAST
（Static Application Security Testing）ツールなどが広く利用されている．
Lint系ツールは，
主にコーディング規約や単純な構文規則に基づいて
潜在的な不具合を検出する静的解析ツールであり，
SASTツールは，
より高度なデータフロー解析や制御フロー解析を用いて
脆弱性の検出を行う．
静的解析は網羅的な検査が可能である一方，実行時の文脈を考慮できないため
誤検知（False Positive）が多いという課題がある．

一方，動的解析はプログラムを実際に実行し，
その挙動を監視することで脆弱性を検出する手法である．
ファジングや実行時モニタリングなどが代表例であり，
AFL（American Fuzzy Lop）に代表されるファジング手法は，実際に悪用可能な脆弱性を検出できる利点を有する．
しかし，実行パスに依存するため，すべての脆弱性を網羅的に検出することは困難である．

近年では，静的解析と動的解析を組み合わせた
ハイブリッド解析手法も提案されており，
両者の欠点を補完するアプローチとして注目されている．
しかし，解析コストの増大や運用の複雑化といった課題も残されている．

これらの従来手法は，既知の脆弱性パターンに基づく検出には有効である一方で，
コードの文脈理解や実装意図の推定といった点に限界がある．
このような課題を背景として，
自然言語およびソースコードの文脈を同時に扱える
LLMを活用した手法が注目されている．

%------------------------------------
\section{Large Language Model（LLM）}
%------------------------------------
大規模言語モデル（Large Language Model: LLM）は，大量のテキストデータを用いて事前学習された
深層学習モデルであり，自然言語処理分野において高い性能を示している．
近年では，Transformer構造を基盤としたモデルが主流となっており，
自己注意機構によって文脈情報を効果的に捉えることが可能である．\cite{transformers}

このようなTransformerベースのLLMにおいて中心的な役割を果たすのが，
自己注意機構である．自己注意機構は，
入力系列 $\mathbf{x} = (x_1, x_2, \dots, x_n)$ に基づいて，
各出力 $\mathbf{y} = (y_1, y_2, \dots, y_n)$ を生成する際に，
入力系列中の重要な要素に重みを付けて参照する仕組みである．

Transformer は，入力系列を固定長のベクトル列として表現し，
それらを複数層にわたって変換するエンコーダ・デコーダ構造
（あるいはデコーダ単体構造）を持つ．
入力系列を $n$ 個のトークンからなる行列
$\mathbf{x} \in \mathbb{R}^{n \times d_{\mathrm{model}}}$
として表すと，各層において線形変換を用いて
クエリ（query），キー（key），バリュー（value）を以下のように生成する．
\begin{equation}
\mathbf{q} = \mathbf{x}\mathbf{W}_q,\quad
\mathbf{k} = \mathbf{x}\mathbf{W}_k,\quad
\mathbf{v} = \mathbf{x}\mathbf{W}_v
\end{equation}
ここで，
$\mathbf{W}_q,\mathbf{W}_k,\mathbf{W}_v \in \mathbb{R}^{d_{\mathrm{model}} \times d_k}$
は学習可能な重み行列であり，
$\mathbf{q},\mathbf{k},\mathbf{v}$ は
それぞれクエリ，キー，バリューの行列表現である．

自己注意機構では，$\mathbf{q}$ と $\mathbf{k}$ の内積に基づいて
トークン間の関連度を算出し，
以下の式によって注意重み付き和を計算する．\cite{transformers}
\begin{equation}
\mathrm{Attention}(\mathbf{q}, \mathbf{k}, \mathbf{v})
= \mathrm{softmax}\left(\frac{\mathbf{q}\mathbf{k}^{\top}}{\sqrt{d_k}}\right)\mathbf{v}
\end{equation}
ここで，$d_k$ はキーの次元数であり，
内積値の分散を抑制するためのスケーリング項として導入される．
この計算により，系列中の任意のトークンが
他のすべてのトークンを参照した表現を同時に得ることができ，
距離に依存しない長距離依存関係の学習が可能となる．

さらに，Transformer ではこの注意機構を複数並列に配置した
マルチヘッドアテンション（Multi-Head Attention）を用いる．\cite{transformers}
$h$ 個のヘッドを用いる場合，
各ヘッド $i$ に対して独立した重み行列を用いて注意計算を行い，
その出力を連結して線形変換することで，
以下のように表される．
\begin{equation}
\mathrm{head}_i
= \mathrm{Attention}
(\mathbf{q}\mathbf{W}_i^q,\,
 \mathbf{k}\mathbf{W}_i^k,\,
 \mathbf{v}\mathbf{W}_i^v)
\end{equation}
\begin{equation}
\mathrm{MultiHead}(\mathbf{q}, \mathbf{k}, \mathbf{v})
= \mathrm{Concat}
(\mathrm{head}_1,\dots,\mathrm{head}_h)\mathbf{W}^O
\end{equation}
この構造により，異なる表現部分空間における依存関係を
同時に捉えることが可能となり，
モデルの表現能力が大きく向上する．
また，自己注意機構は系列全体を一括で処理できるため，
RNN 系モデルと比較して並列計算に適しており，
大規模データを用いた学習を効率的に行えるという利点を持つ．

LLM における出力生成は，
Transformer 層を通じて得られた最終層の隠れ状態
$\mathbf{H} \in \mathbb{R}^{n \times d_{\mathrm{model}}}$
に対し，
語彙サイズ $|V|$ への線形変換と softmax 関数を適用することで行われる．
具体的には，次トークン $y_t$ の確率分布は以下のように定義される．
\begin{equation}
P(y_t \mid y_{<t})
= \mathrm{softmax}(\mathbf{H}_t \mathbf{W}_{\mathrm{out}} + \mathbf{b})
\end{equation}
ここで，
$\mathbf{W}_{\mathrm{out}} \in \mathbb{R}^{d_{\mathrm{model}} \times |V|}$
は出力重み行列，
$\mathbf{b}$ はバイアス項である．
LLM はこの確率分布に基づき，
最大確率のトークンを選択する，
あるいはサンプリングを行うことで，
逐次的に出力文を生成する．

近年のLLMは自然言語だけでなくソースコードを含むデータで学習されており，
プログラムの構文構造や意味的関係を一定程度理解できることが報告されている．
CodeBERT\cite{codebert}やGraphCodeBERT\cite{graphcodebert}などのLLMは，
コードと自然言語の対応関係を学習することで，
プログラム理解タスクにおいて高い性能を示している\cite{llminsoftwaresecurity}．

このような特性から，LLMは単なる自然言語処理モデルにとどまらず，
ソフトウェア解析やセキュリティ分野への応用が期待されている．
次節では，セキュリティ分野におけるLLMの具体的な活用事例について述べる．

%------------------------------------
\section{セキュリティ分野とLLMの関連性および応用}
%------------------------------------
近年，LLMは自然言語処理分野にとどまらず，
サイバーセキュリティ分野においても幅広い応用が進んでいる．
LLMが脆弱性検出，マルウェア解析，ネットワーク侵入検知，フィッシング検出など，
多様なサイバーセキュリティタスクに適用されていることが報告されている\cite{llmcyber}．
このことから，LLMは特定用途に限定された技術ではなく，
セキュリティ分野全体に横断的に利用可能な基盤技術として位置づけられている．

一方で，LLMが生成した成果物そのものが新たなセキュリティリスクとなり得る点も指摘されている．
一部の研究では，LLMが生成したWeb言語向けJavaScriptコードを分析した結果，
24.5\%のコードにおいてセッションタイムアウトの欠如やHTTPセキュリティヘッダーの不足といった
不適切な実装が確認されたと報告されている\cite{hiddenriskllmgeneratedweb}．
この知見は，LLMの出力結果を無条件に信頼することの危険性を示している．

このように，セキュリティ分野におけるLLMの活用は，
防御・検出を支援する側面と，
新たな脆弱性を生み出す可能性という
両義的な性質を有している．
そのため，LLMとセキュリティの関係を論じる上では，
応用可能性だけでなく，
生成結果の検証やリスク評価を含めた
包括的な視点が不可欠である．

%------------------------------------
\section{LLMを用いた脆弱性検出の先行研究}
%------------------------------------
LLMを用いた脆弱性検出に関する先行研究では，
主にCやC++といった低レベル言語を対象としたものが多い．
これらの研究では，ソースコードを入力とし，
脆弱性の有無や種類を分類問題として扱う手法が主に提案されている．
特に，バッファオーバーフローやメモリ破壊といった脆弱性を対象とし，
LLMがコードの文脈情報を活用することで
従来手法よりも高い検出性能を示す可能性が報告されている．

近年では，脆弱性情報が頻繁に更新される
セキュリティ分野の特性を踏まえ，
外部知識ベースを活用する手法を組み合わせた研究も提案されている．
これらの研究では，CWE（Common Weakness Enumeration）や
CVE（Common Vulnerabilities and Exposures）といった
既存の脆弱性知識ベースを参照することで，
脆弱性検出やその説明の精度向上を図っている．
例えば，CVE-LLMでは，
既存のCVEデータとセキュリティオントロジーを統合し，
LLMが脆弱性の背景や影響範囲を考慮しながら
自動的に脆弱性評価を行う枠組みが提案されている \cite{cve-llm}．
このような外部知識の導入は，
コード単体の解析にとどまらず，
既知の脆弱性知識を踏まえた
より包括的な脆弱性理解を可能にする点で有効であると考えられる．

%------------------------------------
\section{埋め込みモデルと類似度検索}
%------------------------------------
本節では，
後述するRetrieval-Augmented Generation（RAG）構成における
検索機構の理解を目的として，
埋め込みモデルと類似度検索の基礎について説明する．
特に，
LLM への入力 $x$ に基づいて
関連する文書 $z$ を取得する過程を明確にする．

近年，情報検索や質問応答，および
Retrieval-Augmented Generation（RAG）といった手法において，
テキストを数値ベクトルとして表現する
埋め込み（Embedding）モデルが広く利用されている．
埋め込みモデルは，
入力されたテキスト $x$ を高次元の実数ベクトル空間へ写像することで，
意味的な近さを数値的に比較可能にする．
このような分散表現に基づく意味検索は，
Sentence-BERT（SBERT）\cite{reimers2019sentencebert}
以降，多くの応用分野で用いられている．

一般に，埋め込みモデルは，
文や段落，あるいはソースコードといった
可変長の入力 $x$ を，
$d$ 次元のベクトル
$\mathbf{v} \in \mathbb{R}^d$
へ変換する写像
$f(\cdot)$ として定式化できる．
すなわち，
\begin{equation}
\mathbf{v} = f(x)
\end{equation}
である．
このとき，
意味的に類似したテキスト同士は，
ベクトル空間上でも近接するように学習される．

埋め込みベクトル間の類似度を測る指標としては，
コサイン類似度（Cosine Similarity）が一般的に用いられる．
二つのベクトル
$\mathbf{v}_1, \mathbf{v}_2 \in \mathbb{R}^d$
に対するコサイン類似度は，
次式で定義される．
\begin{equation}
\mathrm{sim}(\mathbf{v}_1, \mathbf{v}_2)
=
\frac{\mathbf{v}_1 \cdot \mathbf{v}_2}
{\lVert \mathbf{v}_1 \rVert \, \lVert \mathbf{v}_2 \rVert}
\end{equation}
この値は $-1$ から $1$ の範囲を取り，
値が大きいほど
二つのテキストが意味的に類似していることを示す．

類似度検索では，
あらかじめ知識ベース内の文書集合
$\{z_1, z_2, \dots, z_N\}$
を埋め込みモデルによってベクトル化しておく．
その上で，
入力 $x$ に対応するクエリ埋め込み
$\mathbf{v}_x = f(x)$
と，各文書 $z_i$ の埋め込み
$\mathbf{v}_{z_i} = f(z_i)$
との類似度を計算し，
類似度の高い上位 $k$ 件の文書を
関連文書集合 $z$ として取得する．
このような密ベクトル検索の枠組みは，
Dense Passage Retrieval（DPR）\cite{karpukhin2020dense}
などにより体系化され，
RAGにおける検索機構の基盤技術となっている．

この類似度検索の過程は，
RAG において定義される
入力 $x$ に対する文書 $z$ の条件付き確率
$p(z \mid x)$
に対応する処理と解釈できる．
すなわち，
埋め込みモデル $f(\cdot)$ により
$x$ および各文書 $z_i$ をベクトル空間に写像し，
類似度指標 $\mathrm{sim}(\mathbf{v}_x, \mathbf{v}_{z_i})$
に基づいて文書を順位付けする操作は，
確率的には
「入力 $x$ が与えられたときに，
どの文書 $z$ が関連文書として選択されやすいか」
を表す分布 $p(z \mid x)$ を近似的に与えるものとみなせる．

実際の実装においては，
$p(z \mid x)$ を明示的な確率分布として正規化する代わりに，
類似度スコアに基づく上位 $k$ 件の文書を
決定論的に選択する手法が一般的に用いられる．
このような top-$k$ 類似度検索は，
RAG の確率モデルを実用的に近似する方法として，
多くのシステムで採用されている．

また，近年では多言語対応かつ汎用的な意味表現を獲得可能な
埋め込みモデルが多数提案されている．
その一例として，
e5-multilingual\cite{e5} は，
検索タスク向けに弱教師あり対照学習を用いて事前学習されたモデルであり，
入力 $x$ と文書 $z$ の意味的対応関係を
高精度に捉えることが可能である．
自然言語を主対象としつつも，
技術文書やプログラムコードといった
専門的テキストに対しても
一定の有効性が報告されている．

本研究においては，
RAG構成における検索段階において
埋め込みモデルを用いた類似度検索を採用する．
具体的には，
解析対象のPHPコードまたはその一部を入力 $x$ とし，
脆弱性に関する知識ベース内の文書群から
$x$ に意味的に類似した文書 $z$ を検索することで，
LLM が参照すべき関連情報を取得する．
このように，
埋め込みモデルと類似度検索は，
RAGにおける情報検索機構の基盤技術として
重要な役割を果たしている．

%------------------------------------
\section{Retrieval-Augmented Generation（RAG）}
%------------------------------------
Retrieval-Augmented Generation（RAG）は，
LLM による生成時に，
入力 $x$ に基づいて外部の知識ベースから
関連文書 $z$ を検索し，
それらを追加の入力として用いることで，
生成結果 $y$ の品質向上を図る手法である．
この枠組みにより，
モデル内部のパラメータに含まれない知識を
動的に参照することが可能となり，
事実性の向上やハルシネーションの抑制が期待されている\cite{rag}．

RAGは，
生成結果 $y$ を，
入力 $x$ および検索された文書集合 $z$ に条件づけた確率として
以下のように定式化できる．
\begin{equation}
p(y \mid x) = \sum_{z \in \mathcal{Z}} p(y \mid x, z)\, p(z \mid x)
\end{equation}
ここで，
$p(z \mid x)$ は，
入力 $x$ に基づいて
関連文書 $z$ を検索する確率分布を表し，
埋め込みモデルと類似度検索によって実現される．
また，
$p(y \mid x, z)$ は，
検索結果 $z$ を条件として
出力 $y$ を生成する
言語モデルの確率分布を表す．

このようにRAGでは，
入力 $x$ に対して
まず関連情報 $z$ を取得し，
それを条件として出力 $y$ を生成するという
二段階の処理が行われる．
この確率的枠組みは，
Retrieval-Augmented Generation の原論文において
提案・定式化されたモデルに基づいている\cite{rag}．

セキュリティ分野においては，
CWEやCVEといった脆弱性知識ベースを
文書集合 $z$ としてRAGに組み込むことで，
入力されたコード $x$ に対する
脆弱性の検出や説明生成の精度を
向上させる試みが報告されている．
特に，
コード片と既知の脆弱性パターンとの対応関係を
明示的に参照できる点は，
モデルの解釈性向上という観点からも有用である．

一方で，
RAGの性能は検索される文書 $z$ の品質に大きく依存しており，
入力 $x$ と無関係な文書が取得された場合には，
生成結果 $y$ の誤りやノイズの増加につながる可能性がある．
そのため，
検索手法および知識ベースの設計は，
RAG全体の性能を左右する重要な要素となる．

%------------------------------------
\section{ファインチューニング（Fine-Tuning）}
%------------------------------------
ファインチューニング（Fine-Tuning）とは，
大規模コーパスを用いて事前学習されたモデルに対し，
特定タスクのデータを用いて追加学習を行うことで，
タスク固有の特徴に適応させる手法である．
この考え方は，深層ニューラルネットワークにおける
表現学習の枠組みに基づいており，
事前学習によって獲得された汎用的な中間表現を，
下流タスクに最適化する過程として位置づけられる．

Hintonらは，自己符号化器を用いた研究において，
高次元データから有用な低次元表現を事前に学習し，
その後のタスク適応によって性能が向上することを示している
\cite{hinton2006reducing}．
このような段階的学習の考え方は，
現在のLLMにおける事前学習とファインチューニングの関係と
本質的に共通している．

ファインチューニングの考え方は，
特に畳み込みニューラルネットワーク（CNN）において広く用いられてきた．
画像認識の分野では，ImageNet Large Scale Visual Recognition Challenge（ILSVRC）をはじめとする
大規模データセットで事前学習された CNN モデルが，
多くの下流タスクに対する転移学習の基盤モデルとして活用されている．
例えば，医用画像解析を対象とした研究においては，
ImageNet で事前学習された深層 CNN をファインチューニングすることで，
同一タスクにスクラッチから学習した CNN と比較して高い性能を示した．
このように，事前学習された CNN モデルの重みを初期値として用い，
タスク固有の学習データでパラメータを再調整する手法が
ファインチューニングとして有効であることが示されている\cite{uesaka2017multi_view}．

この考え方は，ソフトウェア脆弱性検出といった実応用分野においても取り入れられている．
例えば，脆弱なコードと安全なコードを用いた教師あり学習により，
特定の脆弱性パターンに対する識別性能が向上することが報告されている
\cite{devigneffectivesearchvulnerability}．
一方で，ファインチューニングには
大量のラベル付きデータを必要とする点や，
学習データに強く依存したバイアスが生じやすい点などの課題も存在し，
汎化性能の低下を招く可能性が指摘されている．

さらに，脆弱性検出を目的としたファインチューニングにおいては，
学習時点での知識が固定される点も課題となる．
CVEに代表される脆弱性情報は日々更新されており，
新たな攻撃手法や脆弱性種別が継続的に追加される．
ファインチューニング済みモデルは，
学習データに含まれない新規脆弱性に対しては対応が困難であり，
時間の経過とともに知識の陳腐化が生じる可能性がある．
このことは，
セキュリティ分野において
ファインチューニング単体を長期間運用することの
難しさを示している．

以上の課題から，
ファインチューニングは有効な手法である一方，
知識更新の柔軟性や運用性の観点では
制約が存在することが分かる．

%------------------------------------
\section{評価指標およびベンチマーク}
%------------------------------------
脆弱性検出手法の評価には，
Precision，Recall，F1-scoreといった指標が一般的に用いられる．
これらの指標は，検出結果を
真陽性（True Positive: TP），
偽陽性（False Positive: FP），
偽陰性（False Negative: FN）
に基づいて定義される．

Precisionは，検出された脆弱性のうち，
実際に正しいものの割合を表す指標であり，
次式で定義される．
\begin{equation}
\mathrm{Precision} = \frac{TP}{TP + FP}
\end{equation}
Precisionが低い場合，誤検知が多く発生していることを意味し，
実運用においては解析コストの増大や運用負荷の増加につながる．
そのため，脆弱性検出タスクではPrecisionの高さが重要視される．

一方，Recallは，実際に存在する脆弱性のうち，
正しく検出できた割合を表す指標であり，
次式で定義される．
\begin{equation}
\mathrm{Recall} = \frac{TP}{TP + FN}
\end{equation}
Recallが低い場合，脆弱性の見逃しが多いことを意味し，
セキュリティ上の重大なリスクにつながる可能性がある．
そのため，PrecisionだけでなくRecallとのバランスが重要である．

F1-scoreは，PrecisionとRecallの調和平均として定義され，
両者のバランスを総合的に評価する指標である．
\begin{equation}
\mathrm{F1\text{-}score} = 
\frac{2 \cdot \mathrm{Precision} \cdot \mathrm{Recall}}
{\mathrm{Precision} + \mathrm{Recall}}
\end{equation}
F1-scoreは，PrecisionとRecallのいずれか一方が
極端に低い場合に値が低下するため，
両指標を同時に考慮した評価が可能となる．

さらに，本研究では，
分類器のしきい値に依存しない評価指標として，
ROC曲線およびAUC（Area Under the ROC Curve）も用いる．
ROC曲線は，
偽陽性率（False Positive Rate: FPR）を横軸，
真陽性率（True Positive Rate: TPR）を縦軸として，
分類しきい値を変化させた際の性能を可視化したものである．
ここで，
\begin{equation}
\mathrm{TPR} = \frac{TP}{TP + FN}, \quad
\mathrm{FPR} = \frac{FP}{FP + TN}
\end{equation}
で定義される．

AUCは，
ROC曲線の下側の面積として定義され，
分類器が正例と負例をどの程度正しく識別できているかを
一つの値で表す指標である．
AUCの値は $0.5$ から $1.0$ の範囲を取り，
$1.0$ に近いほど識別性能が高いことを示す．
AUCは，
クラスの分布や分類しきい値の設定に依存しにくいため，
脆弱性検出のように
クラス不均衡が大きいタスクにおいても
比較的安定した評価が可能である．

なお，単一の評価指標のみで手法の有効性を判断することは難しく，
複数の指標を組み合わせて総合的に評価する必要がある．
特に，脆弱性検出タスクでは，
Accuracyのみでは性能を適切に評価できない場合が多く，
Precision，Recall，F1-scoreに加えて，
AUCを併用することが有効である．

本研究においても，
PHPプログラムを対象とした脆弱性検出性能を評価するため，
これらの指標を用いて定量的な比較を行う．

%------------------------------------
\section{既存研究の課題と本研究の位置づけ}
%------------------------------------
以上のように，LLMを用いた脆弱性検出に関する研究は一定の成果を上げているが，
その多くはC/C++を対象とし，
バッファオーバーフローなどのメモリ管理に起因する脆弱性の検出に焦点を当てている．
この背景には，既存のベンチマークデータセットや先行研究の多くが，
低レベル言語を対象として構築されてきたという事情がある．

一方で，Web言語として広く利用されているPHPなどにおいては，
クロスサイトスクリプティング（XSS）やSQLインジェクションといった，
言語仕様や実行環境に依存した脆弱性が多数存在するにもかかわらず，
LLMを用いた包括的に扱った研究は依然として限定的である．
また，既存研究では特定の脆弱性クラスに偏った評価が多く，
検出可能な脆弱性の多様性という観点での分析も限定的である．

そこで本研究では，
Web言語であるPHPを対象としたLLMによる脆弱性検出の可能性を検討する．
さらに，メモリ関連脆弱性に限定せず複数の脆弱性種別を対象とすることで，
LLMが多様な脆弱性パターンをどの程度識別可能であるかを明らかにすることを目的とする．
Web言語特有の脆弱性を対象とし，
LLMを用いて複数種別の脆弱性を統一的に扱う点において，
既存研究とは異なる位置づけを持つ．

%----------------------------------------------------------------------------
\chapter{提案手法}
\label{chapter_3}
%----------------------------------------------------------------------------
本章では，本研究において提案する
LLMを用いたPHPプログラムの脆弱性検出手法について述べる．

PHPは，
Webアプリケーション開発において長年広く利用されてきた
サーバサイドスクリプト言語であり，
現在も多くの既存システムや中小規模Webサービスにおいて
重要な役割を担っている．
一方で，
動的型付けや簡潔な記述を特徴とする言語仕様，
および多様な実装慣習に起因して，
XSSやSQLインジェクションといった
Web特有の脆弱性が発生しやすいという課題を抱えている．
これらの脆弱性は，
入力値の流れや実行時の文脈に依存して発生する場合が多く，
単純なパターンマッチングや
静的なルールに基づく検出手法では，
十分に対応できないことが指摘されている．

第2章で整理した関連研究より，
既存の脆弱性検出手法には
対象言語や脆弱性種別の偏りが存在することが明らかとなった．
特に，言語仕様や実装慣習の違いを考慮した分析が十分に行われていない点は，
PHPのような柔軟な記述が可能な言語において，
脆弱性検出を困難にする要因の一つである．

このような背景を踏まえ，
本研究では
Webアプリケーションで広く利用されているPHPを対象とし，
LLMのコード理解能力を活用した
脆弱性検出手法を提案する．
LLMは，
プログラムコードを文脈情報を含む構造として扱うことが可能であり，
従来手法では見落とされやすい
言語仕様や実装文脈に依存した脆弱性に対しても，
有効に機能する可能性がある．
特に，
言語仕様や実行文脈に依存する脆弱性に対して，
LLMがどの程度有効に機能するかを明らかにすることを目的とする．

本章ではまず，
本研究の概要および設計方針を示し，
続いて対象とする脆弱性および分析対象について説明する．
その後，
提案手法の全体構成，
LLMによるコード解析手法，
知識ベースの活用方法，
ならびに出力形式と判定方法について詳述し，
最後に実装上の留意点について述べる．

%------------------------------------
\section{本研究の概要}
%------------------------------------
本研究の目的は，
Webアプリケーション開発で広く利用されているPHPを対象として，
LLMを用いた脆弱性検出手法を構築し，
その有効性を検証することである．
特に，従来研究では十分に検討されてこなかった
Web言語特有の脆弱性に着目し，
LLMの自然言語理解能力およびコード理解能力を活用することで，
実用的かつ拡張性の高い検出手法の実現を目指す．

本研究では，
LLMの活用形態として以下の三つの構成を採用する．
\begin{itemize}
  \item 事前学習済み言語モデルをそのまま用いる構成（以下，素のLLM）
  \item 脆弱性データセットを用いてFine-Tuningを行った構成
  \item 素のLLMに対して知識ベースを接続したRAG構成
\end{itemize}
これら三構成を同一条件下で比較することで，
学習による知識獲得と，
外部知識の参照という
異なるアプローチの特性を明らかにする．

また，本研究では検出結果を
「脆弱性の種類」「想定されるリスク」「修正案」
といった形式で出力することで，
開発者が結果を理解しやすく，
実際の修正作業に活用しやすいことを重視している．
これにより，LLMを単なる分類器として用いるのではなく，
脆弱性分析を支援するツールとして位置付ける点に
本研究の特徴がある．

%------------------------------------
\section{設計方針}
%------------------------------------
第2章で述べた関連研究の整理より，
従来の脆弱性検出手法には
対象言語の偏りや，
検出対象の限定性といった課題が存在することが明らかとなった．
本研究では，これらの課題に対応するため，
以下の設計方針に基づいて提案手法を構築する．

まず，対象言語としてPHPを採用し，
Webアプリケーションにおいて頻発する
入力処理や外部データの取り扱いに起因する脆弱性を
重点的に扱うこととした．
これにより，
Web言語特有の脆弱性に対する
検出性能を評価可能な枠組みを構築する．

次に，解析手法としてLLMを中核に据え，
静的解析やルールベース手法では対応が困難であった
多様なコーディングスタイルや
文脈依存の脆弱性に対応することを目指す．

さらに，本研究では
LLMの活用形態の違いに着目し，
素のLLM，Fine-Tuning済みLLM，RAG構成の
三つの構成を比較対象とする．
この際，入力コード，プロンプト形式，
および出力形式を統一することで，
モデル構成以外の要因が
検出結果に影響を与えないよう設計した．

%------------------------------------
\section{対象脆弱性および分析対象}
%------------------------------------
本節では，本研究で対象とする脆弱性の種類および
分析対象とするプログラムの範囲について説明する．

%------------------------------------
\subsection{対象脆弱性}
%------------------------------------
本研究では，Webアプリケーションにおいて
発生頻度が高く，
かつ実害につながりやすい脆弱性を主な対象とする．
具体的には，以下の脆弱性を扱う．
\begin{itemize}
  \item クロスサイトスクリプティング（XSS）
  \item クロスサイトリクエストフォージェリ（CSRF）
  \item セッション管理の不備（セッション固定化，ハイジャック等）
\end{itemize}

これらの脆弱性は，
ユーザ入力の検証不足や
不適切なデータ処理に起因することが多く，
コードの文脈や処理の流れを考慮した解析が求められる．
そのため，LLMによる解析が有効であると考えられる．

%------------------------------------
\subsection{分析対象プログラム}
%------------------------------------
分析対象としては，
PHPで記述されたサーバサイドプログラムを対象とする．
関数定義，条件分岐，
データベースアクセス，
外部入力処理などを解析対象とし，
フレームワーク固有の機構や
実行環境依存の設定については考慮しない．

%------------------------------------
\section{提案手法の全体構成}
%------------------------------------
% 手法の全体のフローを更新する
\label{fix_1}
%------------------------------------
提案手法の全体構成を図\ref{fig:system_overview}に示す．
本手法は，
入力となるPHPソースコード，
LLMによる解析処理，
および検出結果の出力から構成される．

解析対象のPHPコードは，
ファイル単位で前処理を施した後，
LLMへの入力として与えられる．
LLMはコードの構造や処理内容を解析し，
脆弱性の有無および種類を判定する．

RAG構成では，
解析対象コードに関連する脆弱性知識を
知識ベースから検索し，
その内容をプロンプトに付加した上で
LLMによる解析を行う．
これにより，
LLMはコード単体の情報だけでなく，
外部知識を参照した判断を行うことが可能となる．

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\linewidth]{./fig_system_overview.jpg}
  \caption{提案手法の全体構成}
  \label{fig:system_overview}
\end{figure}

%------------------------------------
\section{LLMによるコード解析手法}
%------------------------------------
本研究では，
LLMによるコード解析手法として，
以下の三種類の構成を用いる．

素のLLM構成では，
事前学習済みの言語モデルに対して
PHPコードと解析指示を直接入力し，
脆弱性の有無および種類を出力させる．
この構成は追加学習を必要としないため，
導入が容易である一方，
専門知識の不足による誤検出が生じる可能性がある．

Fine-Tuning構成では，
脆弱性データセットを用いて
事前学習済みモデルを微調整し，
Webアプリケーション脆弱性に関する知識を
モデル内部に獲得させる．
これにより，
特定の脆弱性パターンに対する
検出精度の向上が期待される．

RAG構成では，
LLM自体は素のLLMと同一のモデルを用い，
解析時に外部知識ベースを検索・参照する．
これにより，
モデルを再学習することなく，
最新かつ体系化された知識を
解析に反映可能とする．


%------------------------------------
\section{知識ベースの活用方法}
%------------------------------------
本研究では，
LLMによる脆弱性検出の精度および一貫性を向上させるため，
脆弱性に関する知識を体系的に整理した
知識ベースを構築し，これを解析に活用する．
知識ベースには，
各脆弱性の発生条件，
代表的な脆弱コード例，
安全な実装例，
および修正方針に関する情報を含める．

RAG構成においては，
解析対象となるPHPコード，
もしくはその一部をクエリとして用い，
知識ベース内の文書から
関連性の高い情報を検索する．
この検索処理には，
第2章で述べた埋め込みモデルと類似度検索を用い，
入力コードと意味的に近い知識文書を抽出する．

検索によって得られた知識は，
そのまま出力として用いるのではなく，
LLMへの入力プロンプトに付加情報として与えられる．
これにより，
LLMはコード単体の解析結果に加えて，
脆弱性に関する明示的な知識を参照しながら
判断を行うことが可能となる．

このような構成により，
Fine-Tuningを行わない場合であっても，
外部知識の更新や拡張が容易となり，
新たな脆弱性情報への追従性を確保できる．
また，
モデル内部に知識を固定的に保持させる
Fine-Tuning構成との比較を通じて，
知識付与手法の違いが
脆弱性検出性能に与える影響を
評価可能な設計となっている．

%------------------------------------
\section{出力形式および判定方法}
%------------------------------------
LLMの出力は，
脆弱性の種類，
リスクの説明，
修正案の三要素から構成される．

また，本研究では，
LLMの出力結果に対して
以下の基準に基づき判定を行う．

まず，脆弱性の有無については，
対象コードに対して
正解データとして付与された
脆弱性ラベルと比較し，
一致した場合を正検出とする．

次に，脆弱性の種類については，
出力された脆弱性分類が
正解ラベルと一致しているかどうかを判定する．
複数の脆弱性が存在する場合には，
いずれか一つでも正しく指摘されていれば
検出成功とみなす．

本研究では，
脆弱性の有無および種類の判定を
定量評価の対象とし，
リスク説明および修正案については
補助的な定性評価として扱う．

一方で，
存在しない脆弱性を指摘した場合は
過検出（False Positive）として扱う．
これらの判定結果に基づき，
第4章において
各構成の検出性能を定量的に評価する．


%------------------------------------
\section{実装上の留意点}
%------------------------------------
実装にあたっては，
LLM構成間の比較を公平に行うため，
プロンプトの指示内容および
出力形式をすべての構成で統一した．

また，
長大なPHPコードを解析する場合に備え，
入力長制限を考慮し，
ファイル単位で解析を行う設計とした．

これらの工夫により，
モデル構成以外の要因が
検出結果に影響を与えないよう配慮した．

%----------------------------------------------------------------------------
\chapter{実験設定と評価方法}
\label{chapter_4}
%----------------------------------------------------------------------------
本章では，第3章で提案したLLMを用いた脆弱性解析手法の有効性を検証するため，
実験設定および評価方法について述べる．
提案手法の妥当性を定量的に評価するため，
複数のLLM構成を同一条件下で比較する実験を実施する．

本章では，第3章で提案したLLMを用いた脆弱性解析手法の有効性を検証するため，
実験設定および評価方法について述べる．
提案手法の妥当性を定量的に評価するため，
複数のLLM構成を同一条件下で比較する実験を実施する．
また，クラス不均衡の影響を考慮し，
しきい値に依存しない評価を行うため，
AUCを含む複数の評価指標を用いる．

%------------------------------------
\section{実験の目的}
%------------------------------------
本研究における実験の目的は，
第3章で提案した
LLMを用いたPHPプログラムの脆弱性検出手法について，
その有効性および特性を定量的に評価することである．

特に，
事前学習済みLLM単体による解析能力の限界を明らかにするとともに，
Fine-TuningおよびRAG構成が
脆弱性検出結果にどのような影響を与えるかを比較・分析する．

本実験では，
厳密な汎化性能の最適化を目的とするのではなく，
LLMの活用形態の違いが
脆弱性検出挙動および出力傾向に与える影響を
相対的に評価することを主眼とする．


%------------------------------------
\section{使用データセット}
%------------------------------------
本研究では，
Fine-Tuning用データセットと
RAG構成で使用する知識ベースを，
異なる情報源から構築し，
それぞれ異なる目的で使用する．

Fine-Tuning用データセットには，
JVNおよびCVEに公開されている
PHPに関連する脆弱性情報を基に収集した事例を用いた．
各データには，
脆弱性の概要および脆弱性種別ラベルを付与し，
モデルに対して
Webアプリケーション脆弱性に関する知識を付与することを目的とした．

本研究では，
データ規模の制約および
比較実験を主目的とする設計方針から，
Fine-Tuning用データの分割
（学習用・検証用・評価用）を行っていない．
そのため，
本構成は一般的な機械学習における
汎化性能評価を目的としたものではなく，
脆弱性知識をモデル内部に付与した場合の
検出挙動の変化を観察するための
実験的設定として位置付ける．

RAG構成で使用する知識ベースには，
rules.sonarsource.comにおいて公開されている
脆弱なコード記法，
検出ルール，
および修正指針に関する情報を収集した．
なお，
評価対象とするPHPプログラムは，
Fine-Tuning用データおよび
RAG用知識ベースのいずれにも含めないことで，
情報漏洩を防止し，
比較実験の公平性を確保している．


%------------------------------------
\section{実験対象モデル}
%------------------------------------
本研究では，
素のLLM（Base LLM），
Fine-Tuning済みLLM（Fine-Tuned LLM），
およびRAG構成LLM（RAG-augmented LLM）を対象とし，
同一のPHPプログラム群に対して脆弱性検出を行う．
また，基礎モデルとして
\texttt{unsloth/Qwen3-14B-Base-unsloth-bnb-4bit} を使用する．
以下に，各構成について説明する．

%------------------------------------
\subsection{素のLLM}
%------------------------------------
本研究では，
追加学習や外部知識の参照を行わない構成を
\textbf{Base LLM} と呼ぶ．

素のLLMでは，
事前学習済みモデルをそのまま用い，
追加学習や外部知識の参照を行わない．
この構成は，
LLM本来の汎化能力を評価するための
ベースラインとして位置付ける．

%------------------------------------
\subsection{Fine-Tuning済みLLM}
%------------------------------------
本研究では，
事前学習済みモデルに対して
脆弱性データセットを用いた追加学習を行った構成を
\textbf{Fine-Tuned LLM} と呼ぶ．

Fine-Tuning構成では，
JVNおよびCVEから収集した
PHP脆弱性データセットを用いて，
基礎モデルに対する追加学習を行う．
これにより，
モデル内部に
Webアプリケーション脆弱性に関する知識を直接獲得させ，
脆弱性種別の識別性能向上を図る．

Fine-Tuningは，
事前学習済みの大規模言語モデルに対して
80エポックの学習を行い，
実験の再現性を確保するため，
乱数シードを3407に固定した．
なお，本研究では，
収集したデータセット全体を用いて
Fine-Tuningを実施しており，
学習用データと検証用データの分割は行っていない．
これは，本研究の目的が
Fine-Tuning単体の汎化性能評価ではなく，
RAG構成との比較を通じて，
知識付加手法の違いが
脆弱性検出結果に与える影響を分析することにあるためである．

そのため，本構成は，
Fine-Tuningによる性能向上の絶対値を示すものではなく，
RAG構成との相対的な比較を目的としたものである．

%------------------------------------
\subsection{RAG構成LLM}
%------------------------------------
本研究では，
LLM自体のパラメータは変更せず，
推論時に外部知識ベースを検索・参照する構成を
\textbf{RAG-augmented LLM} と呼ぶ．

RAG構成では，
LLM自体は素のLLMと同一のモデルを用い，
解析時に外部知識ベースを検索・参照する．
入力されたPHPコードを埋め込み空間に写像し，
知識ベース内の文書との類似度に基づいて
関連情報を検索し，
その結果をプロンプトに付加する．

この類似度検索には，
埋め込みモデルとして
\texttt{e5-multilingual}\cite{e5}
を使用する．
\texttt{e5-multilingual}は，
検索タスク向けに事前学習された
多言語対応の埋め込みモデルであり，
クエリと文書の意味的対応関係を
高精度に捉えることが可能である．

なお，知識ベース検索においては，
入力コードをクエリとして埋め込みベクトルに変換し，
コサイン類似度に基づく類似度検索を行った．
本研究では，検索件数を top-k = 5 に固定し，
類似度に対する明示的な閾値は設定していない．

そのため，検索結果には，
入力コードとの関連性が必ずしも高くない文書が
含まれる可能性があり，
この点が後述する検出結果および誤検知傾向に
影響を与える可能性がある．

%------------------------------------
\section{実験手順}
%------------------------------------
実験は以下の手順で実施する．

\begin{enumerate}
  \item 対象プログラムをLLMに入力する
  \item 定義したプロンプトに基づき，脆弱性の有無および種類を出力させる
  \item 出力結果を保存し，正解ラベルと比較する
\end{enumerate}

なお，LLMの非決定性による影響を低減するため，
同一条件で複数回実行し，その結果を集計する．
また，AUC算出のため，
各試行における脆弱性検出結果を集計し，
検出頻度をスコアとして用いる．

%------------------------------------
\section{評価指標}
%------------------------------------
本研究では，
第2章で述べた評価指標に基づき，
脆弱性検出性能を定量的に評価する．
具体的には，
Precision，Recall，F1-scoreに加え，AUCを用い，
各LLM構成の検出性能を比較する．
これらの指標を用いることで，
脆弱性の検出精度および検出漏れの傾向を
総合的に把握することが可能となる．

また，
数値指標に加えて，
出力されたリスク説明および修正案の妥当性についても，
定性的な評価を行う．
この評価では，
脆弱性の指摘理由がコードの文脈に即して説明されているか，
および修正案が実用的な内容となっているかに着目する．

さらに，本研究における評価では，
LLMの出力結果が一回の実行において
複数の脆弱性を含む場合がある点を考慮し，
評価単位を
「脆弱性種別 × 試行回数」
と定義する．
この定義に基づき，
各LLM構成について
同一条件下で複数回の試行を行い，
その出力結果を集計する．

LLMが出力した脆弱性指摘のうち，
正解ラベルに含まれる脆弱性を検出した場合を
True Positive（TP）とする．
この際，修正案の成否や説明の完全性にかかわらず，
脆弱性そのものを正しく指摘していれば
検出成功として扱う．

一方，正解ラベルに含まれない脆弱性を指摘した場合は，
誤検知として
False Positive（FP）と定義する．
また，正解ラベルに含まれる脆弱性を
検出できなかった試行については，
False Negative（FN）として扱う．

これらの定義に基づき，
Precision，Recall，F1-score を
micro-average により算出する．
また，AUCについては，
脆弱性検出を正例，
検出されなかった場合を負例として扱い，
検出頻度をスコアとすることでROC曲線を描画し，
その下面積を算出する．
次章において，
各LLM構成間の性能差および誤検知傾向を比較・分析する．

%------------------------------------
\section{実験条件の統一と公平性}
%------------------------------------
本研究では，
異なるLLM構成間で脆弱性検出性能を比較するため，
可能な限り実験条件を統一した．

入力として与えるPHPコード，
評価対象とする脆弱性ラベル，
および最終的な出力形式
（脆弱性の種類，リスク説明，修正案）は，
すべての構成において共通とした．

一方で，
RAG構成においては，
脆弱性診断の過程において
以下の中間処理が追加される点で，
他の構成と処理フローが異なる．

\begin{enumerate}
  \item LLMによる脆弱性の有無および種類の判定
  \item 判定結果および入力コードに基づく
        関連知識文書の検索
  \item 検索結果を付加した上での
        リスク説明および修正案の生成
\end{enumerate}

この中間処理は，
外部知識を活用した説明生成を目的としたものであり，
脆弱性の有無そのものの判定基準には
直接影響しないよう設計している．

評価においては，
最初の脆弱性判定結果のみを
正解ラベルと比較することで，
処理段階数の違いが
検出性能評価に影響を与えないよう配慮した．

また，RAG構成における知識検索では，
検索件数を top-k = 5 に固定し，
類似度閾値を設けない設定とした．
この設定は，全ての実験において共通とし，
RAG構成内での条件差が生じないよう統一した．

%----------------------------------------------------------------------------
\chapter{実験結果と考察}
\label{chapter_5}
%----------------------------------------------------------------------------
本章では，第4章で述べた実験設定および評価方法に基づき実施した
脆弱性検出実験の結果を示し，提案手法の有効性について考察を行う．
まず，各手法における検出性能を定量的に比較し，
次に脆弱性種別ごとの検出傾向や誤検知の分析を行う．
さらに，Fine-TuningおよびRAGを用いた手法の特性を比較し，
最後に本手法の有効性と限界について議論する．

%------------------------------------
\section{検出性能の比較結果}
%------------------------------------
本節では，素のLLM，Fine-Tuning済みLLM，およびRAG構成LLMの
脆弱性検出性能を比較する．
評価指標としては，第4章で述べたPrecision，Recall，F1-scoreを用いる．

表\ref{tab:overall_performance}に示す数値は，
正解ラベルとして定義された脆弱性に対する
検出成否を基準として算出したものであり，
誤検知された脆弱性は
False Positive として Precision を低下させる要因となる．

そのため，本研究における Precision は，
LLMが不要な脆弱性を指摘せず，
適切な脆弱性のみを抽出できているかを示す指標として解釈できる．
一方，Recall は，
正解ラベルに含まれる脆弱性を
どの程度網羅的に検出できているかを示す．

結果から，いずれの構成においても
Recall は比較的低い値に留まっており，
正解ラベルとして定義された脆弱性を
十分に網羅できていないことが分かる．
また，本実験条件においては，
Fine-TuningおよびRAGを導入したモデルは，
素のLLMと比較して
Precision および Recall の双方において
顕著な改善は見られなかった．

この結果は，
脆弱性検出タスクにおいて，
モデルの知識拡張や外部知識の参照だけでは，
検出精度の向上が必ずしも保証されないことを示唆している．

ただし，
脆弱性種別ごとに分析した場合には，
特定の脆弱性において
比較的高い Recall を示すケースも確認されており，
これについては次節で詳述する．

%------------------------------------
% 以下の2つを調べる
% 無害なコードのどこを有害化を調べているか
% 有害なコードのどこを無害と判断してしまうか
\label{fix_2}
%------------------------------------
\begin{table}[t]
\centering
\caption{各手法の検出性能比較}
\label{tab:overall_performance}
\begin{tabular}{lccc}
\hline
手法 & Precision & Recall & F1-score \\
\hline
Base & 0.407 & 0.219 & 0.285 \\
FT      & 0.382 & 0.186 & 0.250 \\
RAG  & 0.360 & 0.171 & 0.231 \\

\hline
\end{tabular}
\end{table}

%------------------------------------
\section{脆弱性種別ごとの検出傾向}
%------------------------------------
本節では，脆弱性種別ごとの検出傾向について分析する．
対象とした脆弱性は，
XSS，CSRF，およびセッション関連の脆弱性とし，
Webアプリケーションにおいて
頻繁に問題となる代表的な脆弱性を対象とした．

表\ref{tab:individual_performance}は，
各脆弱性種別に対する各手法の Recall を示したものである．

XSS に関しては，
素のLLMが最も高い Recall を示しており，
Fine-Tuning済みLLMおよびRAG構成LLMでは
やや低下する結果となった．
このことから，
XSS のように典型的な攻撃パターンを持つ脆弱性については，
事前学習済みモデルでも一定の検出能力を有している一方で，
追加学習や外部知識の導入が必ずしも
Recall の向上につながらない場合があることが示唆される．

CSRF については，
素のLLMおよびFine-Tuning済みLLMでは
Recall が 1.000 となっており，
正解ラベルとして定義された CSRF を
すべて検出できていた．
一方，RAG構成LLMでは Recall が 0.500 に低下しており，
一部の CSRF が検出されなかったことが確認された．
この結果は，
RAG により付与された外部知識が，
CSRF の検出判断において
必ずしも一貫して有効に作用しなかった可能性を示している．

セッション関連の脆弱性については，
RAG構成LLMが最も高い Recall を示しており，
素のLLMおよびFine-Tuning済みLLMと比較して，
見落としが少ない傾向が確認された．
セッション管理や設定に関する脆弱性は，
コード単体の構文情報だけでなく，
一般的な設計指針や攻撃事例に基づく知識が
必要となる場合が多く，
RAG による外部知識の参照が
検出漏れの抑制に寄与した可能性がある．

ただし，
本研究における Recall は，
モデルが出力した指摘結果を基に算出しており，
モデルが一切言及しなかった脆弱性を
網羅的に把握できていない点には留意が必要である．
そのため，
本節の Recall は
脆弱性種別ごとの検出傾向を把握するための
参考指標として位置付ける．

なお，
本節では Recall のみに着目して分析を行っており，
誤検知を含めた総合的な性能評価については，
次節で False Positive の観点から検討する．

%------------------------------------
% Precisionを0.5などに揃えて平等な比較をするべき
% 過去の機械学習演習の内容を参照
% SklearのPrecision/Recallカーブなどを見ると良い？
\label{fix_3a}
%------------------------------------
\begin{table}[t]
\centering
\caption{脆弱性毎の各手法のRecall}
\label{tab:individual_performance}
\begin{tabular}{lccc}
\hline
手法 & XSS & CSRF & セッション関連 \\
\hline
Base & 0.694 & 1.000 & 0.882 \\
FT      & 0.676 & 1.000 & 0.750 \\
RAG  & 0.585 & 0.500 & 0.889 \\

\hline
\end{tabular}
\end{table}

%------------------------------------
\section{誤検知の分析}
%------------------------------------
本節では，各手法における
誤検知（False Positive）の傾向について分析する．

素のLLMでは，
入力コードの文脈を過度に一般化し，
実際には成立しない脆弱性を
指摘するケースが多く見られた．
特に，
PHPでの発生可能性が低い
バッファオーバフローや領域外アクセスといった
脆弱性を指摘する例や，
脆弱性が存在しないとラベル付けされたコードに対しても
問題があると判断する例が確認され，
これらが Precision 低下の一因となっていると考えられる．

Fine-Tuning済みLLMでは，
学習データに基づく脆弱性知識の獲得により，
指摘される脆弱性の種類は
素のLLMと比較して多様化する傾向が確認された．
しかし，
検出された脆弱性の中には，
実装内容と整合しない指摘や，
問題の本質を十分に捉えきれていないケースも散見された．

具体的には，
セッション管理や入力検証に関しては，
脆弱性の存在自体は正しく捉えているものの，
修正内容や影響範囲の説明が不十分な例も多かった．

一方で，
脆弱性が存在しないと正解ラベルで定義されている
プログラムに対しては，
「脆弱性無し」と判断する出力が得られており，
不要な脆弱性指摘を抑制できている点も確認された．

このことから，
Fine-Tuningは
指摘の網羅性を高める効果を持つ一方で，
指摘内容の妥当性や適用条件の判断には
依然として課題が残ることが示唆される．

RAG構成LLMでは，
外部知識の参照に基づき，
特定の脆弱性種別を一貫して指摘する傾向が強く，
同一プログラムに対して
類似した指摘が繰り返されるなど，
出力の再現性が高いことが確認された．
特に，
XSSやセッション固定化といった
代表的なWebアプリケーション脆弱性については，
複数のプログラムにおいて
安定した検出結果が得られている．

一方で，
指摘内容の多くが
実装の詳細や攻撃成立条件を十分に考慮しておらず，
脆弱性の成立が確認できない箇所に対しても
同一種別の脆弱性を機械的に適用してしまう例が見られた．
例えば，
CSRF対策が実装されているプログラムに対して
一律にCSRF脆弱性を指摘するケースや，
XSSや不正なデシリアライズといった脆弱性を
コード文脈に依らず繰り返し指摘する傾向が確認された．

この要因の一つとして，
RAG 構成における類似度検索の特性が考えられる．
特に今回の RAG 構成LLMでは，
類似度検索において明示的な閾値を設けていないため，
入力コードとの関連性が十分でない文書が
プロンプトに含まれる場合がある．
このことが，
入力コードと直接対応しない脆弱性の指摘を誘発し，
False Positive の増加につながった可能性がある．

また，
脆弱性が存在しないと正解ラベルで定義されているプログラムに対しても，
外部知識に基づく一般的な脆弱性パターンを適用し，
脆弱性が存在すると判断する例が多く見られた．
このことから，
RAG構成LLMは
脆弱性種別の想起や再現性の面では有効である一方で，
対象コード固有の実装状況を踏まえた
妥当性判断には課題が残ることが示唆される．

%------------------------------------
\section{Fine-TuningとRAGの比較考察}
%------------------------------------
本節では，
Fine-TuningとRAGという
二つのアプローチの特性を比較し，
それぞれの利点と課題について考察する．

Fine-Tuning 済み LLM は，
脆弱性の背景や一般的な対策方針について，
より詳細な説明を生成する傾向が確認された．
しかしその一方で，
脆弱性が実際に成立するか否かの判断においては，
説明生成を優先するあまり，
検出精度が必ずしも向上しないケースが見られた．
この結果は，
Fine-Tuning が
脆弱性検出というタスクよりも，
説明生成や知識提示に適した方向へ
モデルの挙動を変化させた可能性を示唆している．

一方，RAG 構成LLMでは，
外部の知識ベースを参照しながら推論を行うため，
知識の追加や更新が比較的容易であり，
脆弱性の背景説明や修正方針の提示といった
説明生成の補助としては有効である．
本実験においても，
RAG 構成LLMは
同一入力に対して類似した指摘を行うなど，
出力の再現性が高い傾向を示した．
しかしながら，
類似度検索において明示的な閾値を設けていない場合，
入力コードとの関連性が十分でない文書が
プロンプトに含まれることがあり，
これが入力コードと直接対応しない脆弱性の指摘を誘発し，
False Positive の増加につながった可能性がある．
このことから，
RAG による脆弱性検出精度の向上は，
知識検索の精度や文書選択の制御，
およびプロンプト設計に大きく依存することが明らかとなった．

次節では，検出結果に基づき提示された修正案の妥当性について考察する．

%------------------------------------
\section{脆弱性修正案の妥当性に関する考察}
%------------------------------------
本章では，前節までで得られた脆弱性検出結果を踏まえ，
各脆弱性に対して提示された修正案の妥当性について考察する．
本研究では，脆弱性の有無を正しく判定できるかに加え，
その修正案が実運用において有効であるかどうかを評価することが重要であると考える．
なぜなら，検出精度が高くても，
不適切な修正案は新たな不具合やユーザビリティの低下を招く可能性があるためである．

%------------------------------------
\subsection{修正案評価の観点}
%------------------------------------
本研究では，修正案の妥当性を以下の観点から定性的に評価する．

\begin{itemize}
\item 脆弱性の根本原因に対処しているか
\item 一般的なセキュリティベストプラクティスと整合しているか
\item 実装コストや可読性の観点から現実的であるか
\item 他の脆弱性やユーザビリティ低下を誘発しないか
\end{itemize}

これらの観点に基づき，単に表面的な対策に留まっていないか，
あるいは過剰な対策となっていないかを評価する．

%------------------------------------
\subsection{妥当な修正案の特徴}
%------------------------------------
XSS 脆弱性に対して出力時に \texttt{htmlspecialchars()} や \texttt{json\_encode()} を適用する修正や，
CSRF 脆弱性に対してトークン検証を導入する修正は，脆弱性の発生原因に直接対応しており，
妥当な修正案であると評価できる．また，セッション固定化攻撃に対する 
\texttt{session\_regenerate\_id(true)} や \texttt{session.use\_strict\_mode = 1} などの利用は，一般的に推奨されている対策であり，
既存の機能やユーザビリティへの影響も比較的小さい．

これらの修正案は，既存のWebアプリケーション開発において広く採用されている手法であり，
実装の容易さと効果のバランスが取れている点で有効であると考えられる．

%------------------------------------
\subsection{不十分または過剰な修正案の考察}
%------------------------------------
一方で，本研究において提示された修正案の中には，
脆弱性の本質的な原因に十分対応していない，
あるいは過剰な対策となっている例も確認された．

まず，XSS 脆弱性に関連して，
出力箇所に対して一律にエスケープ処理を施す修正案が見られた．
しかし，中には既に安全な API（例： exttt{textContent}）を
用いている箇所に対して追加でエスケープを行う，
あるいは多重にエスケープ処理を適用する修正案も存在した．
このような過剰なエスケープは，
表示の不整合や可読性の低下を招く可能性があり，
必ずしも望ましい対策とは言えない．

また，パストラバーサル脆弱性に対する修正案として，
入力値の一部を置換・加工するのみで，
依然としてパスに任意の文字列を含めることが可能な記法が提示される例も確認された．
これらの修正案は，一見すると対策を施しているように見えるものの，
攻撃者による不正なパス指定を根本的に防止できておらず，十分な対策とは言い難い．

さらに，検出された脆弱性とは直接関係のない修正や，
条件分岐の追加によって処理を複雑化させる修正など，
結果として保守性を低下させたり，新たな脆弱性を誘発する可能性のある修正案も一部に見られた．

これらの例から，修正案が提示されている場合であっても，
その内容が脆弱性の発生要因と適切に対応付けられていない場合には，
実用的なセキュリティ向上にはつながらないことが分かる．
したがって，修正案の評価においては，単に対策の有無を見るのではなく，
その妥当性や影響範囲を慎重に検討する必要がある．

%------------------------------------
\subsection{検出性能と修正案品質の関係}
%------------------------------------
本研究の結果から，
脆弱性を正しく検出できている場合であっても，
提示される修正案の品質にはばらつきがあることが明らかとなった．
特に，アプリケーションの文脈に強く依存する認可や設計上の問題に関しては，
抽象的または不十分な修正案が提示される傾向が見られた．

このことから，脆弱性検出性能の向上だけでなく，
修正案の妥当性を評価・改善する仕組みが今後の課題であると言える．

%------------------------------------
\subsection{まとめ}
%------------------------------------
本節では，脆弱性修正案の妥当性について定性的な考察を行った．
その結果，一般的な脆弱性に対しては妥当な修正案が提示される一方で，
設計や認可に関わる問題については不十分または過剰な修正案が含まれる場合があることが分かった．
この知見は，次章における本研究の限界と今後の展望に関する議論につながるものである．

%------------------------------------
\section{本手法の有効性と限界}
%------------------------------------
% AUCについても議論すればもう少し具体性が増す
\label{fix_4}
%------------------------------------
以上の実験結果から，
Fine-Tuning および RAG を用いた手法は，
脆弱性のリスク説明や修正案の生成といった
補助的なタスクにおいては一定の有効性を示す一方で，
脆弱性検出精度の向上という観点では，
素の LLM に対して
明確な優位性を示すには至らなかった．
特に，
脆弱性種別ごとの定量評価において
Recall を指標として分析した結果，
いずれの手法においても
脆弱性の見落としは一定程度抑制できているものの，
False Positive を十分に低減できていないことが
課題として浮き彫りとなった．

なお，本研究では，
評価指標として Precision ではなく Recall を主に用いた．
これは，
脆弱性種別ごとの定量評価において，
False Negative を定義することが比較的容易である一方，
False Positive の定義が
正解ラベルの粒度や解釈に強く依存するためである．

そのため，本研究では，
「実際に存在する脆弱性をどの程度検出できたか」
という観点を重視し，
Recall を中心とした評価を採用した．
ただし，Precision を評価指標から完全に排除したわけではなく，
本研究の評価設計上，
主指標としては扱わなかったものである．

Precision に関する詳細な分析については，
正解ラベルの粒度設計や，
脆弱性が存在しないコードに対する評価方法を
より精緻化した上で，
今後の課題として検討する必要がある．

一方で，本手法にはいくつかの限界も存在する．
まず，
評価対象が PHP コードに限定されており，
他言語や異なる実装パラダイムへの一般化については
今後の検討が必要である．
また，
脆弱性の正解ラベルの定義や粒度，
特に脆弱性が存在しないコードを
どのように評価指標へ反映するかといった点が，
評価結果に大きく影響するという制約がある．
さらに，
RAG における知識ベースの品質や
類似度検索の閾値設定，
文書選択戦略が
検出結果に与える影響については，
より詳細な分析が求められる．

これらの課題を踏まえ，
次章では本研究のまとめと
今後の展望について述べる．

%------------------------------------
%   Chapter 6
\chapter{まとめと今後の展望}
\label{chapter_6}
%------------------------------------
本章では，本研究全体を通じて得られた知見をまとめるとともに，
提案手法の限界および今後の課題について述べる．

%------------------------------------
\section{本研究のまとめ}
%------------------------------------
本研究では，Webアプリケーションにおいて広く利用されている
PHPプログラムを対象として，
大規模言語モデル（LLM）を用いた脆弱性検出手法の有効性を検証した．
特に，XSS，CSRF，セッション管理の不備といった
Webアプリケーション特有の脆弱性に着目し，
複数のプログラムを用いた実験を通じて，
LLMによる自動解析の実用可能性を検討した．

本研究では，
素のLLM，Fine-Tuningを施したLLM，およびRAG構成の三手法を比較し，
同一条件下における検出結果および誤検知傾向を分析した．
これにより，
LLMの利用形態の違いが脆弱性検出性能や出力内容に与える影響を
体系的に明らかにした．

%------------------------------------
\section{研究成果の整理}
%------------------------------------
実験結果から，LLMはPHPコードの構造や処理の流れを一定程度理解し，
代表的な脆弱性については自動的に検出できることが確認された．
一方で，脆弱性の種類や実装文脈によっては，
誤検知や検出漏れが発生する場合もあり，
全てのケースにおいて安定した性能を示すわけではないことが明らかとなった．

Fine-Tuning構成では，
学習データに含まれる脆弱性パターンに対して
検出性能の向上が確認された．
しかし，学習時に想定されていない実装や，
文脈依存性の高い脆弱性に対しては，
性能が十分に発揮されない場合も見られた．

これに対してRAG構成では，
外部知識を参照することで，
脆弱性の説明や修正案の一貫性が向上する傾向が確認された．
特に，CWEなどの一般的な知識体系を参照可能である点は，
誤った推論やハルシネーションの抑制に寄与しており，
実運用を想定した利用において有効であると評価できる．

%------------------------------------
\section{本研究の貢献}
%------------------------------------
本研究の主な貢献は，以下の三点に整理できる．

第一に，
PHPを対象としたWebアプリケーション脆弱性検出において，
LLMの有効性を実験的に示した点である．
従来研究では低レベル言語を対象とした解析が中心であったのに対し，
Web言語特有の脆弱性を扱った点に本研究の新規性がある．

第二に，
Fine-TuningおよびRAGという異なるLLM活用手法を
同一条件下で比較し，
それぞれの特性と適用上の利点・欠点を明確にした点である．
これにより，
利用目的に応じたLLM構成の選択指針を示した．

第三に，
脆弱性の検出結果だけでなく，
提示される修正案の妥当性に着目し，
過剰な対策や不十分な修正が生じ得ることを明らかにした点である．
これは，LLMをセキュリティ支援に用いる際の
実用上の注意点を示す重要な知見である．

%------------------------------------
\section{限界と課題}
%------------------------------------
本研究にはいくつかの限界が存在する．
第一に，評価対象を比較的小規模なPHPプログラムに限定しており，
大規模な実運用コードに対する有効性は十分に検証できていない．

第二に，本研究では脆弱性の有無および種類を主な評価対象とし，
修正案の品質については定性的な評価に留まっている．
修正案の安全性や妥当性を
定量的に評価する指標の設計は，
今後の重要な課題である．

第三に，LLMの出力は入力プロンプトや参照知識に依存するため，
結果の再現性や安定性に課題が残る．
この点は，実運用を想定した導入において
慎重な検討が必要である．

%------------------------------------
\section{今後の課題}
%------------------------------------
今後の展望として，
対象言語および脆弱性種別の拡張が挙げられる．
JavaScriptやPythonなど，
他のWeb関連言語を対象とすることで，
本研究で得られた知見の汎用性を検証できると考えられる．

また，
大規模コードベースやCI/CD環境への適用を通じて，
LLMを用いた脆弱性検出手法の
実運用における有効性を評価することも重要である．

さらに，
検出結果と修正案を統合的に評価する仕組みを導入することで，
LLMを単なる解析支援にとどめず，
セキュアコーディングを支援する
実践的な開発支援ツールへと発展させることが期待される．

%------------------------------------
%   Acknowledgements
\chapter*{謝辞}
\label{chapter_7}
%------------------------------------
\addcontentsline{toc}{chapter}{謝辞}
本研究を進めるにあたりご指導頂きました木脇太一先生に感謝いたします．
日頃の議論を通じて多くの知識や示唆を頂きました木脇研究室の皆様に感謝いたします．

%------------------------------------
%   References
%------------------------------------
\bibliography{main} %hoge.bibから拡張子を外した名前
\bibliographystyle{plainnat} %参考文献出力スタイル
%------------------------------------
% \appendix
%------------------------------------

%------------------------------------
\end{document}
%------------------------------------
