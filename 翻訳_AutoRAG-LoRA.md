## LoRA拡張復号による接地生成。

構造化されたプロンプト x′ と上位 K 個の検索文書 D={d_1,d_2,...,d_K} が与えられた場合、生成モジュールは y∼P_gen (y∣x′,D) を生成する。計算効率を維持しつつ事実の整合を強化するため、低ランク適応（LoRA）を用いて基底言語モデルを微調整する。
W∈ℝ^{d×k}は注意層やフィードフォワード層の射影のような変換器アーキテクチャ内の重み行列を表すとする。LoRAは学習可能な低ランク分解を導入する：

W′=W+ΔW=W+BA

ここでA∈ℝ^{r×k}, B∈ℝ^{d×r}, r≪min(d,k)は適応能力を制御する。この設計により、微調整中に更新されるのは低ランク行列AとBのみで、基本重みWは凍結されたままとなり、メモリ・オーバーヘッドが大幅に削減される。
我々の基本モデルはMistral-7Bであり、ランクr=8、スケーリングファクターα=16のLoRAアダプターを使用し、注意投影層（QとV）をターゲットとしている。実装にはHuggingFace PEFTライブラリを用いる。安定性のため、微調整の際にドロップアウトを適用する。

y=Wh+α⋅BAh

hは前の層からの隠れ活性化を表す。この構成では、LoRAアダプタは「事実バイアスインジェクタ」として機能し、検索された文脈により合致するコンテンツへと生成を誘導する。

## 条件付きアダプタルーティング。

事実補正を選択的に適用するために、AutoRAG-LoRAは幻覚リスクに基づくアダプター更新の条件付きルーティングをサポートする。具体的には、幻覚分類器のソフト出力p_hall∈[0,1]（セクション2.4参照）を使って、アダプタを起動すべきかどうかを決定する。

閾値τ（デフォルト：0.7）を定義する。p_hall>τの場合、生成は幻覚を起こしやすいと判定され、学習中のフィードバック補正のためにLoRAアダプタが起動される。そうでない場合は、基本重みを凍結し、アダプタを非アクティブにして生成を進める。

形式的には
~

このバイナリゲーティングは、選択的なファクトチューニングをシミュレートするために、訓練と評価の両方で使用される。将来の研究では、アダプターの活性化の大きさが
p_hallでスケールし、よりスムーズな介入勾配を可能にする、連続的なルーティングを探求する予定である。

## 幻覚の検出。

注意深くプロンプトを構造化し、文脈を考慮した生成を行なっても、検索された文書$D={d_1,...,d_K}$と生成された出力$y∼P_{gen}(y∣x′,D)$のズレにより、幻覚が生じることがある。このようなエラーを検出するため、AutoRAG-LoRA には、与えられた応答が検索された証拠と事実上整合しているかどうかを評価する、専用の幻覚検出モジュールが搭載されている。

このモジュールは2つのモードで動作する：
- 訓練された2値分類器による暗黙的検出。
- LLMスコアリングや説明可能な帰属法のような自己評価メカニズムによる明示的検出。

## 分類器に基づく検出。
二値分類器は、文書集合$D$を条件として生成された出力$y$を幻覚確率にマッピングするように訓練されます：

$$p_hall = σ⁢(W_clf⁢[y;D]+b)$$

ここで、$[y;D]$は出力と文脈の連結（または共同表現）を表し、$W_{clf}$と$b$は学習可能な分類器パラメーター、$σ(⋅)$はシグモイド活性化関数です。分類器は標準の二値クロスエントロピー損失を用いて最適化されます：

$$ℒ_{clf}=−y_{true} \ log \ p_{hall} − (1−y_{true})⁢ log (1−p_{hall})$$

## 説明可能で自己評価可能なアプローチ。
並行して、システムは解釈可能性を向上させた検出をサポートするために、以下の手法を使用します：

- レイヤーごとの関連性伝播（LRP）または統合勾配法を用いて、トークンレベルの貢献度を評価します。
- 注意エントロピーを用いて、拡散的または焦点の定まらない推論パターンを特定します。
- P_gen(y∣x′,D)とP_ret(y∣D)間のコサイン類似度やジェンセン・シャノン散逸度などの意味的ドリフト指標。

これらのモジュールは、二値の幻覚フラグと連続的な信頼度スコア、およびオプションの説明を組み合わせた多角的な事実一致の視点を提供します。これらの出力は、下流の修正ループの決定論理を駆動します。

## KL正規化学習によるフィードバック補正。
幻覚検出モジュールが生成された出力 y∼P_gen(y∣x′,D) を取得されたコンテキスト D と不一致と判定した場合、AutoRAG-LoRA はオプションのフィードバック補正ループをアクティブ化します。このループは、KL正規化と対比学習の目的関数を使用して、将来の生成結果を事実に基づく証拠とより一致させるようにモデルを微調整します。

参照分布 P_ret.
私たちは、取得条件付き参照分布 
P_ret(y∣x′,D) を、ベースモデル（例：Mistral-7B）から取得文書に厳密に条件付けられた凍結されたデコード分布として定義します。具体的には、アダプター活性化と幻覚補正を無効化した状態でプロンプト x′ を再デコードし、「事実に基づくのみ」の応答を生成します。この出力は、KL項の監督信号として扱われます。

実践では、凍結モデルからのトークンのソフトマックス確率を用いて 
P_ret を近似します：

P_ret(y)=softmax(f_frozen(x′,D))

これは、ドリフトが罰則される安定した接地参照として機能します。

## KLダイバージェンスペナルティ。
モデルの生成結果と検索一致参照との間のKLダイバージェンスは次のように計算されます：

ℒ_KL=∑_y P_gen(y∣x′,D)⋅log P_gen(y∣x′,D) / P_ret(y∣x′,D)

このソフト制約は、証拠に基づく出力との意味的一貫性を正規化します。

対照的幻覚損失。
事実の一致をさらに強化するため、対照的KL項を導入します。以下のように定義します：

P+：高い検索一致率と低い幻覚スコア（p_hall<0.3）で生成された根拠に基づく完了、
P−：高い幻覚スコア（p_hall>0.7）を持つ幻覚完了で、以前のモデルチェックポイントからサンプリングするか、合成的に破損した完了からサンプリングされます。
次のように計算します：

ℒ_contrast=KL(P+∥P_ret)−KL(P−∥P_ret)
これにより、モデルは根拠に基づく分布に収束し、幻覚に基づく分布から離れるように促されます。

総生成損失。
最終的なトレーニング目標は、標準のクロスエントロピー損失と両方の補助項を組み合わせたものです：

ℒ_total=ℒ_CE+λ1⋅ℒ_KL+λ_2⋅ℒ_contrastハイパーパラメーター λ_1=0.4, λ_2=0.6 は TruthfulQA での検証を通じて調整されます。

## 評価指標と最終出力の解釈
評価と解釈可能性。
AutoRAG-LoRAによって生成された出力の事実的な一貫性と信頼性を評価するため、定量的な評価指標と説明可能性に基づく解釈ツールの組み合わせを採用しています。これらの指標は、生成の品質と、取得した文脈Dとの一致度を両方を捉えます。

KLダイバージェンスのドリフト。
生成モデル 
P_gen(y∣x′,D) と取得文脈に一致した参照分布 P_ret(y∣x′,D) 間の分布的乖離を、KL 乖離を用いて測定します：
KL Drift=∑y Pgen(y∣x′,D)⋅log P_gen(y∣x′,D)P_ret(y∣x′,D)
これは、生成が取得した情報にどれだけ準拠しているかを直接示す指標です。

セマンティック・ジェンセン・シャノン・ダイバージェンス（JSD）。
セマンティックな重複を考慮し、スタイルの多様性を罰しないように、生成された出力と取得情報に基づく補完の間のジェンセン・シャノンダイバージェンスを計算します。この対称的で有界なダイバージェンスは、事実的な一貫性を測定する安定した指標を提供します。

トークン関連性と帰属。
トークンレベルの解釈可能性技術を活用し、取得した文書の一部が生成された出力にどのように影響したかを可視化・説明します。具体的には：

• レイヤー別関連性伝播（LRP）
• 統合勾配
これらの方法はトークンの帰属重みを強調し、幻覚のデバッグや取得効果の検証に特に有用です。

## 注意エントロピーと焦点メトリクス。
デコードステップ全体で注意エントロピーを分析し、拡散や焦点の喪失の兆候を検出します。高いエントロピーはしばしば幻覚的な文脈と関連し、鋭い注意分布はより強い文脈的基盤を示唆します。

## 最終出力インターフェース。
AutoRAG-LoRAの出力には以下のものが含まれます：

• x^′とDを条件とした生成された応答y
• 幻覚信頼度スコアまたは二値フラグ（分類器または自己評価から）
• オプションの説明トレース（例：LRP、統合勾配）
• アダプター活性化、検索スコア、および修正ループトリガーのログ（有効化されている場合）
これらの出力は、エンドユーザーの利用と開発者側のデバッグの両方を支援し、透明性、追跡可能性、および下流の適応や監査のための堅牢なシグナルを提供します。

---
## 4.7 限界と今後の課題
AutoRAG-LoRAは堅牢な幻覚削減効果を示していますが、いくつかの制限事項が残っています。まず、現在の幻覚分類器は、接地信号が弱い曖昧なまたは多目的のクエリにおいて性能が低下する可能性があります。次に、システムは高品質な検索を前提としています。検索モジュールの失敗は、幻覚検出とフィードバックループを誤導する可能性があります。さらに、LoRAアダプターの二値ルーティングを固定閾値（τ=0.7）で実施する点は、今後のイテレーションでより滑らかで連続的な活性化ダイナミクスを採用する余地があります。最後に、当フレームワークはアダプター更新を隔離することで過学習を回避しますが、プロンプト変換と分類器コンポーネントを共同で再調整しない限り、ドメインシフトに対応できない可能性があります。  

## 4.8 議論
これらの結果は、AutoRAG-LoRAが流暢性や遅延を犠牲にすることなく、最先端の幻覚削減を実現することを示しています。従来の方法がフルモデルRLHFやDPOスタイルの調整を必要とするのに対し、当フレームワークは軽量アダプター、KLガイド補正、幻覚意識型ルーティングを用いて同等の性能向上を実現します。当アーキテクチャはノイズの多いプロンプトに頑健であり、オープンドメインと事実ベースのQA設定の両方で汎化可能です。

さらに、高リスク生成領域（p_hal⁢l経由）でアダプターを選択的に更新することで、AutoRAG-LoRAは標準的なLoRAやDPOパイプラインで一般的な過学習問題を回避します。特に報酬の誤指定下でのこの特性は重要です。当研究の貢献は、忠実な生成、マルチパス再ランク付け、幻覚意識型デコードに関する最近の進展と一致しています。

---
DeepL.com（無料版）で翻訳しました。
